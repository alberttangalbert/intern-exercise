{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff4ae34",
   "metadata": {},
   "source": [
    "#### Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f9a86",
   "metadata": {},
   "source": [
    "Load raw trial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97784b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"data/raw_trials.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e73a1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'objective', 'outcome_details', 'phase',\n",
      "       'primary_completion_date', 'primary_endpoints_reported_date',\n",
      "       'prior_concurrent_therapy', 'start_date', 'study_design',\n",
      "       'treatment_plan', 'record_type', 'patients_per_site_per_month',\n",
      "       'primary_endpoint_json', 'other_endpoint_json', 'associated_cro_json',\n",
      "       'notes_json', 'outcomes_json', 'patient_dispositions_json',\n",
      "       'results_json', 'study_keywords_json', 'tags_json',\n",
      "       'primary_drugs_tested_json', 'other_drugs_tested_json',\n",
      "       'therapeutic_areas_json', 'bmt_other_drugs_tested_json',\n",
      "       'bmt_primary_drugs_tested_json', 'ct_gov_listed_locations_json',\n",
      "       'ct_gov_mesh_terms_json'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b69802af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                                 |   0 |\n",
      "|:--------------------------------|----:|\n",
      "| title                           |   0 |\n",
      "| objective                       |   3 |\n",
      "| outcome_details                 | 146 |\n",
      "| phase                           |   0 |\n",
      "| primary_completion_date         |  61 |\n",
      "| primary_endpoints_reported_date | 161 |\n",
      "| prior_concurrent_therapy        | 184 |\n",
      "| start_date                      |  45 |\n",
      "| study_design                    |  16 |\n",
      "| treatment_plan                  |   1 |\n",
      "| record_type                     |   0 |\n",
      "| patients_per_site_per_month     | 119 |\n",
      "| primary_endpoint_json           |   0 |\n",
      "| other_endpoint_json             |   0 |\n",
      "| associated_cro_json             |   0 |\n",
      "| notes_json                      |   0 |\n",
      "| outcomes_json                   |   0 |\n",
      "| patient_dispositions_json       |   0 |\n",
      "| results_json                    |   0 |\n",
      "| study_keywords_json             |   0 |\n",
      "| tags_json                       |   0 |\n",
      "| primary_drugs_tested_json       |   0 |\n",
      "| other_drugs_tested_json         |   0 |\n",
      "| therapeutic_areas_json          |   0 |\n",
      "| bmt_other_drugs_tested_json     |   0 |\n",
      "| bmt_primary_drugs_tested_json   |   0 |\n",
      "| ct_gov_listed_locations_json    |   0 |\n",
      "| ct_gov_mesh_terms_json          |   0 |\n",
      "Shape: (184, 28)\n"
     ]
    }
   ],
   "source": [
    "print(data.isna().sum().to_markdown())\n",
    "print(\"Shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d278e",
   "metadata": {},
   "source": [
    "Generate unique hash per trial since trial id is missing\n",
    "- i.e. \"tid_0e8fa21079f928135dfc6164a15285f8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6897de1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ cache/raw_trials_with_hash.csv already exists — skipping hash generation.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "OUTPUT_PATH = Path(\"cache/raw_trials_with_hash.csv\")\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# If file already exists → skip generation\n",
    "# ---------------------------------------------------------\n",
    "if OUTPUT_PATH.exists():\n",
    "    print(f\"⚠️ {OUTPUT_PATH} already exists — skipping hash generation.\")\n",
    "else:\n",
    "    print(\"Generating raw_trials_with_hash.csv ...\")\n",
    "\n",
    "    def make_trial_hash(row):\n",
    "        \"\"\"\n",
    "        Deterministic hash for a trial based on stable fields.\n",
    "        You can add/remove fields if needed.\n",
    "        \"\"\"\n",
    "        payload = {\n",
    "            \"title\": row.get(\"title\", \"\"),\n",
    "            \"start_date\": row.get(\"start_date\", \"\"),\n",
    "            \"phase\": row.get(\"phase\", \"\"),\n",
    "        }\n",
    "        raw = json.dumps(payload, sort_keys=True, ensure_ascii=False)\n",
    "        return \"tid_\" + hashlib.md5(raw.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "    # Create trial_hash column\n",
    "    data[\"trial_hash\"] = data.apply(make_trial_hash, axis=1)\n",
    "\n",
    "    # Move trial_hash to first column\n",
    "    cols = [\"trial_hash\"] + [c for c in data.columns if c != \"trial_hash\"]\n",
    "    data = data[cols]\n",
    "\n",
    "    print(data.columns)\n",
    "    print(data.shape)\n",
    "\n",
    "    # Export\n",
    "    data.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"✅ Saved to {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14351eb6",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "\n",
    "Using a chatbot, identify all interventions from each trial. For each intervention...\n",
    "- label as the investigational product, active comparator, or placebo\n",
    "- list all of the alternative names\n",
    "- identify the molecular target \n",
    "- identify the mechanism of action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efb4f1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 184 trials from cache/raw_trials_with_hash.csv\n",
      "Progress: processed 50 trials...\n",
      "Progress: processed 100 trials...\n",
      "Progress: processed 150 trials...\n",
      "✅ Trial drug-role mapping complete. processed=184, skipped=0, llm_error=0, parse_error=0\n",
      "Roles directory: cache/trial_drug_roles\n",
      "Log directory:   cache/trial_drug_roles_log\n",
      "Master roles:    cache/trial_drug_roles_master.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import pandas as pd\n",
    "from services.openai_wrapper import OpenAIWrapper\n",
    "\n",
    "# -------------------------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------------------------\n",
    "BASE_DIR = Path(\"cache\")\n",
    "\n",
    "TRIALS_WITH_HASH_CSV = Path(\"cache/raw_trials_with_hash.csv\")\n",
    "\n",
    "DRUG_ROLE_DIR = BASE_DIR / \"trial_drug_roles\"\n",
    "DRUG_ROLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DRUG_ROLE_LOG_DIR = BASE_DIR / \"trial_drug_roles_log\"\n",
    "DRUG_ROLE_LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MASTER_ROLES_PATH = BASE_DIR / \"trial_drug_roles_master.json\"\n",
    "\n",
    "MODEL = \"gpt-5\"\n",
    "client = OpenAIWrapper()\n",
    "\n",
    "MAX_WORKERS = 8\n",
    "\n",
    "# Columns to feed into the chatbot\n",
    "RELEVANT_COLS = [\n",
    "    \"title\",\n",
    "    \"objective\",\n",
    "    \"outcome_details\",\n",
    "    \"notes_json\",\n",
    "    \"results_json\",\n",
    "    \"primary_drugs_tested_json\",\n",
    "    \"other_drugs_tested_json\",\n",
    "    \"therapeutic_areas_json\",\n",
    "    \"bmt_other_drugs_tested_json\",\n",
    "    \"bmt_primary_drugs_tested_json\",\n",
    "    \"ct_gov_mesh_terms_json\",\n",
    "]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Helpers\n",
    "# -------------------------------------------------\n",
    "def extract_json_object(text: str) -> dict:\n",
    "    \"\"\"Extract first valid JSON object from model output.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return {}\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return {}\n",
    "\n",
    "    # Direct parse first\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: first {...} region\n",
    "    m = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        return {}\n",
    "    try:\n",
    "        obj = json.loads(m.group(0))\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    return {}\n",
    "\n",
    "\n",
    "def build_prompt(trial_payload: dict) -> str:\n",
    "    \"\"\"\n",
    "    Build prompt asking the LLM to:\n",
    "    - Extract drug names\n",
    "    - Canonicalize names by removing company/manufacturer/location qualifiers\n",
    "    - Deduplicate synonymous names\n",
    "    - For each canonical drug, return a dict with:\n",
    "        * role (Investigational Product / Placebo / Active Comparator / Standard of Care)\n",
    "        * alternative_names (list)\n",
    "        * molecular_target\n",
    "        * mechanism\n",
    "    \"\"\"\n",
    "    payload_json = json.dumps(trial_payload, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a clinical trial design and interpretation expert.\n",
    "\n",
    "You are given structured information about a clinical trial, including:\n",
    "- Title and objective\n",
    "- Study design and treatment plan\n",
    "- JSON fields listing drugs tested in the study:\n",
    "  - primary_drugs_tested_json\n",
    "  - other_drugs_tested_json\n",
    "  - bmt_other_drugs_tested_json\n",
    "  - bmt_primary_drugs_tested_json\n",
    "- These JSON fields may also contain metadata such as\n",
    "  drugApprovalStatus (Approved / Unapproved), mechanisms, etc.\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "1. Identify all DISTINCT physical drug entities explicitly used in the study.\n",
    "   - Strings in the *_drugs_tested_json fields are drug-name candidates.\n",
    "   - If these fields contain structured JSON, infer names from keys such as\n",
    "     \"name\", \"drug_name\", \"preferred_name\", \"label\", etc.\n",
    "\n",
    "2. Canonicalize each drug name:\n",
    "   Remove company names, manufacturer qualifiers, geographic qualifiers,\n",
    "   dosage-form qualifiers, or parenthetical descriptors that do NOT change\n",
    "   the name of the underlying drug.\n",
    "   Examples of correct canonicalization:\n",
    "   - \"AlphaBlocker (CompanyX)\" → \"AlphaBlocker\"\n",
    "   - \"Recombinant Growth Factor (rgf)\" → \"Recombinant Growth Factor\"\n",
    "   - \"DrugX citrate (RegionY)\" → \"DrugX citrate\"\n",
    "   - \"BrandName (compound-42, MakerCorp)\" → \"BrandName\"\n",
    "\n",
    "   Keep only the essential drug or brand name as the canonical key.\n",
    "\n",
    "3. Deduplicate synonymous names referring to the SAME drug.\n",
    "   - If multiple variations refer to one physical drug, keep ONE canonical key.\n",
    "   - Prefer the simplest, clean name.\n",
    "   - Collect all other variations in alternative_names.\n",
    "\n",
    "4. For EACH distinct drug, build an object with FOUR fields:\n",
    "\n",
    "   - \"role\": one of:\n",
    "       * \"Investigational Product\"\n",
    "       * \"Placebo\"\n",
    "       * \"Active Comparator\"\n",
    "       * \"Standard of Care\"\n",
    "\n",
    "   ROLE ASSIGNMENT GUIDANCE:\n",
    "\n",
    "   A. \"Investigational Product\"\n",
    "      - Use ONLY for the sponsor's proprietary or novel product.\n",
    "      - Clues: unapproved, new mechanism, highlighted in title/objective.\n",
    "      - Do NOT label common chemotherapy or widely used drugs this way.\n",
    "\n",
    "   B. \"Standard of Care\"\n",
    "      - Use for established backbone therapies, such as common chemotherapies\n",
    "        or widely used drugs in the disease area.\n",
    "      - Examples (fictional): DrugX, Chemo-A, Cytotoxin-7, etc.\n",
    "\n",
    "   C. \"Active Comparator\"\n",
    "      - Use when a non-placebo drug is explicitly the control arm.\n",
    "      - Clues: terms like \"versus\", \"comparator\", \"control regimen\".\n",
    "\n",
    "   D. \"Placebo\"\n",
    "      - Use for inert or sham treatments.\n",
    "\n",
    "   SUMMARY:\n",
    "   - Proprietary or novel study drug → \"Investigational Product\".\n",
    "   - Classical or widely used therapy → \"Standard of Care\".\n",
    "   - Control regimen (non-placebo) → \"Active Comparator\".\n",
    "   - Inert control → \"Placebo\".\n",
    "\n",
    "   - \"alternative_names\": list of synonymous or variant names.\n",
    "     Examples:\n",
    "     * ABC-123 → [\"Compound-ABC\", \"ABC123\"]\n",
    "     * BrandX → [\"generic compound name\"]\n",
    "\n",
    "   - \"molecular_target\": e.g., \"CD20\", \"Kinase-A\", \"Receptor-Z\".\n",
    "     If unknown, use \"\".\n",
    "\n",
    "   - \"mechanism\": e.g., \"monoclonal antibody\", \"kinase inhibitor\",\n",
    "     \"fusion protein\", etc.\n",
    "     If not inferable, use \"\".\n",
    "\n",
    "Important rules:\n",
    "- \"role\" MUST use only the allowed strings.\n",
    "- No invented drugs.\n",
    "- Combination therapies: classify EACH component using the rules above.\n",
    "\n",
    "Input JSON:\n",
    "{payload_json}\n",
    "\n",
    "Output format (IMPORTANT):\n",
    "- Return ONLY a valid JSON object with:\n",
    "    - keys   = canonical drug names\n",
    "    - values = objects with EXACTLY:\n",
    "        * \"role\"\n",
    "        * \"alternative_names\"\n",
    "        * \"molecular_target\"\n",
    "        * \"mechanism\"\n",
    "\n",
    "Example output:\n",
    "{{\n",
    "  \"ABC-123\": {{\n",
    "    \"role\": \"Investigational Product\",\n",
    "    \"alternative_names\": [\"ABC123\", \"Compound-ABC\"],\n",
    "    \"molecular_target\": \"Receptor-Z\",\n",
    "    \"mechanism\": \"Bispecific antibody\"\n",
    "  }},\n",
    "  \"DrugX\": {{\n",
    "    \"role\": \"Standard of Care\",\n",
    "    \"alternative_names\": [\"GenericX\", \"ChemX\"],\n",
    "    \"molecular_target\": \"Enzyme-A\",\n",
    "    \"mechanism\": \"Antimetabolite\"\n",
    "  }},\n",
    "  \"ControlDrug\": {{\n",
    "    \"role\": \"Active Comparator\",\n",
    "    \"alternative_names\": [\"CD-01\"],\n",
    "    \"molecular_target\": \"\",\n",
    "    \"mechanism\": \"\"\n",
    "  }},\n",
    "  \"Placebo\": {{\n",
    "    \"role\": \"Placebo\",\n",
    "    \"alternative_names\": [],\n",
    "    \"molecular_target\": \"\",\n",
    "    \"mechanism\": \"Inert comparator\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Before returning JSON:\n",
    "- Ensure no drug key contains manufacturer qualifiers.\n",
    "- Ensure all four fields exist for every drug.\n",
    "- Ensure classical backbone therapies are NOT labeled “Investigational Product”.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "# Shared counters & master mapping\n",
    "counter = {\n",
    "    \"processed\": 0,\n",
    "    \"skipped_existing\": 0,\n",
    "    \"llm_error\": 0,\n",
    "    \"parse_error\": 0,\n",
    "}\n",
    "counter_lock = threading.Lock()\n",
    "\n",
    "master_roles: dict[str, dict] = {}\n",
    "master_lock = threading.Lock()\n",
    "\n",
    "\n",
    "def process_trial(row: dict, idx: int, total: int) -> None:\n",
    "    \"\"\"Process one trial: prompt LLM, save output & log (only if valid).\"\"\"\n",
    "    trial_hash = str(row.get(\"trial_hash\", \"\")).strip()\n",
    "    if not trial_hash:\n",
    "        print(f\"⚠️ [{idx}/{total}] Missing trial_hash, skipping\")\n",
    "        return\n",
    "\n",
    "    out_fp = DRUG_ROLE_DIR / f\"{trial_hash}.json\"\n",
    "    if out_fp.exists():\n",
    "        with counter_lock:\n",
    "            counter[\"skipped_existing\"] += 1\n",
    "        return\n",
    "\n",
    "    # Build payload from selected columns\n",
    "    trial_payload = {\"trial_hash\": trial_hash}\n",
    "    for col in RELEVANT_COLS:\n",
    "        trial_payload[col] = row.get(col, \"\")\n",
    "\n",
    "    prompt = build_prompt(trial_payload)\n",
    "\n",
    "    token = trial_hash\n",
    "    hash_id = trial_hash\n",
    "\n",
    "    text_response = \"\"\n",
    "    raw_response = None\n",
    "    total_cost = 0.0\n",
    "    elapsed = 0.0\n",
    "\n",
    "    # Call LLM\n",
    "    try:\n",
    "        t0 = time.perf_counter()\n",
    "        res = client.query(prompt=prompt, model=MODEL)\n",
    "        elapsed = round(time.perf_counter() - t0, 2)\n",
    "\n",
    "        text_response = (res.get(\"text_response\") or \"\").strip()\n",
    "        raw_response = res.get(\"raw_response\")\n",
    "        total_cost = float(res.get(\"cost\") or 0.0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ [{idx}/{total}] LLM error for trial_hash={trial_hash}: {e}\")\n",
    "        with counter_lock:\n",
    "            counter[\"llm_error\"] += 1\n",
    "        return\n",
    "\n",
    "    drug_roles = extract_json_object(text_response)\n",
    "\n",
    "    # Treat non-dict OR empty dict as invalid → do NOT save anything\n",
    "    if not isinstance(drug_roles, dict) or not drug_roles:\n",
    "        print(f\"⚠️ [{idx}/{total}] JSON parse/validity error trial_hash={trial_hash}, raw={text_response!r}\")\n",
    "        with counter_lock:\n",
    "            counter[\"parse_error\"] += 1\n",
    "        return\n",
    "\n",
    "    mapped = {\n",
    "        \"trial_hash\": trial_hash,\n",
    "        \"title\": row.get(\"title\"),\n",
    "        \"drug_roles\": drug_roles,\n",
    "        \"source\": \"llm\",\n",
    "    }\n",
    "\n",
    "    # Save per-trial roles JSON\n",
    "    out_fp.write_text(json.dumps(mapped, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    # Log entry\n",
    "    log_payload = {\n",
    "        \"token\": token,\n",
    "        \"hash_id\": hash_id,\n",
    "        \"model\": MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"structured_response\": json.dumps(mapped, ensure_ascii=False, indent=2),\n",
    "        \"raw_response\": repr(raw_response),\n",
    "        \"total_cost\": total_cost,\n",
    "        \"time_elapsed\": elapsed,\n",
    "    }\n",
    "    (DRUG_ROLE_LOG_DIR / f\"{hash_id}.json\").write_text(\n",
    "        json.dumps(log_payload, ensure_ascii=False, indent=2),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "    # Update master roles\n",
    "    with master_lock:\n",
    "        master_roles[trial_hash] = mapped\n",
    "        MASTER_ROLES_PATH.write_text(\n",
    "            json.dumps(master_roles, ensure_ascii=False, indent=2),\n",
    "            encoding=\"utf-8\"\n",
    "        )\n",
    "\n",
    "    with counter_lock:\n",
    "        counter[\"processed\"] += 1\n",
    "        if counter[\"processed\"] % 50 == 0:\n",
    "            print(f\"Progress: processed {counter['processed']} trials...\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# RUN CONCURRENTLY\n",
    "# -------------------------------------------------\n",
    "df_trials = pd.read_csv(TRIALS_WITH_HASH_CSV, dtype=str).fillna(\"\")\n",
    "rows = df_trials.to_dict(orient=\"records\")\n",
    "total_trials = len(rows)\n",
    "print(f\"Loaded {total_trials} trials from {TRIALS_WITH_HASH_CSV}\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    futures = {\n",
    "        ex.submit(process_trial, row, idx, total_trials): row.get(\"trial_hash\")\n",
    "        for idx, row in enumerate(rows, start=1)\n",
    "    }\n",
    "    for fut in as_completed(futures):\n",
    "        th = futures[fut]\n",
    "        try:\n",
    "            fut.result()\n",
    "        except Exception as e:\n",
    "                print(f\"⚠️ Worker error trial_hash={th}: {e}\")\n",
    "\n",
    "print(\n",
    "    f\"✅ Trial drug-role mapping complete. \"\n",
    "    f\"processed={counter['processed']}, \"\n",
    "    f\"skipped={counter['skipped_existing']}, \"\n",
    "    f\"llm_error={counter['llm_error']}, \"\n",
    "    f\"parse_error={counter['parse_error']}\"\n",
    ")\n",
    "print(f\"Roles directory: {DRUG_ROLE_DIR}\")\n",
    "print(f\"Log directory:   {DRUG_ROLE_LOG_DIR}\")\n",
    "print(f\"Master roles:    {MASTER_ROLES_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce191b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== LLM COST SUMMARY ==========\n",
      "Total LLM cost:             $3.8619\n",
      "Number of logged trials:     184\n",
      "Average cost per trial:      $0.0210\n",
      "\n",
      "Top 10 most expensive trials:\n",
      "  tid_261f0233308ca080d1c60e3fda61ca85.json: $0.0621\n",
      "  tid_1158b3369546dc4b16dc21c8c026b619.json: $0.0454\n",
      "  tid_8b4d60a5fddc078962af34399d7e342c.json: $0.0425\n",
      "  tid_e0a77c4ecf93cf781f04cc467c974511.json: $0.0423\n",
      "  tid_94883aa2d583afced004e22a7991ef3e.json: $0.0416\n",
      "  tid_86fc91efde85f9a7a9e0f9786fc67404.json: $0.0410\n",
      "  tid_a50324f4d36f5cc93b795ec7f8b7005b.json: $0.0407\n",
      "  tid_43635104c2d64be16c8882a500dd5181.json: $0.0401\n",
      "  tid_837737698a5271d314ea8208addb2d72.json: $0.0397\n",
      "  tid_763e3011bc90e46c88c7a2953a39ed2a.json: $0.0390\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "LOG_DIR = Path(\"cache/trial_drug_roles_log\")\n",
    "\n",
    "total_cost = 0.0\n",
    "num_entries = 0\n",
    "costs = []\n",
    "\n",
    "for fp in LOG_DIR.glob(\"*.json\"):\n",
    "    try:\n",
    "        log = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "        c = float(log.get(\"total_cost\") or 0.0)\n",
    "        total_cost += c\n",
    "        costs.append((fp.name, c))\n",
    "        num_entries += 1\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {fp.name}: {e}\")\n",
    "\n",
    "# Sort descending by cost\n",
    "costs_sorted = sorted(costs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"========== LLM COST SUMMARY ==========\")\n",
    "print(f\"Total LLM cost:             ${total_cost:,.4f}\")\n",
    "print(f\"Number of logged trials:     {num_entries}\")\n",
    "if num_entries > 0:\n",
    "    print(f\"Average cost per trial:      ${total_cost / num_entries:,.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Top 10 most expensive trials:\")\n",
    "for name, c in costs_sorted[:10]:\n",
    "    print(f\"  {name}: ${c:,.4f}\")\n",
    "\n",
    "print(\"========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e313110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trial product breakdown to cache/trial_product_breakdown.csv\n",
      "|     | trial_hash                           | investigational_products                      | investigational_products_alternative_names                                                                                                                                                                                | investigational_products_molecular_target   | investigational_products_mechanism                                               | active_comparators   | active_comparators_alternative_names                                                                                                                                            | active_comparators_molecular_target   | active_comparators_mechanism                                 | placebos   | placebos_alternative_names   | placebos_molecular_target   | placebos_mechanism   | standard_of_care   | standard_of_care_alternative_names   | standard_of_care_molecular_target   | standard_of_care_mechanism   |\n",
      "|----:|:-------------------------------------|:----------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------|:---------------------------------------------------------------------------------|:---------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------|:-------------------------------------------------------------|:-----------|:-----------------------------|:----------------------------|:---------------------|:-------------------|:-------------------------------------|:------------------------------------|:-----------------------------|\n",
      "|  94 | tid_0541995757b10e613a42173d6b8ddc09 | ['Cinacalcet hydrochloride']                  | [['Cinacalcet HCl', 'Cinacalcet']]                                                                                                                                                                                        | ['Calcium-sensing receptor (CaSR)']         | ['Calcimimetic; allosteric modulator of CaSR']                                   | []                   | []                                                                                                                                                                              | []                                    | []                                                           | []         | []                           | []                          | []                   | []                 | []                                   | []                                  | []                           |\n",
      "|  64 | tid_0da20e863cfc5f3e369868462bff74e0 | ['NuPIAO']                                    | [['nupiao', 'recombinant erythropoietin stimulating protein', 'rESP', 'SSS-06', 'SSS06', 'SSS 06', 'recombinant erythropoietin stimulating protein, 3SBio', 'rESP, 3SBio', 'recombinant human erythropoietin injection']] | ['Erythropoietin receptor']                 | ['Erythropoietin receptor agonist']                                              | []                   | []                                                                                                                                                                              | []                                    | []                                                           | []         | []                           | []                          | []                   | []                 | []                                   | []                                  | []                           |\n",
      "| 144 | tid_0e8fa21079f928135dfc6164a15285f8 | ['SSS-17']                                    | [['SSS17', 'SSS 17', 'HIF 117', 'HIF-117', 'HIF117', '[14C] SSS17', '[14C]-SSS17', '[14C]SSS17']]                                                                                                                         | ['HIF']                                     | ['Hypoxia-inducible factor antagonist']                                          | []                   | []                                                                                                                                                                              | []                                    | []                                                           | []         | []                           | []                          | []                   | []                 | []                                   | []                                  | []                           |\n",
      "|  19 | tid_0f04ddb3d522d528d083d7d5c43d1e18 | ['Metformin hydrochloride sustained-release'] | [['metformin hydrochloride, Zhejiang Sunshine Mandi Pharmaceutical Co.', 'metformin HCl sustained-release', 'metformin hydrochloride SR', 'metformin XR']]                                                                | ['AMPK']                                    | ['Biguanide; insulin sensitizer; gluconeogenesis inhibitor']                     | ['Glucophage XR']    | [['Glucophage', 'Glucophage IR', 'Glifage XR', 'Dabex XR', 'Diabex', 'Diabex XR', 'Metgluco', 'Stagid', 'SMP-862', 'metformin hydrochloride, once-daily, BMS', 'metformin XR']] | ['AMPK']                              | ['Biguanide; insulin sensitizer; gluconeogenesis inhibitor'] | []         | []                           | []                          | []                   | []                 | []                                   | []                                  | []                           |\n",
      "|  17 | tid_10562c0430b8b9bae93c94cadfb0a129 | ['RD-01']                                     | [['RD001', 'RD 001', 'RD-001', 'RD01', 'Peg-EPO', 'Long-acting rhEPO']]                                                                                                                                                   | ['EPOR (erythropoietin receptor)']          | ['Erythropoiesis-stimulating agent; PEGylated recombinant human erythropoietin'] | []                   | []                                                                                                                                                                              | []                                    | []                                                           | []         | []                           | []                          | []                   | []                 | []                                   | []                                  | []                           |\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Build trial_product_breakdown.csv\n",
    "# -------------------------------------------------\n",
    "OUT_CSV = BASE_DIR / \"trial_product_breakdown.csv\"\n",
    "\n",
    "rows = []\n",
    "\n",
    "for fp in DRUG_ROLE_DIR.glob(\"*.json\"):\n",
    "    try:\n",
    "        obj = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {fp.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    trial_hash = obj.get(\"trial_hash\")\n",
    "    if not trial_hash:\n",
    "        print(f\"⚠️ Missing trial_hash in {fp.name}, skipping\")\n",
    "        continue\n",
    "\n",
    "    drug_roles = obj.get(\"drug_roles\") or {}\n",
    "    if not isinstance(drug_roles, dict):\n",
    "        print(f\"⚠️ drug_roles not dict in {fp.name}, skipping\")\n",
    "        continue\n",
    "\n",
    "    # Containers\n",
    "    inv_names = []\n",
    "    inv_alt_names = []          # list of lists\n",
    "    inv_targets = []\n",
    "    inv_mechanisms = []\n",
    "\n",
    "    ac_names = []\n",
    "    ac_alt_names = []           # list of lists\n",
    "    ac_targets = []\n",
    "    ac_mechanisms = []\n",
    "\n",
    "    plc_names = []\n",
    "    plc_alt_names = []          # list of lists\n",
    "    plc_targets = []\n",
    "    plc_mechanisms = []\n",
    "\n",
    "    soc_names = []\n",
    "    soc_alt_names = []          # list of lists\n",
    "    soc_targets = []\n",
    "    soc_mechanisms = []\n",
    "\n",
    "    for drug_name, meta in drug_roles.items():\n",
    "        if not isinstance(meta, dict):\n",
    "            continue\n",
    "\n",
    "        role = (meta.get(\"role\") or \"\").strip()\n",
    "        role_norm = role.lower()\n",
    "\n",
    "        alt_names = meta.get(\"alternative_names\") or []\n",
    "        if not isinstance(alt_names, list):\n",
    "            alt_names = [str(alt_names)]\n",
    "\n",
    "        molecular_target = meta.get(\"molecular_target\") or \"\"\n",
    "        mechanism = meta.get(\"mechanism\") or \"\"\n",
    "\n",
    "        if role_norm == \"investigational product\":\n",
    "            inv_names.append(drug_name)\n",
    "            inv_alt_names.append(alt_names)\n",
    "            inv_targets.append(molecular_target)\n",
    "            inv_mechanisms.append(mechanism)\n",
    "        elif role_norm == \"active comparator\":\n",
    "            ac_names.append(drug_name)\n",
    "            ac_alt_names.append(alt_names)\n",
    "            ac_targets.append(molecular_target)\n",
    "            ac_mechanisms.append(mechanism)\n",
    "        elif role_norm == \"placebo\":\n",
    "            plc_names.append(drug_name)\n",
    "            plc_alt_names.append(alt_names)\n",
    "            plc_targets.append(molecular_target)\n",
    "            plc_mechanisms.append(mechanism)\n",
    "        elif role_norm == \"standard of care\":\n",
    "            soc_names.append(drug_name)\n",
    "            soc_alt_names.append(alt_names)\n",
    "            soc_targets.append(molecular_target)\n",
    "            soc_mechanisms.append(mechanism)\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"trial_hash\": trial_hash,\n",
    "\n",
    "            \"investigational_products\": inv_names,\n",
    "            \"investigational_products_alternative_names\": inv_alt_names,\n",
    "            \"investigational_products_molecular_target\": inv_targets,\n",
    "            \"investigational_products_mechanism\": inv_mechanisms,\n",
    "\n",
    "            \"active_comparators\": ac_names,\n",
    "            \"active_comparators_alternative_names\": ac_alt_names,\n",
    "            \"active_comparators_molecular_target\": ac_targets,\n",
    "            \"active_comparators_mechanism\": ac_mechanisms,\n",
    "\n",
    "            \"placebos\": plc_names,\n",
    "            \"placebos_alternative_names\": plc_alt_names,\n",
    "            \"placebos_molecular_target\": plc_targets,\n",
    "            \"placebos_mechanism\": plc_mechanisms,\n",
    "\n",
    "            \"standard_of_care\": soc_names,\n",
    "            \"standard_of_care_alternative_names\": soc_alt_names,\n",
    "            \"standard_of_care_molecular_target\": soc_targets,\n",
    "            \"standard_of_care_mechanism\": soc_mechanisms,\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_out = pd.DataFrame(rows).sort_values(\"trial_hash\")\n",
    "\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved trial product breakdown to {OUT_CSV}\")\n",
    "print(df_out.head().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e0e24",
   "metadata": {},
   "source": [
    "Manually check the rows with no investigational products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca77eab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NO investigational products: 5 / 184\n",
      "| trial_hash                           | investigational_products   |\n",
      "|:-------------------------------------|:---------------------------|\n",
      "| tid_4c45730f6411aa1e5a38bb1223d66988 | []                         |\n",
      "| tid_67de51bf9728e056a6fb42c76e4b0212 | []                         |\n",
      "| tid_8cab7b7177fcb0d10255bced8b0633ee | []                         |\n",
      "| tid_bb1e0571142dde8a49976632c349593c | []                         |\n",
      "| tid_ed66bb2727de7173d74abf4af19f70e8 | []                         |\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "IN_CSV = BASE_DIR / \"trial_product_breakdown.csv\"\n",
    "\n",
    "df = pd.read_csv(IN_CSV, dtype=str).fillna(\"\")\n",
    "\n",
    "def parse_listish(s: str):\n",
    "    \"\"\"\n",
    "    Parse a stringified list like \"['A', 'B']\" into a Python list.\n",
    "    If parsing fails or the cell is empty, return [].\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "    s = s.strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    # Common empty-list cases\n",
    "    if s in (\"[]\", \"[ ]\"):\n",
    "        return []\n",
    "    try:\n",
    "        val = ast.literal_eval(s)\n",
    "        if isinstance(val, list):\n",
    "            return val\n",
    "        # If it's something else, treat as a single non-empty token\n",
    "        return [val]\n",
    "    except Exception:\n",
    "        # Fallback: treat non-empty string as a single element\n",
    "        return [s]\n",
    "\n",
    "# Parse the investigational_products column into real lists\n",
    "df[\"investigational_products_parsed\"] = df[\"investigational_products\"].apply(parse_listish)\n",
    "\n",
    "# Flag rows with no investigational products\n",
    "no_inv_mask = df[\"investigational_products_parsed\"].apply(lambda x: len(x) == 0)\n",
    "\n",
    "num_no_inv = int(no_inv_mask.sum())\n",
    "total = len(df)\n",
    "\n",
    "print(f\"Rows with NO investigational products: {num_no_inv} / {total}\")\n",
    "\n",
    "# Show a few examples\n",
    "print(\n",
    "    df.loc[no_inv_mask, [\"trial_hash\", \"investigational_products\"]]\n",
    "      .head(20)\n",
    "      .to_markdown(index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01ab97f",
   "metadata": {},
   "source": [
    "Manual checks \n",
    "- tid_4c45730f6411aa1e5a38bb1223d66988\n",
    "    - This trial is combining three standard-of-care agents into a regimen “DCF”\n",
    "- tid_67de51bf9728e056a6fb42c76e4b0212\n",
    "    - Even though they administer Yisaipu in a structured way, it is an approved drug and not being tested for regulatory approval.\n",
    "- tid_8cab7b7177fcb0d10255bced8b0633ee\n",
    "    - The trial is studying treatment strategies, regimens, algorithms, imaging-guided regimen selection, or dosing, using only approved standard therapies.\n",
    "- tid_bb1e0571142dde8a49976632c349593c\n",
    "    - The trial's focus is on optimizing regimen selection (e.g., TIPy or TCbIPy) via imaging, rather than testing a new drug entity.\n",
    "- tid_ed66bb2727de7173d74abf4af19f70e8\n",
    "    - evaluates the safety and efficacy of 3SBio's EPIAO (a biosimilar epoetin alfa/recombinant human erythropoietin) for cancer-related anemia\n",
    "\n",
    "these are all confirmed generics biosimilars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47323055",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "\n",
    "Identify whether the drugs are innovative or/generic biosimilars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52a5c1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 179 trials with investigational products for innovation-status classification.\n",
      "✅ Trial investigational-drug innovation classification complete. processed=0, skipped=179, llm_error=0, parse_error=0, coverage_error=0\n",
      "Classifications directory: cache/trial_investigational_drugs_classifications\n",
      "Log directory:             cache/trial_investigational_drugs_classifications_log\n",
      "Master classifications:    cache/trial_investigational_drugs_classifications_master.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from services.openai_wrapper import OpenAIWrapper\n",
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------------------------\n",
    "BASE_DIR = Path(\"cache\")\n",
    "\n",
    "TRIALS_WITH_HASH_CSV    = BASE_DIR / \"raw_trials_with_hash.csv\"\n",
    "PRODUCT_BREAKDOWN_CSV   = BASE_DIR / \"trial_product_breakdown.csv\"\n",
    "\n",
    "INNOV_DIR = BASE_DIR / \"trial_investigational_drugs_classifications\"\n",
    "INNOV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INNOV_LOG_DIR = BASE_DIR / \"trial_investigational_drugs_classifications_log\"\n",
    "INNOV_LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MASTER_INNOV_PATH = BASE_DIR / \"trial_investigational_drugs_classifications_master.json\"\n",
    "\n",
    "RELEVANT_COLS = [\n",
    "    \"title\",\n",
    "    \"objective\",\n",
    "    \"outcome_details\",\n",
    "    \"notes_json\",\n",
    "    \"results_json\",\n",
    "    \"primary_drugs_tested_json\",\n",
    "    \"other_drugs_tested_json\",\n",
    "    \"therapeutic_areas_json\",\n",
    "    \"bmt_other_drugs_tested_json\",\n",
    "    \"bmt_primary_drugs_tested_json\",\n",
    "    \"ct_gov_mesh_terms_json\",\n",
    "]\n",
    "\n",
    "MAX_WORKERS_INNOV = 8\n",
    "\n",
    "MODEL = \"gpt-5\"\n",
    "client = OpenAIWrapper()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Helpers\n",
    "# -------------------------------------------------\n",
    "def load_master_innov() -> dict:\n",
    "    if not MASTER_INNOV_PATH.exists():\n",
    "        return {}\n",
    "    try:\n",
    "        return json.loads(MASTER_INNOV_PATH.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def extract_json_object(text: str) -> dict:\n",
    "    \"\"\"Extract first valid JSON object from model output.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return {}\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return {}\n",
    "\n",
    "    # Direct parse first\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: first {...} region\n",
    "    m = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        return {}\n",
    "    try:\n",
    "        obj = json.loads(m.group(0))\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    return {}\n",
    "\n",
    "def parse_listish(s: str):\n",
    "    \"\"\"\n",
    "    Parse a stringified list like \"['A', 'B']\" into a Python list.\n",
    "    If parsing fails or the cell is empty, return [].\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "    s = s.strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    # Common empty-list cases\n",
    "    if s in (\"[]\", \"[ ]\"):\n",
    "        return []\n",
    "    try:\n",
    "        val = ast.literal_eval(s)\n",
    "        if isinstance(val, list):\n",
    "            return val\n",
    "        # If it's something else, treat as a single non-empty token\n",
    "        return [val]\n",
    "    except Exception:\n",
    "        # Fallback: treat non-empty string as a single element\n",
    "        return [s]\n",
    "\n",
    "master_innov = load_master_innov()\n",
    "master_lock = threading.Lock()\n",
    "\n",
    "innov_counter = {\n",
    "    \"processed\": 0,\n",
    "    \"skipped_existing\": 0,\n",
    "    \"llm_error\": 0,\n",
    "    \"parse_error\": 0,\n",
    "    \"coverage_error\": 0,\n",
    "}\n",
    "counter_lock = threading.Lock()\n",
    "\n",
    "\n",
    "def build_innovation_prompt(trial_payload: dict, investigational_products: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Build prompt to classify each investigational product as\n",
    "    Innovative / Generic / Biosimilar, with one-sentence explanation.\n",
    "    \"\"\"\n",
    "    payload_json = json.dumps(trial_payload, ensure_ascii=False, indent=2)\n",
    "    drugs_json   = json.dumps(investigational_products, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a clinical trial design and drug development expert.\n",
    "\n",
    "You are given:\n",
    "1) Structured information about a clinical trial (title, objective, results, etc.).\n",
    "2) A list of investigational products used in the trial.\n",
    "3) Structured fields describing how drugs are classified in the study\n",
    "   (investigational_products, active_comparators, placebos, standard_of_care, etc.).\n",
    "\n",
    "Your task: For EACH investigational product, classify whether it is:\n",
    "- \"Innovative\"\n",
    "- \"Generic\"\n",
    "- \"Biosimilar\"\n",
    "\n",
    "and provide a one-sentence concise explanation for your classification.\n",
    "\n",
    "DEFINITIONS / GUIDANCE\n",
    "----------------------\n",
    "\n",
    "Innovative:\n",
    "- A novel or proprietary drug.\n",
    "- New mechanism of action OR new biological entity OR clearly sponsor's lead product.\n",
    "- Often associated with superiority or efficacy language:\n",
    "  - \"evaluate efficacy\", \"vs placebo\", \"improve outcomes\", etc.\n",
    "- Not a copy of an already-approved product.\n",
    "\n",
    "Generic:\n",
    "- A small-molecule copy of an already-approved branded drug.\n",
    "- Same active ingredient, strength, dosage form, and route.\n",
    "- Often associated with:\n",
    "  - language like \"generic\", \"copy\", \"equivalent\",\n",
    "  - OR clear indication that the product is a non-branded version.\n",
    "\n",
    "Biosimilar:\n",
    "- A biologic product that is highly similar to an already-approved reference biologic.\n",
    "- Same target and mechanism as a branded biologic.\n",
    "- Strong clues:\n",
    "  - \"equivalence\", \"non-inferiority\", \"no clinically meaningful differences\",\n",
    "  - direct comparison to a specific branded reference biologic with the SAME active ingredient.\n",
    "\n",
    "Task 2 — Classify Innovation Status\n",
    "-----------------------------------\n",
    "\n",
    "Use clues within the text to determine whether each investigational drug is:\n",
    "- \"Innovative\"\n",
    "- \"Generic\"\n",
    "- \"Biosimilar\"\n",
    "\n",
    "Examples of helpful cues:\n",
    "- Innovative:\n",
    "  - Superiority/efficacy language (\"versus placebo\", \"evaluate efficacy\").\n",
    "  - Novel or advanced mechanism, new target, or first-in-class description.\n",
    "- Biosimilar:\n",
    "  - Equivalence or non-inferiority language.\n",
    "  - Direct comparison to a branded reference product with the same active ingredient.\n",
    "- Generic:\n",
    "  - Explicitly described as generic.\n",
    "  - Non-biologic small-molecule copy of an existing branded product.\n",
    "\n",
    "If the information is incomplete, choose the MOST LIKELY label based on the text and typical drug naming patterns.\n",
    "You MUST still choose ONE of the three labels (\"Innovative\", \"Generic\", \"Biosimilar\") for each drug.\n",
    "If you are uncertain, you may say so in the one-sentence explanation.\n",
    "\n",
    "OUTPUT FORMAT (IMPORTANT)\n",
    "-------------------------\n",
    "\n",
    "Return ONLY a valid JSON object, with:\n",
    "- KEYS   = exactly the investigational product names as provided in the list below\n",
    "- VALUES = an object with exactly two fields:\n",
    "    - \"classification\": one of \"Innovative\", \"Generic\", \"Biosimilar\"\n",
    "    - \"explanation\": a single, concise sentence explaining your reasoning\n",
    "\n",
    "You MUST provide a classification for EVERY investigational product name.\n",
    "\n",
    "Example output:\n",
    "{{\n",
    "  \"DrugA\": {{\n",
    "    \"classification\": \"Innovative\",\n",
    "    \"explanation\": \"DrugA is a novel monoclonal antibody targeting a new receptor and is the sponsor's lead product.\"\n",
    "  }},\n",
    "  \"DrugB\": {{\n",
    "    \"classification\": \"Biosimilar\",\n",
    "    \"explanation\": \"DrugB is tested for non-inferiority compared to the branded biologic with the same target.\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "TRIAL PAYLOAD (includes trial text and all drug-role breakdown columns):\n",
    "{payload_json}\n",
    "\n",
    "INVESTIGATIONAL PRODUCTS (you MUST classify EACH of these):\n",
    "{drugs_json}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def process_innov_row(row: dict, idx: int, total: int, breakdown_cols: list[str]) -> None:\n",
    "    \"\"\"Process a single trial with investigational products.\"\"\"\n",
    "    trial_hash = str(row.get(\"trial_hash\", \"\")).strip()\n",
    "    if not trial_hash:\n",
    "        print(f\"⚠️ [{idx}/{total}] Missing trial_hash, skipping\")\n",
    "        return\n",
    "\n",
    "    investigational_products = row.get(\"investigational_products_parsed\") or []\n",
    "    investigational_products = [str(x).strip() for x in investigational_products if str(x).strip()]\n",
    "\n",
    "    if not investigational_products:\n",
    "        # Shouldn't happen due to filtering, but be safe\n",
    "        return\n",
    "\n",
    "    out_fp = INNOV_DIR / f\"{trial_hash}.json\"\n",
    "    if out_fp.exists():\n",
    "        with counter_lock:\n",
    "            innov_counter[\"skipped_existing\"] += 1\n",
    "        return\n",
    "\n",
    "    # Build payload from selected columns\n",
    "    trial_payload = {\"trial_hash\": trial_hash}\n",
    "\n",
    "    # 1) Trial-level textual fields from raw_trials_with_hash.csv\n",
    "    for col in RELEVANT_COLS:\n",
    "        trial_payload[col] = row.get(col, \"\")\n",
    "\n",
    "    # 2) ALL columns from trial_product_breakdown.csv\n",
    "    for col in breakdown_cols:\n",
    "        trial_payload[col] = row.get(col, \"\")\n",
    "\n",
    "    prompt = build_innovation_prompt(trial_payload, investigational_products)\n",
    "\n",
    "    token = trial_hash\n",
    "    hash_id = trial_hash\n",
    "\n",
    "    text_response = \"\"\n",
    "    raw_response = None\n",
    "    total_cost = 0.0\n",
    "    elapsed = 0.0\n",
    "\n",
    "    # Call LLM\n",
    "    try:\n",
    "        t0 = time.perf_counter()\n",
    "        res = client.query(prompt=prompt, model=MODEL)\n",
    "        elapsed = round(time.perf_counter() - t0, 2)\n",
    "\n",
    "        text_response = (res.get(\"text_response\") or \"\").strip()\n",
    "        raw_response = res.get(\"raw_response\")\n",
    "        total_cost = float(res.get(\"cost\") or 0.0)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ [{idx}/{total}] LLM error for trial_hash={trial_hash}: {e}\")\n",
    "        with counter_lock:\n",
    "            innov_counter[\"llm_error\"] += 1\n",
    "        return\n",
    "\n",
    "    # Parse JSON\n",
    "    classifications = extract_json_object(text_response)\n",
    "\n",
    "    if not isinstance(classifications, dict) or not classifications:\n",
    "        print(f\"⚠️ [{idx}/{total}] JSON parse error trial_hash={trial_hash}, raw={text_response!r}\")\n",
    "        with counter_lock:\n",
    "            innov_counter[\"parse_error\"] += 1\n",
    "        return\n",
    "\n",
    "    # Check coverage: every investigational product must be present as a key\n",
    "    missing = [d for d in investigational_products if d not in classifications]\n",
    "    if missing:\n",
    "        print(\n",
    "            f\"⚠️ [{idx}/{total}] Coverage error for trial_hash={trial_hash}: \"\n",
    "            f\"missing classifications for {missing}\"\n",
    "        )\n",
    "        with counter_lock:\n",
    "            innov_counter[\"coverage_error\"] += 1\n",
    "        # DO NOT save this trial so it can be re-run next time\n",
    "        return\n",
    "\n",
    "    # Optional: sanity check that each value has classification + explanation\n",
    "    for d in investigational_products:\n",
    "        meta = classifications.get(d, {})\n",
    "        if not isinstance(meta, dict):\n",
    "            print(f\"⚠️ [{idx}/{total}] Invalid meta for {d} in trial_hash={trial_hash}\")\n",
    "            with counter_lock:\n",
    "                innov_counter[\"parse_error\"] += 1\n",
    "            return\n",
    "        if \"classification\" not in meta or \"explanation\" not in meta:\n",
    "            print(f\"⚠️ [{idx}/{total}] Missing fields for {d} in trial_hash={trial_hash}\")\n",
    "            with counter_lock:\n",
    "                innov_counter[\"parse_error\"] += 1\n",
    "            return\n",
    "\n",
    "    mapped = {\n",
    "        \"trial_hash\": trial_hash,\n",
    "        \"investigational_products\": investigational_products,\n",
    "        \"classifications\": classifications,\n",
    "        \"source\": \"llm\",\n",
    "    }\n",
    "\n",
    "    # Save per-trial JSON\n",
    "    out_fp.write_text(json.dumps(mapped, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    # Log entry\n",
    "    log_payload = {\n",
    "        \"token\": token,\n",
    "        \"hash_id\": hash_id,\n",
    "        \"model\": MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"structured_response\": json.dumps(mapped, ensure_ascii=False, indent=2),\n",
    "        \"raw_response\": repr(raw_response),\n",
    "        \"total_cost\": total_cost,\n",
    "        \"time_elapsed\": elapsed,\n",
    "    }\n",
    "    (INNOV_LOG_DIR / f\"{hash_id}.json\").write_text(\n",
    "        json.dumps(log_payload, ensure_ascii=False, indent=2),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "    # Update master\n",
    "    with master_lock:\n",
    "        master_innov[trial_hash] = mapped\n",
    "        MASTER_INNOV_PATH.write_text(\n",
    "            json.dumps(master_innov, ensure_ascii=False, indent=2),\n",
    "            encoding=\"utf-8\"\n",
    "        )\n",
    "\n",
    "    with counter_lock:\n",
    "        innov_counter[\"processed\"] += 1\n",
    "        if innov_counter[\"processed\"] % 50 == 0:\n",
    "            print(f\"Progress: processed {innov_counter['processed']} trials for innovation status...\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# LOAD & MERGE DATA\n",
    "# -------------------------------------------------\n",
    "# Load breakdown (investigational products + all drug-role cols)\n",
    "df_breakdown = pd.read_csv(PRODUCT_BREAKDOWN_CSV, dtype=str).fillna(\"\")\n",
    "\n",
    "# Reuse parse_listish from previous cell\n",
    "df_breakdown[\"investigational_products_parsed\"] = df_breakdown[\"investigational_products\"].apply(parse_listish)\n",
    "mask_has_inv = df_breakdown[\"investigational_products_parsed\"].apply(lambda x: len(x) > 0)\n",
    "\n",
    "# Restrict to rows with investigational products\n",
    "df_breakdown_sub = df_breakdown.loc[mask_has_inv].copy()\n",
    "\n",
    "# All columns from trial_product_breakdown.csv except trial_hash (which is already separate)\n",
    "BREAKDOWN_COLS = [c for c in df_breakdown_sub.columns if c != \"trial_hash\"]\n",
    "\n",
    "# Load raw trials (for RELEVANT_COLS)\n",
    "df_trials = pd.read_csv(TRIALS_WITH_HASH_CSV, dtype=str).fillna(\"\")\n",
    "\n",
    "# Merge on trial_hash; keep all breakdown columns + investigational_products_parsed + RELEVANT_COLS\n",
    "df_merged = df_breakdown_sub.merge(\n",
    "    df_trials[[\"trial_hash\"] + RELEVANT_COLS],\n",
    "    on=\"trial_hash\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "innov_rows = df_merged.to_dict(orient=\"records\")\n",
    "total_innov = len(innov_rows)\n",
    "print(f\"Loaded {total_innov} trials with investigational products for innovation-status classification.\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# RUN CONCURRENTLY\n",
    "# -------------------------------------------------\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS_INNOV) as ex:\n",
    "    futures = {\n",
    "        ex.submit(process_innov_row, row, idx, total_innov, BREAKDOWN_COLS): row.get(\"trial_hash\")\n",
    "        for idx, row in enumerate(innov_rows, start=1)\n",
    "    }\n",
    "    for fut in as_completed(futures):\n",
    "        th = futures[fut]\n",
    "        try:\n",
    "            fut.result()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Worker error (innovation) trial_hash={th}: {e}\")\n",
    "\n",
    "print(\n",
    "    f\"✅ Trial investigational-drug innovation classification complete. \"\n",
    "    f\"processed={innov_counter['processed']}, \"\n",
    "    f\"skipped={innov_counter['skipped_existing']}, \"\n",
    "    f\"llm_error={innov_counter['llm_error']}, \"\n",
    "    f\"parse_error={innov_counter['parse_error']}, \"\n",
    "    f\"coverage_error={innov_counter['coverage_error']}\"\n",
    ")\n",
    "print(f\"Classifications directory: {INNOV_DIR}\")\n",
    "print(f\"Log directory:             {INNOV_LOG_DIR}\")\n",
    "print(f\"Master classifications:    {MASTER_INNOV_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c10a2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== LLM COST SUMMARY ==========\n",
      "Total LLM cost:             $2.0853\n",
      "Number of logged trials:     179\n",
      "Average cost per trial:      $0.0116\n",
      "\n",
      "Top 10 most expensive trials:\n",
      "  tid_8b4d60a5fddc078962af34399d7e342c.json: $0.0277\n",
      "  tid_9727cefa81bf0a9c341273bce42d3346.json: $0.0254\n",
      "  tid_fc93655913a5e1b233a8077e9fc758c6.json: $0.0226\n",
      "  tid_a1c1e47263bd9f338f83e52f97565ff1.json: $0.0222\n",
      "  tid_b29013cdbc706b95776d47be1d6e98e6.json: $0.0219\n",
      "  tid_94883aa2d583afced004e22a7991ef3e.json: $0.0208\n",
      "  tid_9dc4ace9308864c9f8a619d6abe32011.json: $0.0207\n",
      "  tid_99fac3ebe48aad5ebc1077142f61d5eb.json: $0.0205\n",
      "  tid_4f644d4f81a34d114e8e22321d3af440.json: $0.0187\n",
      "  tid_a50324f4d36f5cc93b795ec7f8b7005b.json: $0.0186\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "LOG_DIR = Path(\"cache/trial_investigational_drugs_classifications_log\")\n",
    "\n",
    "total_cost = 0.0\n",
    "num_entries = 0\n",
    "costs = []\n",
    "\n",
    "for fp in LOG_DIR.glob(\"*.json\"):\n",
    "    try:\n",
    "        log = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "        c = float(log.get(\"total_cost\") or 0.0)\n",
    "        total_cost += c\n",
    "        costs.append((fp.name, c))\n",
    "        num_entries += 1\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {fp.name}: {e}\")\n",
    "\n",
    "# Sort descending by cost\n",
    "costs_sorted = sorted(costs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"========== LLM COST SUMMARY ==========\")\n",
    "print(f\"Total LLM cost:             ${total_cost:,.4f}\")\n",
    "print(f\"Number of logged trials:     {num_entries}\")\n",
    "if num_entries > 0:\n",
    "    print(f\"Average cost per trial:      ${total_cost / num_entries:,.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Top 10 most expensive trials:\")\n",
    "for name, c in costs_sorted[:10]:\n",
    "    print(f\"  {name}: ${c:,.4f}\")\n",
    "\n",
    "print(\"========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bebf824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved investigational drug classifications to cache/trial_investigational_drugs_classifications.csv\n",
      "| trial_hash                           | investigational_products                      | investigational_products_classifications   |\n",
      "|:-------------------------------------|:----------------------------------------------|:-------------------------------------------|\n",
      "| tid_0541995757b10e613a42173d6b8ddc09 | [\"Cinacalcet hydrochloride\"]                  | [\"Generic\"]                                |\n",
      "| tid_0da20e863cfc5f3e369868462bff74e0 | [\"NuPIAO\"]                                    | [\"Innovative\"]                             |\n",
      "| tid_0e8fa21079f928135dfc6164a15285f8 | [\"SSS-17\"]                                    | [\"Innovative\"]                             |\n",
      "| tid_0f04ddb3d522d528d083d7d5c43d1e18 | [\"Metformin hydrochloride sustained-release\"] | [\"Generic\"]                                |\n",
      "| tid_10562c0430b8b9bae93c94cadfb0a129 | [\"RD-01\"]                                     | [\"Innovative\"]                             |\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "OUT_CSV = BASE_DIR / \"trial_investigational_drugs_classifications.csv\"\n",
    "\n",
    "rows = []\n",
    "\n",
    "for fp in INNOV_DIR.glob(\"*.json\"):\n",
    "    try:\n",
    "        obj = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {fp.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    trial_hash = obj.get(\"trial_hash\")\n",
    "    if not trial_hash:\n",
    "        print(f\"⚠️ Missing trial_hash in {fp.name}, skipping\")\n",
    "        continue\n",
    "\n",
    "    inv_products_raw = obj.get(\"investigational_products\") or []\n",
    "    classifications_map = obj.get(\"classifications\") or {}\n",
    "\n",
    "    flat_products = []\n",
    "    flat_classifications = []\n",
    "\n",
    "    for drug_raw in inv_products_raw:\n",
    "        # drug_raw might be \"['inetetamab', 'toripalimab']\" or just \"SSGJ-707\"\n",
    "        if isinstance(drug_raw, str):\n",
    "            parsed_names = parse_listish(drug_raw)  # from earlier cell (uses ast.literal_eval)\n",
    "        else:\n",
    "            parsed_names = [drug_raw]\n",
    "\n",
    "        # Prefer classification using the exact key that was sent to the model\n",
    "        meta = classifications_map.get(drug_raw, {})\n",
    "        cls = meta.get(\"classification\", \"\")\n",
    "\n",
    "        # If not found, try each parsed name as a key\n",
    "        if not cls:\n",
    "            for name in parsed_names:\n",
    "                meta_n = classifications_map.get(name, {})\n",
    "                if \"classification\" in meta_n:\n",
    "                    cls = meta_n.get(\"classification\", \"\")\n",
    "                    break\n",
    "\n",
    "        if not cls:\n",
    "            print(\n",
    "                f\"⚠️ Missing classification for raw drug {drug_raw!r} in \"\n",
    "                f\"trial_hash={trial_hash}, file={fp.name}\"\n",
    "            )\n",
    "\n",
    "        # Add one entry per parsed name so both lists are flat and aligned\n",
    "        for name in parsed_names:\n",
    "            flat_products.append(name)\n",
    "            flat_classifications.append(cls)\n",
    "\n",
    "    # Sanity check: lengths must match\n",
    "    if len(flat_products) != len(flat_classifications):\n",
    "        print(\n",
    "            f\"⚠️ Length mismatch for trial_hash={trial_hash}: \"\n",
    "            f\"{len(flat_products)} products vs {len(flat_classifications)} classifications\"\n",
    "        )\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"trial_hash\": trial_hash,\n",
    "            # store as JSON stringified flat lists\n",
    "            \"investigational_products\": json.dumps(flat_products, ensure_ascii=False),\n",
    "            \"investigational_products_classifications\": json.dumps(flat_classifications, ensure_ascii=False),\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_out = pd.DataFrame(rows).sort_values(\"trial_hash\")\n",
    "\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"✅ Saved investigational drug classifications to {OUT_CSV}\")\n",
    "print(df_out.head().to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a96291d",
   "metadata": {},
   "source": [
    "#### Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e55d32",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f9e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
