{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff4ae34",
   "metadata": {},
   "source": [
    "#### Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f9a86",
   "metadata": {},
   "source": [
    "Load raw trial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97784b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"data/raw_trials.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e73a1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'objective', 'outcome_details', 'phase',\n",
      "       'primary_completion_date', 'primary_endpoints_reported_date',\n",
      "       'prior_concurrent_therapy', 'start_date', 'study_design',\n",
      "       'treatment_plan', 'record_type', 'patients_per_site_per_month',\n",
      "       'primary_endpoint_json', 'other_endpoint_json', 'associated_cro_json',\n",
      "       'notes_json', 'outcomes_json', 'patient_dispositions_json',\n",
      "       'results_json', 'study_keywords_json', 'tags_json',\n",
      "       'primary_drugs_tested_json', 'other_drugs_tested_json',\n",
      "       'therapeutic_areas_json', 'bmt_other_drugs_tested_json',\n",
      "       'bmt_primary_drugs_tested_json', 'ct_gov_listed_locations_json',\n",
      "       'ct_gov_mesh_terms_json'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b69802af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                                 |   0 |\n",
      "|:--------------------------------|----:|\n",
      "| title                           |   0 |\n",
      "| objective                       |   3 |\n",
      "| outcome_details                 | 146 |\n",
      "| phase                           |   0 |\n",
      "| primary_completion_date         |  61 |\n",
      "| primary_endpoints_reported_date | 161 |\n",
      "| prior_concurrent_therapy        | 184 |\n",
      "| start_date                      |  45 |\n",
      "| study_design                    |  16 |\n",
      "| treatment_plan                  |   1 |\n",
      "| record_type                     |   0 |\n",
      "| patients_per_site_per_month     | 119 |\n",
      "| primary_endpoint_json           |   0 |\n",
      "| other_endpoint_json             |   0 |\n",
      "| associated_cro_json             |   0 |\n",
      "| notes_json                      |   0 |\n",
      "| outcomes_json                   |   0 |\n",
      "| patient_dispositions_json       |   0 |\n",
      "| results_json                    |   0 |\n",
      "| study_keywords_json             |   0 |\n",
      "| tags_json                       |   0 |\n",
      "| primary_drugs_tested_json       |   0 |\n",
      "| other_drugs_tested_json         |   0 |\n",
      "| therapeutic_areas_json          |   0 |\n",
      "| bmt_other_drugs_tested_json     |   0 |\n",
      "| bmt_primary_drugs_tested_json   |   0 |\n",
      "| ct_gov_listed_locations_json    |   0 |\n",
      "| ct_gov_mesh_terms_json          |   0 |\n",
      "Shape: (184, 28)\n"
     ]
    }
   ],
   "source": [
    "print(data.isna().sum().to_markdown())\n",
    "print(\"Shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d278e",
   "metadata": {},
   "source": [
    "Generate unique hash per trial since trial id is missing\n",
    "- i.e. \"tid_0e8fa21079f928135dfc6164a15285f8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6897de1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ cache/raw_trials_with_hash.csv already exists — skipping hash generation.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "OUTPUT_PATH = Path(\"cache/raw_trials_with_hash.csv\")\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# If file already exists → skip generation\n",
    "# ---------------------------------------------------------\n",
    "if OUTPUT_PATH.exists():\n",
    "    print(f\"⚠️ {OUTPUT_PATH} already exists — skipping hash generation.\")\n",
    "else:\n",
    "    print(\"Generating raw_trials_with_hash.csv ...\")\n",
    "\n",
    "    def make_trial_hash(row):\n",
    "        \"\"\"\n",
    "        Deterministic hash for a trial based on stable fields.\n",
    "        You can add/remove fields if needed.\n",
    "        \"\"\"\n",
    "        payload = {\n",
    "            \"title\": row.get(\"title\", \"\"),\n",
    "            \"start_date\": row.get(\"start_date\", \"\"),\n",
    "            \"phase\": row.get(\"phase\", \"\"),\n",
    "        }\n",
    "        raw = json.dumps(payload, sort_keys=True, ensure_ascii=False)\n",
    "        return \"tid_\" + hashlib.md5(raw.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "    # Create trial_hash column\n",
    "    data[\"trial_hash\"] = data.apply(make_trial_hash, axis=1)\n",
    "\n",
    "    # Move trial_hash to first column\n",
    "    cols = [\"trial_hash\"] + [c for c in data.columns if c != \"trial_hash\"]\n",
    "    data = data[cols]\n",
    "\n",
    "    print(data.columns)\n",
    "    print(data.shape)\n",
    "\n",
    "    # Export\n",
    "    data.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"Saved to {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14351eb6",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "\n",
    "Using a chatbot, identify all interventions from each trial. For each intervention...\n",
    "- label as the investigational product, active comparator, or placebo\n",
    "- list all of the alternative names\n",
    "- identify the molecular target \n",
    "- identify the mechanism of action\n",
    "- for investigational products\n",
    "    - trial trove drug id\n",
    "    - biomedtracker drug id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "efb4f1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 184 trials from cache/raw_trials_with_hash.csv\n",
      "Trial drug-role mapping complete. processed=0, skipped=184, llm_error=0, parse_error=0\n",
      "Roles directory: cache/trial_drug_roles\n",
      "Log directory:   cache/trial_drug_roles_log\n",
      "Master roles:    cache/trial_drug_roles_master.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import pandas as pd\n",
    "from services.openai_wrapper import OpenAIWrapper\n",
    "\n",
    "# -------------------------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------------------------\n",
    "BASE_DIR = Path(\"cache\")\n",
    "\n",
    "TRIALS_WITH_HASH_CSV = Path(\"cache/raw_trials_with_hash.csv\")\n",
    "\n",
    "DRUG_ROLE_DIR = BASE_DIR / \"trial_drug_roles\"\n",
    "DRUG_ROLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DRUG_ROLE_LOG_DIR = BASE_DIR / \"trial_drug_roles_log\"\n",
    "DRUG_ROLE_LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MASTER_ROLES_PATH = BASE_DIR / \"trial_drug_roles_master.json\"\n",
    "\n",
    "MODEL = \"gpt-5\"\n",
    "client = OpenAIWrapper()\n",
    "\n",
    "MAX_WORKERS = 8\n",
    "\n",
    "# Columns to feed into the chatbot\n",
    "RELEVANT_COLS = [\n",
    "    \"title\",\n",
    "    \"objective\",\n",
    "    \"outcome_details\",\n",
    "    \"treatment_plan\",\n",
    "    \"notes_json\",\n",
    "    \"results_json\",\n",
    "    \"primary_drugs_tested_json\",\n",
    "    \"other_drugs_tested_json\",\n",
    "    \"therapeutic_areas_json\",\n",
    "    \"bmt_other_drugs_tested_json\",\n",
    "    \"bmt_primary_drugs_tested_json\",\n",
    "    \"ct_gov_mesh_terms_json\",\n",
    "]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Helpers\n",
    "# -------------------------------------------------\n",
    "def extract_json_object(text: str) -> dict:\n",
    "    \"\"\"Extract first valid JSON object from model output.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return {}\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return {}\n",
    "\n",
    "    # Direct parse first\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: first {...} region\n",
    "    m = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        return {}\n",
    "    try:\n",
    "        obj = json.loads(m.group(0))\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    return {}\n",
    "\n",
    "\n",
    "def build_prompt(trial_payload: dict) -> str:\n",
    "    \"\"\"\n",
    "    Build prompt asking the LLM to:\n",
    "    - Extract drug names\n",
    "    - Canonicalize names by removing company/manufacturer/location qualifiers\n",
    "    - Deduplicate synonymous names\n",
    "    - For each canonical drug, return a dict with:\n",
    "        * role (Investigational Product / Placebo / Active Comparator / Standard of Care)\n",
    "        * alternative_names (list)\n",
    "        * molecular_target\n",
    "        * mechanism\n",
    "        * tt_drug_id (TrialTrove/PharmaProjects drugId as string)\n",
    "        * bmt_drug_id (BioMedTracker bmtDrugId as string)\n",
    "    \"\"\"\n",
    "    payload_json = json.dumps(trial_payload, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a clinical trial design and interpretation expert.\n",
    "\n",
    "You are given structured information about a clinical trial, including:\n",
    "- Title and objective\n",
    "- Study design and treatment plan\n",
    "- JSON fields listing drugs tested in the study:\n",
    "  - primary_drugs_tested_json\n",
    "  - other_drugs_tested_json\n",
    "  - bmt_other_drugs_tested_json\n",
    "  - bmt_primary_drugs_tested_json\n",
    "- These JSON fields may also contain metadata such as\n",
    "  drugApprovalStatus (Approved / Unapproved), mechanisms, synonyms, etc.\n",
    "- In the TrialTrove/PharmaProjects JSON blocks, the unique drug identifier\n",
    "  is usually under a key like \"drugId\".\n",
    "- In the BioMedTracker JSON blocks, the unique drug identifier\n",
    "  is usually under a key like \"bmtDrugId\".\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "1. Identify all DISTINCT physical drug entities explicitly used in the study.\n",
    "   - Strings in the *_drugs_tested_json fields are drug-name candidates.\n",
    "   - If these fields contain structured JSON, infer names from keys such as\n",
    "     \"name\", \"drug_name\", \"drugName\", \"drugPrimaryName\", \"preferred_name\",\n",
    "     \"label\", etc.\n",
    "\n",
    "2. Canonicalize each drug name:\n",
    "   Remove company names, manufacturer qualifiers, geographic qualifiers,\n",
    "   dosage-form qualifiers, or parenthetical descriptors that do NOT change\n",
    "   the name of the underlying drug.\n",
    "\n",
    "   Examples:\n",
    "   - \"AlphaBlocker (CompanyX)\" → \"AlphaBlocker\"\n",
    "   - \"Recombinant Growth Factor (rgf)\" → \"Recombinant Growth Factor\"\n",
    "   - \"DrugX citrate (RegionY)\" → \"DrugX citrate\"\n",
    "   - \"BrandName (compound-42, MakerCorp)\" → \"BrandName\"\n",
    "\n",
    "3. Deduplicate synonymous names referring to the SAME drug.\n",
    "   - Prefer the simplest, most standard canonical name.\n",
    "   - Collect all other variations under alternative_names.\n",
    "\n",
    "4. For EACH distinct drug, build an object with SIX fields:\n",
    "\n",
    "   • \"role\": one of:\n",
    "       - \"Investigational Product\"\n",
    "       - \"Placebo\"\n",
    "       - \"Active Comparator\"\n",
    "       - \"Standard of Care\"\n",
    "\n",
    "     ROLE ASSIGNMENT RULES:\n",
    "     A. \"Investigational Product\": sponsor's novel/proprietary product.\n",
    "     B. \"Standard of Care\": widely used backbone treatments.\n",
    "     C. \"Active Comparator\": explicit non-placebo comparator.\n",
    "     D. \"Placebo\": inert controls.\n",
    "\n",
    "   • \"alternative_names\": list of synonymous variants.\n",
    "   • \"molecular_target\": e.g., \"CD20\", \"VEGF-A\". If unknown, \"\".\n",
    "   • \"mechanism\": e.g., \"monoclonal antibody\", \"kinase inhibitor\". If unknown, \"\".\n",
    "   • \"tt_drug_id\": STRING. If not confidently matchable, \"\".\n",
    "   • \"bmt_drug_id\": STRING. If not confidently matchable, \"\".\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "MISMAPPING SAFETY RULE (CRITICAL — NEW REQUIREMENT)\n",
    "--------------------------------------------------------------------\n",
    "\n",
    "You MUST NOT assign a tt_drug_id or bmt_drug_id if:\n",
    "\n",
    "- The ID corresponds to a completely different drug\n",
    "  (e.g., Citeline mapped “Inetetamab” to Inotuzumab, or “601” to GLP-1 AER-601).\n",
    "- The mechanism, target, indication, route, or class contradicts the trial text.\n",
    "- The name similarity is superficial but the drugs are unrelated.\n",
    "- The drugId or bmtDrugId belongs to a medication with a different\n",
    "  disease area, modality, or use.\n",
    "\n",
    "IF THERE IS ANY SIGN OF MISMAPPING:\n",
    "→ Set BOTH \"tt_drug_id\" and \"bmt_drug_id\" to \"\".\n",
    "\n",
    "ONLY include identifiers when the match is **clear, unambiguous, and biologically correct**.\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "\n",
    "ID ASSIGNMENT RULES:\n",
    "- Convert numeric IDs to strings without modification.\n",
    "- Never guess IDs.\n",
    "- Never include an ID from an unrelated drug.\n",
    "- Investigational Products should only receive an ID when matched with\n",
    "  very high confidence.\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "\n",
    "Output format (IMPORTANT):\n",
    "Return ONLY a valid JSON object with:\n",
    "  - keys   = canonical drug names\n",
    "  - values = objects with EXACTLY:\n",
    "        * \"role\"\n",
    "        * \"alternative_names\"\n",
    "        * \"molecular_target\"\n",
    "        * \"mechanism\"\n",
    "        * \"tt_drug_id\"\n",
    "        * \"bmt_drug_id\"\n",
    "\n",
    "Example:\n",
    "{{\n",
    "  \"ABC-123\": {{\n",
    "    \"role\": \"Investigational Product\",\n",
    "    \"alternative_names\": [\"ABC123\", \"Compound-ABC\"],\n",
    "    \"molecular_target\": \"Receptor-Z\",\n",
    "    \"mechanism\": \"Bispecific antibody\",\n",
    "    \"tt_drug_id\": \"123456\",\n",
    "    \"bmt_drug_id\": \"78901\"\n",
    "  }},\n",
    "  \"DrugX\": {{\n",
    "    \"role\": \"Standard of Care\",\n",
    "    \"alternative_names\": [\"GenericX\", \"ChemX\"],\n",
    "    \"molecular_target\": \"Enzyme-A\",\n",
    "    \"mechanism\": \"Antimetabolite\",\n",
    "    \"tt_drug_id\": \"\",\n",
    "    \"bmt_drug_id\": \"\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Input JSON:\n",
    "{payload_json}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "# Shared counters & master mapping\n",
    "counter = {\n",
    "    \"processed\": 0,\n",
    "    \"skipped_existing\": 0,\n",
    "    \"llm_error\": 0,\n",
    "    \"parse_error\": 0,\n",
    "}\n",
    "counter_lock = threading.Lock()\n",
    "\n",
    "master_roles: dict[str, dict] = {}\n",
    "master_lock = threading.Lock()\n",
    "\n",
    "\n",
    "def process_trial(row: dict, idx: int, total: int) -> None:\n",
    "    \"\"\"Process one trial: prompt LLM, save output & log (only if valid).\"\"\"\n",
    "    trial_hash = str(row.get(\"trial_hash\", \"\")).strip()\n",
    "    if not trial_hash:\n",
    "        print(f\"⚠️ [{idx}/{total}] Missing trial_hash, skipping\")\n",
    "        return\n",
    "\n",
    "    out_fp = DRUG_ROLE_DIR / f\"{trial_hash}.json\"\n",
    "    if out_fp.exists():\n",
    "        with counter_lock:\n",
    "            counter[\"skipped_existing\"] += 1\n",
    "        return\n",
    "\n",
    "    # Build payload from selected columns\n",
    "    trial_payload = {\"trial_hash\": trial_hash}\n",
    "    for col in RELEVANT_COLS:\n",
    "        trial_payload[col] = row.get(col, \"\")\n",
    "\n",
    "    prompt = build_prompt(trial_payload)\n",
    "\n",
    "    token = trial_hash\n",
    "    hash_id = trial_hash\n",
    "\n",
    "    text_response = \"\"\n",
    "    raw_response = None\n",
    "    total_cost = 0.0\n",
    "    elapsed = 0.0\n",
    "\n",
    "    # Call LLM\n",
    "    try:\n",
    "        t0 = time.perf_counter()\n",
    "        res = client.query(prompt=prompt, model=MODEL)\n",
    "        elapsed = round(time.perf_counter() - t0, 2)\n",
    "\n",
    "        text_response = (res.get(\"text_response\") or \"\").strip()\n",
    "        raw_response = res.get(\"raw_response\")\n",
    "        total_cost = float(res.get(\"cost\") or 0.0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ [{idx}/{total}] LLM error for trial_hash={trial_hash}: {e}\")\n",
    "        with counter_lock:\n",
    "            counter[\"llm_error\"] += 1\n",
    "        return\n",
    "\n",
    "    drug_roles = extract_json_object(text_response)\n",
    "\n",
    "    # Treat non-dict OR empty dict as invalid → do NOT save anything\n",
    "    if not isinstance(drug_roles, dict) or not drug_roles:\n",
    "        print(f\"⚠️ [{idx}/{total}] JSON parse/validity error trial_hash={trial_hash}, raw={text_response!r}\")\n",
    "        with counter_lock:\n",
    "            counter[\"parse_error\"] += 1\n",
    "        return\n",
    "\n",
    "    mapped = {\n",
    "        \"trial_hash\": trial_hash,\n",
    "        \"title\": row.get(\"title\"),\n",
    "        \"drug_roles\": drug_roles,\n",
    "        \"source\": \"llm\",\n",
    "    }\n",
    "\n",
    "    # Save per-trial roles JSON\n",
    "    out_fp.write_text(json.dumps(mapped, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    # Log entry\n",
    "    log_payload = {\n",
    "        \"token\": token,\n",
    "        \"hash_id\": hash_id,\n",
    "        \"model\": MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"structured_response\": json.dumps(mapped, ensure_ascii=False, indent=2),\n",
    "        \"raw_response\": repr(raw_response),\n",
    "        \"total_cost\": total_cost,\n",
    "        \"time_elapsed\": elapsed,\n",
    "    }\n",
    "    (DRUG_ROLE_LOG_DIR / f\"{hash_id}.json\").write_text(\n",
    "        json.dumps(log_payload, ensure_ascii=False, indent=2),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "    # Update master roles\n",
    "    with master_lock:\n",
    "        master_roles[trial_hash] = mapped\n",
    "        MASTER_ROLES_PATH.write_text(\n",
    "            json.dumps(master_roles, ensure_ascii=False, indent=2),\n",
    "            encoding=\"utf-8\"\n",
    "        )\n",
    "\n",
    "    with counter_lock:\n",
    "        counter[\"processed\"] += 1\n",
    "        if counter[\"processed\"] % 50 == 0:\n",
    "            print(f\"Progress: processed {counter['processed']} trials...\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# RUN CONCURRENTLY\n",
    "# -------------------------------------------------\n",
    "df_trials = pd.read_csv(TRIALS_WITH_HASH_CSV, dtype=str).fillna(\"\")\n",
    "rows = df_trials.to_dict(orient=\"records\")\n",
    "total_trials = len(rows)\n",
    "print(f\"Loaded {total_trials} trials from {TRIALS_WITH_HASH_CSV}\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    futures = {\n",
    "        ex.submit(process_trial, row, idx, total_trials): row.get(\"trial_hash\")\n",
    "        for idx, row in enumerate(rows, start=1)\n",
    "    }\n",
    "    for fut in as_completed(futures):\n",
    "        th = futures[fut]\n",
    "        try:\n",
    "            fut.result()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Worker error trial_hash={th}: {e}\")\n",
    "\n",
    "print(\n",
    "    f\"Trial drug-role mapping complete. \"\n",
    "    f\"processed={counter['processed']}, \"\n",
    "    f\"skipped={counter['skipped_existing']}, \"\n",
    "    f\"llm_error={counter['llm_error']}, \"\n",
    "    f\"parse_error={counter['parse_error']}\"\n",
    ")\n",
    "print(f\"Roles directory: {DRUG_ROLE_DIR}\")\n",
    "print(f\"Log directory:   {DRUG_ROLE_LOG_DIR}\")\n",
    "print(f\"Master roles:    {MASTER_ROLES_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ce191b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== LLM COST SUMMARY ==========\n",
      "Total LLM cost:             $4.3453\n",
      "Number of logged trials:     184\n",
      "Average cost per trial:      $0.0236\n",
      "\n",
      "Top 10 most expensive trials:\n",
      "  tid_261f0233308ca080d1c60e3fda61ca85.json: $0.0692\n",
      "  tid_1158b3369546dc4b16dc21c8c026b619.json: $0.0606\n",
      "  tid_e0a77c4ecf93cf781f04cc467c974511.json: $0.0522\n",
      "  tid_94883aa2d583afced004e22a7991ef3e.json: $0.0519\n",
      "  tid_196721abc2d5ee98883da9bfcf5bb255.json: $0.0486\n",
      "  tid_e9e01f51b6680ba4f467ac191bb307c5.json: $0.0467\n",
      "  tid_8b4d60a5fddc078962af34399d7e342c.json: $0.0452\n",
      "  tid_763e3011bc90e46c88c7a2953a39ed2a.json: $0.0447\n",
      "  tid_837737698a5271d314ea8208addb2d72.json: $0.0440\n",
      "  tid_7e80effdd579ba535ef686ac50dcc4bc.json: $0.0431\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "LOG_DIR = Path(\"cache/trial_drug_roles_log\")\n",
    "\n",
    "total_cost = 0.0\n",
    "num_entries = 0\n",
    "costs = []\n",
    "\n",
    "for fp in LOG_DIR.glob(\"*.json\"):\n",
    "    try:\n",
    "        log = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "        c = float(log.get(\"total_cost\") or 0.0)\n",
    "        total_cost += c\n",
    "        costs.append((fp.name, c))\n",
    "        num_entries += 1\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {fp.name}: {e}\")\n",
    "\n",
    "# Sort descending by cost\n",
    "costs_sorted = sorted(costs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"========== LLM COST SUMMARY ==========\")\n",
    "print(f\"Total LLM cost:             ${total_cost:,.4f}\")\n",
    "print(f\"Number of logged trials:     {num_entries}\")\n",
    "if num_entries > 0:\n",
    "    print(f\"Average cost per trial:      ${total_cost / num_entries:,.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Top 10 most expensive trials:\")\n",
    "for name, c in costs_sorted[:10]:\n",
    "    print(f\"  {name}: ${c:,.4f}\")\n",
    "\n",
    "print(\"========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0e313110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trial product breakdown to cache/trial_product_breakdown.csv\n",
      "|     | trial_hash                           | investigational_products                      | investigational_products_alternative_names                                                                                                                                                 | investigational_products_molecular_target   | investigational_products_mechanism                                    | investigational_products_tt_drug_id   | investigational_products_bmt_drug_id   | active_comparators                       | active_comparators_alternative_names                                                                                                                                                                                            | active_comparators_molecular_target   | active_comparators_mechanism                                 | active_comparators_tt_drug_id   | active_comparators_bmt_drug_id   | placebos   | placebos_alternative_names   | placebos_molecular_target   | placebos_mechanism   | standard_of_care   | standard_of_care_alternative_names   | standard_of_care_molecular_target   | standard_of_care_mechanism   | standard_of_care_tt_drug_id   | standard_of_care_bmt_drug_id   |\n",
      "|----:|:-------------------------------------|:----------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------|:----------------------------------------------------------------------|:--------------------------------------|:---------------------------------------|:-----------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------|:-------------------------------------------------------------|:--------------------------------|:---------------------------------|:-----------|:-----------------------------|:----------------------------|:---------------------|:-------------------|:-------------------------------------|:------------------------------------|:-----------------------------|:------------------------------|:-------------------------------|\n",
      "|  94 | tid_0541995757b10e613a42173d6b8ddc09 | ['cinacalcet hydrochloride (test)']           | [['cinacalcet HCl, Zhejiang Wansheng Pharmaceutical Co.', 'cinacalcet hydrochloride, Zhejiang Wansheng Pharmaceutical Co.', 'cinacalcet, Zhejiang Wansheng Pharmaceutical Co.']]           | ['Calcium-sensing receptor (CaSR)']         | ['Calcimimetic; calcium-sensing receptor agonist']                    | ['194454']                            | ['']                                   | ['cinacalcet hydrochloride (reference)'] | [['cinacalcet hydrochloride tablets produced by Kyowa Kirin Co., Ltd.', 'cinacalcet HCl (Kyowa Kirin)']]                                                                                                                        | ['Calcium-sensing receptor (CaSR)']   | ['Calcimimetic; calcium-sensing receptor agonist']           | ['']                            | ['']                             | []         | []                           | []                          | []                   | []                 | []                                   | []                                  | []                           | []                            | []                             |\n",
      "|  64 | tid_0da20e863cfc5f3e369868462bff74e0 | ['NuPIAO']                                    | [['nupiao', 'rESP', 'SSS-06', 'SSS 06', 'SSS06', 'NuPIAO (iv)', 'recombinant erythropoietin stimulating protein', 'recombinant erythropoiesis-stimulating protein injection (CHO cells)']] | ['Erythropoietin receptor']                 | ['Erythropoietin receptor agonist']                                   | ['40640']                             | ['19694']                              | []                                       | []                                                                                                                                                                                                                              | []                                    | []                                                           | []                              | []                               | []         | []                           | []                          | []                   | []                 | []                                   | []                                  | []                           | []                            | []                             |\n",
      "| 144 | tid_0e8fa21079f928135dfc6164a15285f8 | ['SSS-17']                                    | [['SSS17', 'SSS 17', '[14C]SSS17', '[14C] SSS17', '[14C]-SSS17', '[¹⁴C]SSS17', '[¹⁴C] SSS17', '[¹⁴C]-SSS17', 'HIF-117', 'HIF 117', 'HIF117', '[14C]HIF-117']]                              | ['Hypoxia-inducible factor (HIF)']          | ['Hypoxia-inducible factor antagonist']                               | ['130313']                            | ['']                                   | []                                       | []                                                                                                                                                                                                                              | []                                    | []                                                           | []                              | []                               | []         | []                           | []                          | []                   | []                 | []                                   | []                                  | []                           | []                            | []                             |\n",
      "|  19 | tid_0f04ddb3d522d528d083d7d5c43d1e18 | ['Metformin hydrochloride sustained-release'] | [['Metformin Hydrochloride Sustained-release Tablets', 'metformin hydrochloride, Zhejiang Sunshine Mandi Pharmaceutical Co.', 'metformin hydrochloride extended-release', 'metformin XR']] | ['']                                        | ['Biguanide; gluconeogenesis inhibitor; insulin sensitizer']          | ['290388']                            | ['']                                   | ['Glucophage XR']                        | [['Glucophage', '格华止', 'metformin XR', 'metformin hydrochloride, once-daily, BMS', 'metformin HCl, once-daily, BMS', 'Diabex', 'Diabex XR', 'Dabex XR', 'Glifage XR', 'Metgluco', 'Stagid', 'SMP 862', 'SMP-862', 'SMP862']] | ['']                                  | ['Biguanide; gluconeogenesis inhibitor; insulin sensitizer'] | ['24060']                       | ['']                             | []         | []                           | []                          | []                   | []                 | []                                   | []                                  | []                           | []                            | []                             |\n",
      "|  17 | tid_10562c0430b8b9bae93c94cadfb0a129 | ['RD-01']                                     | [['RD001', 'RD-001', 'RD 001', 'RD01', 'RD-01 Long-acting rhEPO', 'Peg-EPO']]                                                                                                              | ['Erythropoietin receptor (EPOR)']          | ['PEGylated recombinant human erythropoietin (EPO) receptor agonist'] | ['144350']                            | ['']                                   | []                                       | []                                                                                                                                                                                                                              | []                                    | []                                                           | []                              | []                               | []         | []                           | []                          | []                   | []                 | []                                   | []                                  | []                           | []                            | []                             |\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Build trial_product_breakdown.csv\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Base directory for cache + input/output\n",
    "BASE_DIR = Path(\"cache\")\n",
    "\n",
    "# Directory that contains per-trial drug-role JSONs\n",
    "DRUG_ROLE_DIR = BASE_DIR / \"trial_drug_roles\"\n",
    "\n",
    "# Output CSV path\n",
    "OUT_CSV = BASE_DIR / \"trial_product_breakdown.csv\"\n",
    "\n",
    "rows = []\n",
    "\n",
    "for fp in DRUG_ROLE_DIR.glob(\"*.json\"):\n",
    "    try:\n",
    "        obj = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {fp.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    trial_hash = obj.get(\"trial_hash\")\n",
    "    if not trial_hash:\n",
    "        print(f\"⚠️ Missing trial_hash in {fp.name}, skipping\")\n",
    "        continue\n",
    "\n",
    "    drug_roles = obj.get(\"drug_roles\") or {}\n",
    "    if not isinstance(drug_roles, dict):\n",
    "        print(f\"⚠️ drug_roles not dict in {fp.name}, skipping\")\n",
    "        continue\n",
    "\n",
    "    # Containers\n",
    "    inv_names = []\n",
    "    inv_alt_names = []          # list of lists\n",
    "    inv_targets = []\n",
    "    inv_mechanisms = []\n",
    "    inv_tt_ids = []\n",
    "    inv_bmt_ids = []\n",
    "\n",
    "    ac_names = []\n",
    "    ac_alt_names = []           # list of lists\n",
    "    ac_targets = []\n",
    "    ac_mechanisms = []\n",
    "    ac_tt_ids = []\n",
    "    ac_bmt_ids = []\n",
    "\n",
    "    plc_names = []\n",
    "    plc_alt_names = []          # list of lists\n",
    "    plc_targets = []\n",
    "    plc_mechanisms = []\n",
    "\n",
    "    soc_names = []\n",
    "    soc_alt_names = []          # list of lists\n",
    "    soc_targets = []\n",
    "    soc_mechanisms = []\n",
    "    soc_tt_ids = []\n",
    "    soc_bmt_ids = []\n",
    "\n",
    "    for drug_name, meta in drug_roles.items():\n",
    "        if not isinstance(meta, dict):\n",
    "            continue\n",
    "\n",
    "        role = (meta.get(\"role\") or \"\").strip()\n",
    "        role_norm = role.lower()\n",
    "\n",
    "        alt_names = meta.get(\"alternative_names\") or []\n",
    "        if not isinstance(alt_names, list):\n",
    "            alt_names = [str(alt_names)]\n",
    "\n",
    "        molecular_target = meta.get(\"molecular_target\") or \"\"\n",
    "        mechanism = meta.get(\"mechanism\") or \"\"\n",
    "\n",
    "        # IDs are always stored as strings in the LLM output, but be defensive\n",
    "        tt_id = str(meta.get(\"tt_drug_id\") or \"\")\n",
    "        bmt_id = str(meta.get(\"bmt_drug_id\") or \"\")\n",
    "\n",
    "        if role_norm == \"investigational product\":\n",
    "            inv_names.append(drug_name)\n",
    "            inv_alt_names.append(alt_names)\n",
    "            inv_targets.append(molecular_target)\n",
    "            inv_mechanisms.append(mechanism)\n",
    "            inv_tt_ids.append(tt_id)\n",
    "            inv_bmt_ids.append(bmt_id)\n",
    "\n",
    "        elif role_norm == \"active comparator\":\n",
    "            ac_names.append(drug_name)\n",
    "            ac_alt_names.append(alt_names)\n",
    "            ac_targets.append(molecular_target)\n",
    "            ac_mechanisms.append(mechanism)\n",
    "            ac_tt_ids.append(tt_id)\n",
    "            ac_bmt_ids.append(bmt_id)\n",
    "\n",
    "        elif role_norm == \"placebo\":\n",
    "            plc_names.append(drug_name)\n",
    "            plc_alt_names.append(alt_names)\n",
    "            plc_targets.append(molecular_target)\n",
    "            plc_mechanisms.append(mechanism)\n",
    "\n",
    "        elif role_norm == \"standard of care\":\n",
    "            soc_names.append(drug_name)\n",
    "            soc_alt_names.append(alt_names)\n",
    "            soc_targets.append(molecular_target)\n",
    "            soc_mechanisms.append(mechanism)\n",
    "            soc_tt_ids.append(tt_id)\n",
    "            soc_bmt_ids.append(bmt_id)\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"trial_hash\": trial_hash,\n",
    "\n",
    "            \"investigational_products\": inv_names,\n",
    "            \"investigational_products_alternative_names\": inv_alt_names,\n",
    "            \"investigational_products_molecular_target\": inv_targets,\n",
    "            \"investigational_products_mechanism\": inv_mechanisms,\n",
    "            \"investigational_products_tt_drug_id\": inv_tt_ids,\n",
    "            \"investigational_products_bmt_drug_id\": inv_bmt_ids,\n",
    "\n",
    "            \"active_comparators\": ac_names,\n",
    "            \"active_comparators_alternative_names\": ac_alt_names,\n",
    "            \"active_comparators_molecular_target\": ac_targets,\n",
    "            \"active_comparators_mechanism\": ac_mechanisms,\n",
    "            \"active_comparators_tt_drug_id\": ac_tt_ids,\n",
    "            \"active_comparators_bmt_drug_id\": ac_bmt_ids,\n",
    "\n",
    "            \"placebos\": plc_names,\n",
    "            \"placebos_alternative_names\": plc_alt_names,\n",
    "            \"placebos_molecular_target\": plc_targets,\n",
    "            \"placebos_mechanism\": plc_mechanisms,\n",
    "\n",
    "            \"standard_of_care\": soc_names,\n",
    "            \"standard_of_care_alternative_names\": soc_alt_names,\n",
    "            \"standard_of_care_molecular_target\": soc_targets,\n",
    "            \"standard_of_care_mechanism\": soc_mechanisms,\n",
    "            \"standard_of_care_tt_drug_id\": soc_tt_ids,\n",
    "            \"standard_of_care_bmt_drug_id\": soc_bmt_ids,\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_out = pd.DataFrame(rows).sort_values(\"trial_hash\")\n",
    "\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved trial product breakdown to {OUT_CSV}\")\n",
    "print(df_out.head().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e0e24",
   "metadata": {},
   "source": [
    "Manually check the rows with no investigational products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ca77eab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NO investigational products: 4 / 184\n",
      "| trial_hash                           | investigational_products   |\n",
      "|:-------------------------------------|:---------------------------|\n",
      "| tid_4c45730f6411aa1e5a38bb1223d66988 | []                         |\n",
      "| tid_67de51bf9728e056a6fb42c76e4b0212 | []                         |\n",
      "| tid_8cab7b7177fcb0d10255bced8b0633ee | []                         |\n",
      "| tid_bb1e0571142dde8a49976632c349593c | []                         |\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "IN_CSV = BASE_DIR / \"trial_product_breakdown.csv\"\n",
    "\n",
    "df = pd.read_csv(IN_CSV, dtype=str).fillna(\"\")\n",
    "\n",
    "def parse_listish(s: str):\n",
    "    \"\"\"\n",
    "    Parse a stringified list like \"['A', 'B']\" into a Python list.\n",
    "    If parsing fails or the cell is empty, return [].\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "    s = s.strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    # Common empty-list cases\n",
    "    if s in (\"[]\", \"[ ]\"):\n",
    "        return []\n",
    "    try:\n",
    "        val = ast.literal_eval(s)\n",
    "        if isinstance(val, list):\n",
    "            return val\n",
    "        # If it's something else, treat as a single non-empty token\n",
    "        return [val]\n",
    "    except Exception:\n",
    "        # Fallback: treat non-empty string as a single element\n",
    "        return [s]\n",
    "\n",
    "# Parse the investigational_products column into real lists\n",
    "df[\"investigational_products_parsed\"] = df[\"investigational_products\"].apply(parse_listish)\n",
    "\n",
    "# Flag rows with no investigational products\n",
    "no_inv_mask = df[\"investigational_products_parsed\"].apply(lambda x: len(x) == 0)\n",
    "\n",
    "num_no_inv = int(no_inv_mask.sum())\n",
    "total = len(df)\n",
    "\n",
    "print(f\"Rows with NO investigational products: {num_no_inv} / {total}\")\n",
    "\n",
    "# Show a few examples\n",
    "print(\n",
    "    df.loc[no_inv_mask, [\"trial_hash\", \"investigational_products\"]]\n",
    "      .head(20)\n",
    "      .to_markdown(index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01ab97f",
   "metadata": {},
   "source": [
    "Manual checks \n",
    "- tid_4c45730f6411aa1e5a38bb1223d66988\n",
    "    - This trial is combining three standard-of-care agents into a regimen “DCF”\n",
    "- tid_67de51bf9728e056a6fb42c76e4b0212\n",
    "    - Even though they administer Yisaipu in a structured way, it is an approved drug and not being tested for regulatory approval.\n",
    "- tid_8cab7b7177fcb0d10255bced8b0633ee\n",
    "    - The trial is studying treatment strategies, regimens, algorithms, imaging-guided regimen selection, or dosing, using only approved standard therapies.\n",
    "- tid_bb1e0571142dde8a49976632c349593c\n",
    "    - The trial's focus is on optimizing regimen selection (e.g., TIPy or TCbIPy) via imaging, rather than testing a new drug entity.\n",
    "\n",
    "these are all confirmed generics biosimilars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c3463d",
   "metadata": {},
   "source": [
    "Identify and group trials by unique products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ebdc7bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated by tt_drug_id (first 10 rows):\n",
      "|   tt_drug_id | drug_names                           | alternative_names                                                                                                                                                     | molecular_targets                                                                    | product_mechanisms                                                                                                                                                  | trial_hashes                                                                                                                                                                                                                                     |\n",
      "|-------------:|:-------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "|       104351 | ['recombinant human thrombopoietin'] | []                                                                                                                                                                    | ['MPL (TPO receptor)']                                                               | ['Thrombopoietin receptor agonist; recombinant cytokine']                                                                                                           | ['tid_58a84007ff09f957ed7e2275b22a07e6']                                                                                                                                                                                                         |\n",
      "|       104513 | ['rhTPO']                            | ['rHuTPO', 'recombinant human thrombopoietin']                                                                                                                        | ['MPL']                                                                              | ['Thrombopoietin receptor agonist']                                                                                                                                 | ['tid_dbcfbd78eefaa77a4d740900bcb30c51']                                                                                                                                                                                                         |\n",
      "|       113881 | ['SB8']                              | ['615', 'Aybintio', 'Onbevzi', 'SB 8', 'SB-8', 'bevacizumab']                                                                                                         | ['VEGF-A']                                                                           | ['Anti-VEGF humanized monoclonal antibody']                                                                                                                         | ['tid_89d6847422b8926a855e677c6434b263']                                                                                                                                                                                                         |\n",
      "|        11947 | ['Methotrexate', 'methotrexate']     | ['Emthexate', 'Lantarel', 'Ledertrexate', 'MTX', 'Novatrex', 'Rheumatrex', 'Trexall', 'methotrexate (oral)']                                                          | ['DHFR', 'Dihydrofolate reductase (DHFR)']                                           | ['Antimetabolite (dihydrofolate reductase inhibitor)', 'Dihydrofolate reductase inhibitor', 'Dihydrofolate reductase inhibitor (antimetabolite immunosuppressant)'] | ['tid_8cab7b7177fcb0d10255bced8b0633ee', 'tid_9dc4ace9308864c9f8a619d6abe32011', 'tid_fc93655913a5e1b233a8077e9fc758c6']                                                                                                                         |\n",
      "|       122198 | ['Bevacizumab']                      | ['601 t', '601-t', '601t', 'bevacizumab, 3SBio', 'bevacizumab, Shanghai CP Guojian']                                                                                  | ['VEGF-A']                                                                           | ['Humanized monoclonal antibody; angiogenesis inhibitor (anti-VEGF)']                                                                                               | ['tid_27f709d68d54479e8ac19e27a5b5a300']                                                                                                                                                                                                         |\n",
      "|       122500 | ['Fexofenadine hydrochloride']       | ['fexofenadine', 'fexofenadine HCl', 'fexofenadine hydrochloride, Zhejiang Wansheng']                                                                                 | ['Histamine H1 receptor']                                                            | ['H1 receptor antagonist (antihistamine)', 'Histamine H1 receptor antagonist']                                                                                      | ['tid_7cbe7f647635abbe0ccccf9233a6e375', 'tid_8c76966ccc6c54153d53dc85c07f1d4b']                                                                                                                                                                 |\n",
      "|        12359 | ['Mycophenolate mofetil']            | ['CellCept', 'ME-MPA', 'MMF', 'Munoloc', 'R-99', 'R99', 'RS-61443', 'Renodapt']                                                                                       | ['IMPDH']                                                                            | ['Inosine monophosphate dehydrogenase inhibitor']                                                                                                                   | ['tid_94883aa2d583afced004e22a7991ef3e']                                                                                                                                                                                                         |\n",
      "|       125796 | ['Apremilast', 'apremilast']         | ['AP-506', 'AP506', 'apremilast, 3SBio']                                                                                                                              | ['PDE4']                                                                             | ['Phosphodiesterase 4 inhibitor']                                                                                                                                   | ['tid_857d006a53745f50ac861416a33e8960', 'tid_888909319365ceead4be875847493bb0']                                                                                                                                                                 |\n",
      "|       126134 | ['toripalimab']                      | ['JS-001', 'JS001', 'Loqtorzi', 'TAB-001', 'TAB001', 'Tuoyi', 'toripalimab-tpzi']                                                                                     | ['PD-1']                                                                             | ['Monoclonal antibody (PD-1 inhibitor)']                                                                                                                            | ['tid_e9e01f51b6680ba4f467ac191bb307c5']                                                                                                                                                                                                         |\n",
      "|       130313 | ['SSS-17', 'SSS17']                  | ['HIF 117', 'HIF-117', 'HIF117', 'SSS 17', 'SSS-17', 'SSS17', '[14C] SSS17', '[14C]-SSS17', '[14C]HIF-117', '[14C]SSS17', '[¹⁴C] SSS17', '[¹⁴C]-SSS17', '[¹⁴C]SSS17'] | ['HIF', 'HIF prolyl hydroxylase (PHD)', 'HIF-PH1', 'Hypoxia-inducible factor (HIF)'] | ['HIF-prolyl hydroxylase inhibitor', 'Hypoxia-inducible factor antagonist']                                                                                         | ['tid_0e8fa21079f928135dfc6164a15285f8', 'tid_232704536c29e97119c451c906d641f0', 'tid_394f064db860c7cebcdd82c40cad1d9d', 'tid_6dc666a780607d3dcb99598f22cb5210', 'tid_b31c0cb67a9379f28e0393dc632f56d2', 'tid_e7a7c80dc675e3ddaf7b4f73690f0015'] |\n",
      "Saved aggregated tt_drug_id table → cache/product_id_master_by_tt.csv\n",
      "Rows missing molecular_targets or product_mechanisms:\n",
      "|   tt_drug_id | drug_names                  | alternative_names                                         | molecular_targets   | product_mechanisms   | trial_hashes                             |\n",
      "|-------------:|:----------------------------|:----------------------------------------------------------|:--------------------|:---------------------|:-----------------------------------------|\n",
      "|       131499 | ['SSS24']                   | ['SSS 24', 'SSS-24']                                      | []                  | []                   | ['tid_a70cae5bfe1598f1d1f9d7e6d2fef4f7'] |\n",
      "|       182230 | ['narfurine hydrochloride'] | ['narfurine hydrochloride orally disintegrating tablets'] | []                  | []                   | ['tid_302158af0c6b2664f2a682e42b6de1e8'] |\n",
      "Saved → cache/product_id_missing_targets_or_mechs.csv\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = Path(\"cache\")\n",
    "IN_CSV   = BASE_DIR / \"trial_product_breakdown.csv\"\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "def parse_listish(x):\n",
    "    \"\"\"Parse a list-like string (e.g. \"['a','b']\") into a Python list.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    try:\n",
    "        v = ast.literal_eval(s)\n",
    "        return v if isinstance(v, list) else []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Load\n",
    "# ---------------------------\n",
    "df = pd.read_csv(IN_CSV, dtype=str).fillna(\"\")\n",
    "\n",
    "# We'll aggregate everything keyed by tt_drug_id\n",
    "agg = {}  # tt_id -> {\"names\": set(), \"alt_names\": set(), \"targets\": set(), \"mechs\": set(), \"trials\": set()}\n",
    "\n",
    "ROLE_PAIRS = [\n",
    "    (\"investigational_products\", \"investigational_products_tt_drug_id\"),\n",
    "    (\"active_comparators\", \"active_comparators_tt_drug_id\"),\n",
    "    (\"standard_of_care\", \"standard_of_care_tt_drug_id\"),\n",
    "]\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    trial_hash = str(row.get(\"trial_hash\", \"\")).strip()\n",
    "\n",
    "    for base_col, tt_col in ROLE_PAIRS:\n",
    "        # aligned lists\n",
    "        names_list   = parse_listish(row.get(base_col, \"\"))\n",
    "        alts_list    = parse_listish(row.get(f\"{base_col}_alternative_names\", \"\"))\n",
    "        targets_list = parse_listish(row.get(f\"{base_col}_molecular_target\", \"\"))\n",
    "        mechs_list   = parse_listish(row.get(f\"{base_col}_mechanism\", \"\"))\n",
    "        tt_ids       = parse_listish(row.get(tt_col, \"\"))\n",
    "\n",
    "        # iterate by index over tt_ids (they define the products)\n",
    "        for i, raw_tt in enumerate(tt_ids):\n",
    "            tt_id = str(raw_tt).strip()\n",
    "            if not tt_id:\n",
    "                continue\n",
    "\n",
    "            # init aggregate bucket if needed\n",
    "            if tt_id not in agg:\n",
    "                agg[tt_id] = {\n",
    "                    \"names\": set(),\n",
    "                    \"alt_names\": set(),\n",
    "                    \"targets\": set(),\n",
    "                    \"mechs\": set(),\n",
    "                    \"trials\": set(),\n",
    "                }\n",
    "\n",
    "            # record trial hash if available\n",
    "            if trial_hash:\n",
    "                agg[tt_id][\"trials\"].add(trial_hash)\n",
    "\n",
    "            # name\n",
    "            if i < len(names_list):\n",
    "                name = str(names_list[i]).strip()\n",
    "                if name:\n",
    "                    agg[tt_id][\"names\"].add(name)\n",
    "\n",
    "            # alternative names (may be nested lists)\n",
    "            if i < len(alts_list):\n",
    "                alt_entry = alts_list[i]\n",
    "                if isinstance(alt_entry, list):\n",
    "                    for a in alt_entry:\n",
    "                        a_str = str(a).strip()\n",
    "                        if a_str:\n",
    "                            agg[tt_id][\"alt_names\"].add(a_str)\n",
    "                else:\n",
    "                    a_str = str(alt_entry).strip()\n",
    "                    if a_str:\n",
    "                        agg[tt_id][\"alt_names\"].add(a_str)\n",
    "\n",
    "            # target\n",
    "            if i < len(targets_list):\n",
    "                tgt = str(targets_list[i]).strip()\n",
    "                if tgt:\n",
    "                    agg[tt_id][\"targets\"].add(tgt)\n",
    "\n",
    "            # mechanism\n",
    "            if i < len(mechs_list):\n",
    "                mech = str(mechs_list[i]).strip()\n",
    "                if mech:\n",
    "                    agg[tt_id][\"mechs\"].add(mech)\n",
    "\n",
    "# ---------------------------\n",
    "# Build aggregated DataFrame\n",
    "# ---------------------------\n",
    "rows_out = []\n",
    "for tt_id, payload in agg.items():\n",
    "    rows_out.append(\n",
    "        {\n",
    "            \"tt_drug_id\": tt_id,\n",
    "            \"drug_names\": sorted(payload[\"names\"]),\n",
    "            \"alternative_names\": sorted(payload[\"alt_names\"]),\n",
    "            \"molecular_targets\": sorted(payload[\"targets\"]),\n",
    "            \"product_mechanisms\": sorted(payload[\"mechs\"]),\n",
    "            \"trial_hashes\": sorted(payload[\"trials\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "grouped_df = pd.DataFrame(rows_out).sort_values(\"tt_drug_id\")\n",
    "\n",
    "print(\"Aggregated by tt_drug_id (first 10 rows):\")\n",
    "print(grouped_df.head(10).to_markdown(index=False))\n",
    "\n",
    "OUT_AGG = BASE_DIR / \"product_id_master_by_tt.csv\"\n",
    "grouped_df.to_csv(OUT_AGG, index=False)\n",
    "print(f\"Saved aggregated tt_drug_id table → {OUT_AGG}\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Cell: Print all rows missing targets or mechanisms\n",
    "# ---------------------------------------------\n",
    "\n",
    "# A row is \"missing\" if either list is empty\n",
    "missing_mask = grouped_df[\"molecular_targets\"].apply(lambda x: len(x) == 0) & \\\n",
    "               grouped_df[\"product_mechanisms\"].apply(lambda x: len(x) == 0)\n",
    "\n",
    "missing_df = grouped_df[missing_mask].copy()\n",
    "\n",
    "print(\"Rows missing molecular_targets or product_mechanisms:\")\n",
    "if missing_df.empty:\n",
    "    print(\"No missing values — every tt_drug_id has targets and mechanisms.\")\n",
    "else:\n",
    "    # Pretty print full table\n",
    "    print(missing_df.to_markdown(index=False))\n",
    "\n",
    "# Optionally save for debugging\n",
    "OUT_MISSING = BASE_DIR / \"product_id_missing_targets_or_mechs.csv\"\n",
    "missing_df.to_csv(OUT_MISSING, index=False)\n",
    "print(f\"Saved → {OUT_MISSING}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d86691e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 products missing targets/mechanisms\n",
      "Product mechanism inference complete. processed=0, skipped=2, llm_error=0, parse_error=0\n",
      "Per-product directory: cache/product_mechanism_inference\n",
      "Log directory:        cache/product_mechanism_inference_log\n",
      "Master file:          cache/product_mechanism_inference_master.json\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import pandas as pd\n",
    "from services.openai_wrapper import OpenAIWrapper\n",
    "\n",
    "# -------------------------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------------------------\n",
    "BASE_DIR = Path(\"cache\")\n",
    "\n",
    "RAW_TRIALS_CSV = BASE_DIR / \"raw_trials_with_hash.csv\"\n",
    "\n",
    "PRODUCT_MECH_DIR = BASE_DIR / \"product_mechanism_inference\"\n",
    "PRODUCT_MECH_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PRODUCT_MECH_LOG_DIR = BASE_DIR / \"product_mechanism_inference_log\"\n",
    "PRODUCT_MECH_LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MASTER_PRODUCT_MECH_PATH = BASE_DIR / \"product_mechanism_inference_master.json\"\n",
    "\n",
    "MODEL = \"gpt-5\"\n",
    "client = OpenAIWrapper()\n",
    "\n",
    "MAX_WORKERS = 8\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Helpers\n",
    "# -------------------------------------------------\n",
    "def extract_json_object(text: str) -> dict:\n",
    "    \"\"\"Extract first valid JSON object from model output.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return {}\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return {}\n",
    "\n",
    "    # Direct parse first\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: first {...} region\n",
    "    m = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        return {}\n",
    "    try:\n",
    "        obj = json.loads(m.group(0))\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    return {}\n",
    "\n",
    "\n",
    "def safe_parse_listish(val):\n",
    "    \"\"\"\n",
    "    Parse list-like strings back into Python lists, if needed.\n",
    "    If already a list, return as-is.\n",
    "    \"\"\"\n",
    "    if isinstance(val, list):\n",
    "        return val\n",
    "    if val is None:\n",
    "        return []\n",
    "    s = str(val).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    try:\n",
    "        v = ast.literal_eval(s)\n",
    "        if isinstance(v, list):\n",
    "            return v\n",
    "        return [v]\n",
    "    except Exception:\n",
    "        return [s]\n",
    "\n",
    "\n",
    "def build_product_prompt(row: dict, trial_context: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Build prompt asking the LLM (with web_search) to infer\n",
    "    molecular_target and mechanism for a product, based on:\n",
    "      - drug names / alternative names\n",
    "      - full metadata for associated trials\n",
    "    \"\"\"\n",
    "    drug_names = row.get(\"drug_names\", []) or []\n",
    "\n",
    "    # Ensure lists are JSON-serializable\n",
    "    try:\n",
    "        drug_names_json = json.dumps(drug_names, ensure_ascii=False)\n",
    "    except TypeError:\n",
    "        drug_names_json = json.dumps([str(x) for x in drug_names], ensure_ascii=False)\n",
    "\n",
    "    # Trials context JSON\n",
    "    trials_json = json.dumps(trial_context, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a pharmacology expert with access to web search.\n",
    "\n",
    "You are given:\n",
    "- A drug name.\n",
    "- Full metadata for one or more clinical trials in which this drug appears (JSON objects).\n",
    "\n",
    "Your goal:\n",
    "Using web search and your domain knowledge, determine:\n",
    "1. The primary molecular target(s) of the drug (e.g., EGFR, VEGFR2, TNF, CD20, JAK1/2).\n",
    "2. A concise, standard mechanism of action label (e.g., \"EGFR inhibitor\", \"Anti-PD-1 antibody\", \n",
    "   \"JAK inhibitor\", \"DNA-damaging cytotoxic\", etc.).\n",
    "\n",
    "Rules:\n",
    "- Try searching for the drug using all known names or aliases.\n",
    "- If **no molecular target or mechanism of action has been disclosed publicly**, then return **empty strings** for those fields.\n",
    "\n",
    "INPUT\n",
    "-----\n",
    "drug_name: {drug_names_json}\n",
    "trial_metadata:\n",
    "{trials_json}\n",
    "\n",
    "OUTPUT (JSON only)\n",
    "------------------\n",
    "{{\n",
    "  \"molecular_target\": \"\",\n",
    "  \"mechanism\": \"\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "# Shared counters & master mapping\n",
    "product_counter = {\n",
    "    \"processed\": 0,\n",
    "    \"skipped_existing\": 0,\n",
    "    \"llm_error\": 0,\n",
    "    \"parse_error\": 0,\n",
    "}\n",
    "product_counter_lock = threading.Lock()\n",
    "\n",
    "product_master: dict[str, dict] = {}\n",
    "product_master_lock = threading.Lock()\n",
    "\n",
    "# Load existing master if present\n",
    "if MASTER_PRODUCT_MECH_PATH.exists():\n",
    "    try:\n",
    "        product_master = json.loads(MASTER_PRODUCT_MECH_PATH.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        product_master = {}\n",
    "\n",
    "# -------------------------------------------------\n",
    "# LOAD TRIAL METADATA AND BUILD INDEX\n",
    "# -------------------------------------------------\n",
    "df_trials = pd.read_csv(RAW_TRIALS_CSV, dtype=str).fillna(\"\")\n",
    "trials_index: dict[str, dict] = {\n",
    "    str(row[\"trial_hash\"]).strip(): row.to_dict()\n",
    "    for _, row in df_trials.iterrows()\n",
    "}\n",
    "\n",
    "\n",
    "def process_product(row: dict, idx: int, total: int) -> None:\n",
    "    \"\"\"Process one tt_drug_id: prompt LLM+web_search with trial context, save output & log.\"\"\"\n",
    "    tt_drug_id = str(row.get(\"tt_drug_id\", \"\")).strip()\n",
    "    if not tt_drug_id:\n",
    "        print(f\"⚠️ [{idx}/{total}] Missing tt_drug_id, skipping\")\n",
    "        return\n",
    "\n",
    "    out_fp = PRODUCT_MECH_DIR / f\"{tt_drug_id}.json\"\n",
    "    if out_fp.exists():\n",
    "        with product_counter_lock:\n",
    "            product_counter[\"skipped_existing\"] += 1\n",
    "        return\n",
    "\n",
    "    # Get associated trial hashes and build trial context list\n",
    "    trial_hashes_raw = row.get(\"trial_hashes\", [])\n",
    "    trial_hashes = safe_parse_listish(trial_hashes_raw)\n",
    "\n",
    "    trial_context = []\n",
    "    for th in trial_hashes:\n",
    "        th_key = str(th).strip()\n",
    "        if not th_key:\n",
    "            continue\n",
    "        trial_row = trials_index.get(th_key)\n",
    "        if trial_row:\n",
    "            trial_context.append(trial_row)\n",
    "\n",
    "    prompt = build_product_prompt(row, trial_context)\n",
    "\n",
    "    text_response = \"\"\n",
    "    raw_response = None\n",
    "    total_cost = 0.0\n",
    "    elapsed = 0.0\n",
    "\n",
    "    # Call LLM with web_search tool\n",
    "    try:\n",
    "        t0 = time.perf_counter()\n",
    "        res = client.query(\n",
    "            prompt=prompt,\n",
    "            model=MODEL,\n",
    "            tools=[{\"type\": \"web_search\"}],\n",
    "        )\n",
    "        elapsed = round(time.perf_counter() - t0, 2)\n",
    "\n",
    "        text_response = (res.get(\"text_response\") or \"\").strip()\n",
    "        raw_response = res.get(\"raw_response\")\n",
    "        total_cost = float(res.get(\"cost\") or 0.0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ [{idx}/{total}] LLM error for tt_drug_id={tt_drug_id}: {e}\")\n",
    "        with product_counter_lock:\n",
    "            product_counter[\"llm_error\"] += 1\n",
    "        return\n",
    "\n",
    "    mech_obj = extract_json_object(text_response)\n",
    "\n",
    "    # Expect a dict with the two keys\n",
    "    if not isinstance(mech_obj, dict) or not mech_obj:\n",
    "        print(f\"⚠️ [{idx}/{total}] JSON parse/validity error tt_drug_id={tt_drug_id}, raw={text_response!r}\")\n",
    "        with product_counter_lock:\n",
    "            product_counter[\"parse_error\"] += 1\n",
    "        return\n",
    "\n",
    "    molecular_target = str(mech_obj.get(\"molecular_target\", \"\") or \"\").strip()\n",
    "    mechanism = str(mech_obj.get(\"mechanism\", \"\") or \"\").strip()\n",
    "\n",
    "    mapped = {\n",
    "        \"tt_drug_id\": tt_drug_id,\n",
    "        \"drug_names\": row.get(\"drug_names\", []),\n",
    "        \"alternative_names\": row.get(\"alternative_names\", []),\n",
    "        \"trial_hashes\": trial_hashes,\n",
    "        \"molecular_target\": molecular_target,\n",
    "        \"mechanism\": mechanism,\n",
    "        \"source\": \"llm_web_search\",\n",
    "    }\n",
    "\n",
    "    # Save per-product JSON\n",
    "    out_fp.write_text(json.dumps(mapped, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    # Log entry\n",
    "    log_payload = {\n",
    "        \"tt_drug_id\": tt_drug_id,\n",
    "        \"model\": MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"structured_response\": json.dumps(mapped, ensure_ascii=False, indent=2),\n",
    "        \"raw_response\": repr(raw_response),\n",
    "        \"total_cost\": total_cost,\n",
    "        \"time_elapsed\": elapsed,\n",
    "    }\n",
    "    (PRODUCT_MECH_LOG_DIR / f\"{tt_drug_id}.json\").write_text(\n",
    "        json.dumps(log_payload, ensure_ascii=False, indent=2),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "    # Update master\n",
    "    with product_master_lock:\n",
    "        product_master[tt_drug_id] = mapped\n",
    "        MASTER_PRODUCT_MECH_PATH.write_text(\n",
    "            json.dumps(product_master, ensure_ascii=False, indent=2),\n",
    "            encoding=\"utf-8\",\n",
    "        )\n",
    "\n",
    "    with product_counter_lock:\n",
    "        product_counter[\"processed\"] += 1\n",
    "        if product_counter[\"processed\"] % 50 == 0:\n",
    "            print(f\"Progress: processed {product_counter['processed']} products...\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# RUN CONCURRENTLY ON MISSING PRODUCTS\n",
    "# -------------------------------------------------\n",
    "# missing_df was defined in the previous cell and includes trial_hashes\n",
    "missing_rows = missing_df.to_dict(orient=\"records\")\n",
    "total_missing = len(missing_rows)\n",
    "print(f\"Loaded {total_missing} products missing targets/mechanisms\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    futures = {\n",
    "        ex.submit(process_product, row, idx, total_missing): row.get(\"tt_drug_id\")\n",
    "        for idx, row in enumerate(missing_rows, start=1)\n",
    "    }\n",
    "    for fut in as_completed(futures):\n",
    "        tid = futures[fut]\n",
    "        try:\n",
    "            fut.result()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Worker error tt_drug_id={tid}: {e}\")\n",
    "\n",
    "print(\n",
    "    f\"Product mechanism inference complete. \"\n",
    "    f\"processed={product_counter['processed']}, \"\n",
    "    f\"skipped={product_counter['skipped_existing']}, \"\n",
    "    f\"llm_error={product_counter['llm_error']}, \"\n",
    "    f\"parse_error={product_counter['parse_error']}\"\n",
    ")\n",
    "print(f\"Per-product directory: {PRODUCT_MECH_DIR}\")\n",
    "print(f\"Log directory:        {PRODUCT_MECH_LOG_DIR}\")\n",
    "print(f\"Master file:          {MASTER_PRODUCT_MECH_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "90e85a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trial breakdown: cache/trial_product_breakdown.csv, shape=(184, 23)\n",
      "Aggregated 119 distinct tt_drug_id entries.\n",
      "Aggregated 15 products without tt_drug_id but with target/mechanism.\n",
      "Saved did-keyed drug master JSON → cache/product_id_master_by_did.json\n",
      "Total drugs: 134\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------\n",
    "# CONFIG\n",
    "# ----------------------------------------\n",
    "BASE_DIR = Path(\"cache\")\n",
    "IN_BREAKDOWN_CSV = BASE_DIR / \"trial_product_breakdown.csv\"\n",
    "MASTER_PRODUCT_MECH_PATH = BASE_DIR / \"product_mechanism_inference_master.json\"\n",
    "OUT_JSON = BASE_DIR / \"product_id_master_by_did.json\"\n",
    "\n",
    "# ----------------------------------------\n",
    "# Helpers\n",
    "# ----------------------------------------\n",
    "def parse_listish(x):\n",
    "    \"\"\"Parse a list-like string (e.g. \"['a','b']\") into a Python list.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if x is None:\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if not s or s in (\"[]\", \"[ ]\"):\n",
    "        return []\n",
    "    try:\n",
    "        v = ast.literal_eval(s)\n",
    "        if isinstance(v, list):\n",
    "            return v\n",
    "        return [v]\n",
    "    except Exception:\n",
    "        return [s]\n",
    "\n",
    "\n",
    "def pad_to_length(lst, n):\n",
    "    \"\"\"Pad list with empty strings so len(lst) >= n.\"\"\"\n",
    "    lst = list(lst)\n",
    "    while len(lst) < n:\n",
    "        lst.append(\"\")\n",
    "    return lst\n",
    "\n",
    "\n",
    "def make_did_from_tt(tt_drug_id: str) -> str:\n",
    "    \"\"\"Deterministic drug hash ID based on tt_drug_id (for known IDs).\"\"\"\n",
    "    h = hashlib.md5(tt_drug_id.encode(\"utf-8\")).hexdigest()\n",
    "    return f\"did_{h}\"\n",
    "\n",
    "\n",
    "def make_did_for_unknown(key: str) -> str:\n",
    "    \"\"\"\n",
    "    Deterministic drug hash ID for products without tt_drug_id.\n",
    "    Key can be any composite string (e.g., name + target + mechanism).\n",
    "    \"\"\"\n",
    "    h = hashlib.md5(key.encode(\"utf-8\")).hexdigest()\n",
    "    return f\"did_{h}\"\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# Load inputs\n",
    "# ----------------------------------------\n",
    "df = pd.read_csv(IN_BREAKDOWN_CSV, dtype=str).fillna(\"\")\n",
    "print(f\"Loaded trial breakdown: {IN_BREAKDOWN_CSV}, shape={df.shape}\")\n",
    "\n",
    "if MASTER_PRODUCT_MECH_PATH.exists():\n",
    "    product_master = json.loads(MASTER_PRODUCT_MECH_PATH.read_text(encoding=\"utf-8\"))\n",
    "else:\n",
    "    product_master = {}\n",
    "    print(f\"⚠️ No product master mech file found at {MASTER_PRODUCT_MECH_PATH}\")\n",
    "\n",
    "# role → (base_name_col, tt_id_col, target_col, mech_col)\n",
    "ROLE_SPECS = [\n",
    "    (\n",
    "        \"investigational_products\",\n",
    "        \"investigational_products_tt_drug_id\",\n",
    "        \"investigational_products_molecular_target\",\n",
    "        \"investigational_products_mechanism\",\n",
    "    ),\n",
    "    (\n",
    "        \"active_comparators\",\n",
    "        \"active_comparators_tt_drug_id\",\n",
    "        \"active_comparators_molecular_target\",\n",
    "        \"active_comparators_mechanism\",\n",
    "    ),\n",
    "    (\n",
    "        \"standard_of_care\",\n",
    "        \"standard_of_care_tt_drug_id\",\n",
    "        \"standard_of_care_molecular_target\",\n",
    "        \"standard_of_care_mechanism\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# ----------------------------------------\n",
    "# Aggregate per tt_drug_id and per \"unknown but has mech/target\"\n",
    "# ----------------------------------------\n",
    "agg_tt = {}       # tt_id -> {...}\n",
    "agg_unknown = {}  # composite_key -> {...}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    trial_hash = str(row.get(\"trial_hash\", \"\")).strip()\n",
    "\n",
    "    for base_col, tt_col, tgt_col, mech_col in ROLE_SPECS:\n",
    "        # Skip if any required column is missing\n",
    "        if tt_col not in df.columns or tgt_col not in df.columns or mech_col not in df.columns:\n",
    "            continue\n",
    "\n",
    "        # Base name + alt-name columns\n",
    "        names_list = parse_listish(row.get(base_col, \"\"))\n",
    "        alt_list   = parse_listish(row.get(f\"{base_col}_alternative_names\", \"\"))\n",
    "\n",
    "        tt_ids   = parse_listish(row.get(tt_col, \"\"))\n",
    "        targets  = parse_listish(row.get(tgt_col, \"\"))\n",
    "        mechs    = parse_listish(row.get(mech_col, \"\"))\n",
    "\n",
    "        # Align target/mech lists to tt_ids length\n",
    "        targets = pad_to_length(targets, len(tt_ids))\n",
    "        mechs   = pad_to_length(mechs, len(tt_ids))\n",
    "\n",
    "        for i, raw_tt in enumerate(tt_ids):\n",
    "            tt_id = str(raw_tt).strip()\n",
    "\n",
    "            # Name (by position if available)\n",
    "            name = \"\"\n",
    "            if i < len(names_list):\n",
    "                name = str(names_list[i]).strip()\n",
    "\n",
    "            # Alternative names (can be list-of-lists or flat)\n",
    "            alt_names_for_this = []\n",
    "            if i < len(alt_list):\n",
    "                alt_entry = alt_list[i]\n",
    "                if isinstance(alt_entry, list):\n",
    "                    for a in alt_entry:\n",
    "                        a_str = str(a).strip()\n",
    "                        if a_str:\n",
    "                            alt_names_for_this.append(a_str)\n",
    "                else:\n",
    "                    a_str = str(alt_entry).strip()\n",
    "                    if a_str:\n",
    "                        alt_names_for_this.append(a_str)\n",
    "\n",
    "            # Existing target/mechanism from CSV\n",
    "            csv_target = str(targets[i]).strip()\n",
    "            csv_mech   = str(mechs[i]).strip()\n",
    "\n",
    "            # ----------------------------------------\n",
    "            # Case 1: Have a tt_drug_id → normal aggregation\n",
    "            # ----------------------------------------\n",
    "            if tt_id:\n",
    "                if tt_id not in agg_tt:\n",
    "                    agg_tt[tt_id] = {\n",
    "                        \"names\": set(),\n",
    "                        \"alt_names\": set(),\n",
    "                        \"targets\": set(),\n",
    "                        \"mechs\": set(),\n",
    "                        \"trials\": set(),\n",
    "                    }\n",
    "\n",
    "                # Record trial hash\n",
    "                if trial_hash:\n",
    "                    agg_tt[tt_id][\"trials\"].add(trial_hash)\n",
    "\n",
    "                # Names\n",
    "                if name:\n",
    "                    agg_tt[tt_id][\"names\"].add(name)\n",
    "\n",
    "                for a_str in alt_names_for_this:\n",
    "                    agg_tt[tt_id][\"alt_names\"].add(a_str)\n",
    "\n",
    "                # LLM-inferred target/mechanism (if available)\n",
    "                info = product_master.get(tt_id) or {}\n",
    "                inferred_target = str(info.get(\"molecular_target\", \"\") or \"\").strip()\n",
    "                inferred_mech   = str(info.get(\"mechanism\", \"\") or \"\").strip()\n",
    "\n",
    "                # Final chosen values for this (trial, index, tt_id)\n",
    "                final_target = csv_target or inferred_target\n",
    "                final_mech   = csv_mech   or inferred_mech\n",
    "\n",
    "                if final_target:\n",
    "                    agg_tt[tt_id][\"targets\"].add(final_target)\n",
    "                if final_mech:\n",
    "                    agg_tt[tt_id][\"mechs\"].add(final_mech)\n",
    "\n",
    "            # ----------------------------------------\n",
    "            # Case 2: NO tt_drug_id, but we have target or mechanism\n",
    "            # → create a synthetic product entry with empty tt_drug_id\n",
    "            # ----------------------------------------\n",
    "            else:\n",
    "                # If we have no name and no mechanistic info, skip\n",
    "                if not (name or csv_target or csv_mech):\n",
    "                    continue\n",
    "\n",
    "                # Only create unknown entry if there is mechanistic info\n",
    "                if not (csv_target or csv_mech):\n",
    "                    continue\n",
    "\n",
    "                # Build a composite key to deduplicate unknown products\n",
    "                composite_key = f\"{base_col}||{name}||{csv_target}||{csv_mech}\"\n",
    "\n",
    "                if composite_key not in agg_unknown:\n",
    "                    agg_unknown[composite_key] = {\n",
    "                        \"names\": set(),\n",
    "                        \"alt_names\": set(),\n",
    "                        \"targets\": set(),\n",
    "                        \"mechs\": set(),\n",
    "                        \"trials\": set(),\n",
    "                    }\n",
    "\n",
    "                if trial_hash:\n",
    "                    agg_unknown[composite_key][\"trials\"].add(trial_hash)\n",
    "\n",
    "                if name:\n",
    "                    agg_unknown[composite_key][\"names\"].add(name)\n",
    "\n",
    "                for a_str in alt_names_for_this:\n",
    "                    agg_unknown[composite_key][\"alt_names\"].add(a_str)\n",
    "\n",
    "                if csv_target:\n",
    "                    agg_unknown[composite_key][\"targets\"].add(csv_target)\n",
    "                if csv_mech:\n",
    "                    agg_unknown[composite_key][\"mechs\"].add(csv_mech)\n",
    "\n",
    "print(f\"Aggregated {len(agg_tt)} distinct tt_drug_id entries.\")\n",
    "print(f\"Aggregated {len(agg_unknown)} products without tt_drug_id but with target/mechanism.\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Build did-keyed JSON structure\n",
    "# ----------------------------------------\n",
    "drug_master_by_did = {}\n",
    "\n",
    "# 1) Entries with real tt_drug_id\n",
    "for tt_id, payload in agg_tt.items():\n",
    "    did = make_did_from_tt(tt_id)\n",
    "    drug_master_by_did[did] = {\n",
    "        \"did\": did,\n",
    "        \"tt_drug_id\": tt_id,\n",
    "        \"drug_names\": sorted(payload[\"names\"]),\n",
    "        \"alternative_names\": sorted(payload[\"alt_names\"]),\n",
    "        \"molecular_targets\": sorted(payload[\"targets\"]),\n",
    "        \"product_mechanisms\": sorted(payload[\"mechs\"]),\n",
    "        \"trial_hashes\": sorted(payload[\"trials\"]),\n",
    "    }\n",
    "\n",
    "# 2) Entries without tt_drug_id (tt_drug_id = \"\")\n",
    "for composite_key, payload in agg_unknown.items():\n",
    "    did = make_did_for_unknown(composite_key)\n",
    "    drug_master_by_did[did] = {\n",
    "        \"did\": did,\n",
    "        \"tt_drug_id\": \"\",  # explicitly empty as requested\n",
    "        \"drug_names\": sorted(payload[\"names\"]),\n",
    "        \"alternative_names\": sorted(payload[\"alt_names\"]),\n",
    "        \"molecular_targets\": sorted(payload[\"targets\"]),\n",
    "        \"product_mechanisms\": sorted(payload[\"mechs\"]),\n",
    "        \"trial_hashes\": sorted(payload[\"trials\"]),\n",
    "    }\n",
    "\n",
    "# ----------------------------------------\n",
    "# Save JSON\n",
    "# ----------------------------------------\n",
    "OUT_JSON.parent.mkdir(parents=True, exist_ok=True)\n",
    "OUT_JSON.write_text(\n",
    "    json.dumps(drug_master_by_did, ensure_ascii=False, indent=2),\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(f\"Saved did-keyed drug master JSON → {OUT_JSON}\")\n",
    "print(f\"Total drugs: {len(drug_master_by_did)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6709c055",
   "metadata": {},
   "source": [
    "#### Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77190ce",
   "metadata": {},
   "source": [
    "Identify whether the drugs are innovative or/generic biosimilars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "52a5c1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 180 trials with investigational products for innovation-status classification.\n",
      "Trial investigational-drug innovation classification complete. processed=0, skipped=180, llm_error=0, parse_error=0, coverage_error=0\n",
      "Classifications directory: cache/trial_investigational_drugs_classifications\n",
      "Log directory:             cache/trial_investigational_drugs_classifications_log\n",
      "Master classifications:    cache/trial_investigational_drugs_classifications_master.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from services.openai_wrapper import OpenAIWrapper\n",
    "import ast\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------------------------\n",
    "BASE_DIR = Path(\"cache\")\n",
    "\n",
    "TRIALS_WITH_HASH_CSV    = BASE_DIR / \"raw_trials_with_hash.csv\"\n",
    "PRODUCT_BREAKDOWN_CSV   = BASE_DIR / \"trial_product_breakdown.csv\"\n",
    "PRODUCT_BY_DID_JSON     = BASE_DIR / \"product_id_master_by_did.json\"\n",
    "\n",
    "INNOV_DIR = BASE_DIR / \"trial_investigational_drugs_classifications\"\n",
    "INNOV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INNOV_LOG_DIR = BASE_DIR / \"trial_investigational_drugs_classifications_log\"\n",
    "INNOV_LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MASTER_INNOV_PATH = BASE_DIR / \"trial_investigational_drugs_classifications_master.json\"\n",
    "\n",
    "RELEVANT_COLS = [\n",
    "    \"title\",\n",
    "    \"objective\",\n",
    "    \"outcome_details\",\n",
    "    \"treatment_plan\",\n",
    "    \"notes_json\",\n",
    "    \"results_json\",\n",
    "    \"primary_drugs_tested_json\",\n",
    "    \"other_drugs_tested_json\",\n",
    "    \"therapeutic_areas_json\",\n",
    "    \"bmt_other_drugs_tested_json\",\n",
    "    \"bmt_primary_drugs_tested_json\",\n",
    "    \"ct_gov_mesh_terms_json\",\n",
    "]\n",
    "\n",
    "MAX_WORKERS_INNOV = 8\n",
    "\n",
    "MODEL = \"gpt-5\"\n",
    "client = OpenAIWrapper()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Helpers\n",
    "# -------------------------------------------------\n",
    "def load_master_innov() -> dict:\n",
    "    if not MASTER_INNOV_PATH.exists():\n",
    "        return {}\n",
    "    try:\n",
    "        return json.loads(MASTER_INNOV_PATH.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def extract_json_object(text: str) -> dict:\n",
    "    \"\"\"Extract first valid JSON object from model output.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return {}\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return {}\n",
    "\n",
    "    # Direct parse first\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: first {...} region\n",
    "    m = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        return {}\n",
    "    try:\n",
    "        obj = json.loads(m.group(0))\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    return {}\n",
    "\n",
    "def parse_listish(s):\n",
    "    \"\"\"\n",
    "    Parse a stringified list like \"['A', 'B']\" into a Python list.\n",
    "    If parsing fails or the cell is empty, return [].\n",
    "    \"\"\"\n",
    "    if isinstance(s, list):\n",
    "        return s\n",
    "    if s is None:\n",
    "        return []\n",
    "    s = str(s).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    # Common empty-list cases\n",
    "    if s in (\"[]\", \"[ ]\"):\n",
    "        return []\n",
    "    try:\n",
    "        val = ast.literal_eval(s)\n",
    "        if isinstance(val, list):\n",
    "            return val\n",
    "        # If it's something else, treat as a single non-empty token\n",
    "        return [val]\n",
    "    except Exception:\n",
    "        # Fallback: treat non-empty string as a single element\n",
    "        return [s]\n",
    "\n",
    "def pad_to_length(lst, n):\n",
    "    \"\"\"Pad list with empty strings so len(lst) >= n.\"\"\"\n",
    "    lst = list(lst)\n",
    "    while len(lst) < n:\n",
    "        lst.append(\"\")\n",
    "    return lst\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Load per-drug metadata (product_id_master_by_did.json)\n",
    "# -------------------------------------------------\n",
    "if PRODUCT_BY_DID_JSON.exists():\n",
    "    product_by_did = json.loads(PRODUCT_BY_DID_JSON.read_text(encoding=\"utf-8\"))\n",
    "else:\n",
    "    product_by_did = {}\n",
    "    print(f\"⚠️ No drug master JSON found at {PRODUCT_BY_DID_JSON}\")\n",
    "\n",
    "# Build tt_drug_id → metadata mapping for quick lookup\n",
    "tt_to_drug_meta: dict[str, dict] = {}\n",
    "for did, rec in product_by_did.items():\n",
    "    tt = str(rec.get(\"tt_drug_id\", \"\")).strip()\n",
    "    if tt and tt not in tt_to_drug_meta:\n",
    "        tt_to_drug_meta[tt] = rec\n",
    "\n",
    "\n",
    "def build_innovation_prompt(trial_payload: dict, drug_contexts: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Build prompt to classify each investigational product as\n",
    "    Innovative / Generic / Biosimilar, with one-sentence explanation,\n",
    "    using extra context about each drug (names, alt names, targets, mechanisms).\n",
    "    \"\"\"\n",
    "    payload_json = json.dumps(trial_payload, ensure_ascii=False, indent=2)\n",
    "    drugs_json   = json.dumps(drug_contexts, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a clinical trial design and drug development expert.\n",
    "\n",
    "You are given:\n",
    "1) Structured information about a clinical trial (title, objective, results, etc.).\n",
    "2) A list of investigational products used in the trial, with extra metadata for each.\n",
    "   Each investigational drug entry has:\n",
    "   - \"name\": the canonical investigational product name in this trial\n",
    "   - \"tt_drug_id\": the TrialTrove/PharmaProjects drugId as a string (if known)\n",
    "   - \"drug_names\": list of names for this drug\n",
    "   - \"alternative_names\": list of alternative or synonym names\n",
    "   - \"molecular_targets\": list of known molecular targets\n",
    "   - \"product_mechanisms\": list of known mechanisms of action\n",
    "\n",
    "Your task: For EACH investigational product (by its \"name\"), classify whether it is:\n",
    "- \"Innovative\"\n",
    "- \"Generic\"\n",
    "- \"Biosimilar\"\n",
    "\n",
    "and provide:\n",
    "- a one-sentence concise explanation for your classification\n",
    "- the tt_drug_id (string; use \"\" if unknown).\n",
    "\n",
    "DEFINITIONS / GUIDANCE\n",
    "----------------------\n",
    "\n",
    "Innovative:\n",
    "- A novel or proprietary drug (new or sponsor-specific product).\n",
    "- New mechanism of action OR new molecular entity OR clearly the sponsor's lead product.\n",
    "- Often associated with efficacy or superiority language:\n",
    "  - \"evaluate efficacy\", \"vs placebo\", \"improve outcomes\", etc.\n",
    "- Not a copy of an already-approved product.\n",
    "\n",
    "Generic:\n",
    "- A small-molecule copy of an already-approved branded drug.\n",
    "- Same active ingredient, strength, dosage form, and route.\n",
    "- Often explicitly described as generic or equivalent.\n",
    "\n",
    "Biosimilar:\n",
    "- A biologic product that is highly similar to an already-approved reference biologic.\n",
    "- Same target and mechanism as a branded biologic.\n",
    "- Strong clues:\n",
    "  - \"equivalence\", \"non-inferiority\", \"no clinically meaningful differences\",\n",
    "  - direct comparison to a specific branded reference biologic.\n",
    "\n",
    "You MUST choose ONE of the three labels (\"Innovative\", \"Generic\", \"Biosimilar\") for each drug.\n",
    "If you are uncertain, you may say so in the one-sentence explanation, but still pick a label.\n",
    "\n",
    "Use all available information:\n",
    "- Trial text and design\n",
    "- Investigational vs comparator roles\n",
    "- Known targets/mechanisms from the drug metadata.\n",
    "\n",
    "OUTPUT FORMAT (IMPORTANT)\n",
    "-------------------------\n",
    "\n",
    "Return ONLY a valid JSON object, with:\n",
    "- KEYS   = exactly the investigational product \"name\" values given below\n",
    "- VALUES = an object with exactly three fields:\n",
    "    - \"classification\": one of \"Innovative\", \"Generic\", \"Biosimilar\"\n",
    "    - \"explanation\": a single, concise sentence explaining your reasoning\n",
    "    - \"tt_drug_id\": the string tt_drug_id for this drug (\"\" if unknown)\n",
    "\n",
    "Example output:\n",
    "{{\n",
    "  \"DrugA\": {{\n",
    "    \"classification\": \"Innovative\",\n",
    "    \"explanation\": \"DrugA is a novel monoclonal antibody targeting a new receptor and is the sponsor's lead product.\",\n",
    "    \"tt_drug_id\": \"123456\"\n",
    "  }},\n",
    "  \"DrugB\": {{\n",
    "    \"classification\": \"Biosimilar\",\n",
    "    \"explanation\": \"DrugB is tested for equivalence compared to the branded biologic with the same active ingredient.\",\n",
    "    \"tt_drug_id\": \"789012\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "TRIAL PAYLOAD (includes trial text and all drug-role breakdown columns):\n",
    "{payload_json}\n",
    "\n",
    "INVESTIGATIONAL DRUG CONTEXTS (you MUST classify EACH by its 'name' key):\n",
    "{drugs_json}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "master_innov = load_master_innov()\n",
    "master_lock = threading.Lock()\n",
    "\n",
    "innov_counter = {\n",
    "    \"processed\": 0,\n",
    "    \"skipped_existing\": 0,\n",
    "    \"llm_error\": 0,\n",
    "    \"parse_error\": 0,\n",
    "    \"coverage_error\": 0,\n",
    "}\n",
    "counter_lock = threading.Lock()\n",
    "\n",
    "\n",
    "def process_innov_row(row: dict, idx: int, total: int, breakdown_cols: list[str]) -> None:\n",
    "    \"\"\"Process a single trial with investigational products.\"\"\"\n",
    "    trial_hash = str(row.get(\"trial_hash\", \"\")).strip()\n",
    "    if not trial_hash:\n",
    "        print(f\"⚠️ [{idx}/{total}] Missing trial_hash, skipping\")\n",
    "        return\n",
    "\n",
    "    # Names as used in the trial\n",
    "    investigational_products = row.get(\"investigational_products_parsed\") or []\n",
    "    investigational_products = [str(x).strip() for x in investigational_products if str(x).strip()]\n",
    "\n",
    "    if not investigational_products:\n",
    "        # Shouldn't happen due to filtering, but be safe\n",
    "        return\n",
    "\n",
    "    out_fp = INNOV_DIR / f\"{trial_hash}.json\"\n",
    "    if out_fp.exists():\n",
    "        with counter_lock:\n",
    "            innov_counter[\"skipped_existing\"] += 1\n",
    "        return\n",
    "\n",
    "    # ------------------------------------\n",
    "    # Build per-drug context from did JSON\n",
    "    # ------------------------------------\n",
    "    # Aligned TrialTrove IDs for investigational products\n",
    "    inv_tt_raw = row.get(\"investigational_products_tt_drug_id\", \"\")\n",
    "    inv_tt_ids = parse_listish(inv_tt_raw)\n",
    "    inv_tt_ids = pad_to_length(inv_tt_ids, len(investigational_products))\n",
    "\n",
    "    drug_contexts = []\n",
    "    for i, name in enumerate(investigational_products):\n",
    "        tt_id = str(inv_tt_ids[i]).strip() if i < len(inv_tt_ids) else \"\"\n",
    "        meta = tt_to_drug_meta.get(tt_id, {}) if tt_id else {}\n",
    "\n",
    "        drug_contexts.append(\n",
    "            {\n",
    "                \"name\": name,\n",
    "                \"tt_drug_id\": tt_id,\n",
    "                \"drug_names\": meta.get(\"drug_names\", []),\n",
    "                \"alternative_names\": meta.get(\"alternative_names\", []),\n",
    "                \"molecular_targets\": meta.get(\"molecular_targets\", []),\n",
    "                \"product_mechanisms\": meta.get(\"product_mechanisms\", []),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # ------------------------------------\n",
    "    # Build payload from selected columns\n",
    "    # ------------------------------------\n",
    "    trial_payload = {\"trial_hash\": trial_hash}\n",
    "\n",
    "    # 1) Trial-level textual fields from raw_trials_with_hash.csv\n",
    "    for col in RELEVANT_COLS:\n",
    "        trial_payload[col] = row.get(col, \"\")\n",
    "\n",
    "    # 2) ALL columns from trial_product_breakdown.csv\n",
    "    for col in breakdown_cols:\n",
    "        trial_payload[col] = row.get(col, \"\")\n",
    "\n",
    "    prompt = build_innovation_prompt(trial_payload, drug_contexts)\n",
    "\n",
    "    token = trial_hash\n",
    "    hash_id = trial_hash\n",
    "\n",
    "    text_response = \"\"\n",
    "    raw_response = None\n",
    "    total_cost = 0.0\n",
    "    elapsed = 0.0\n",
    "\n",
    "    # Call LLM\n",
    "    try:\n",
    "        t0 = time.perf_counter()\n",
    "        res = client.query(prompt=prompt, model=MODEL)\n",
    "        elapsed = round(time.perf_counter() - t0, 2)\n",
    "\n",
    "        text_response = (res.get(\"text_response\") or \"\").strip()\n",
    "        raw_response = res.get(\"raw_response\")\n",
    "        total_cost = float(res.get(\"cost\") or 0.0)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ [{idx}/{total}] LLM error for trial_hash={trial_hash}: {e}\")\n",
    "        with counter_lock:\n",
    "            innov_counter[\"llm_error\"] += 1\n",
    "        return\n",
    "\n",
    "    # Parse JSON\n",
    "    classifications = extract_json_object(text_response)\n",
    "\n",
    "    if not isinstance(classifications, dict) or not classifications:\n",
    "        print(f\"⚠️ [{idx}/{total}] JSON parse error trial_hash={trial_hash}, raw={text_response!r}\")\n",
    "        with counter_lock:\n",
    "            innov_counter[\"parse_error\"] += 1\n",
    "        return\n",
    "\n",
    "    # Check coverage: every investigational product must be present as a key\n",
    "    missing = [d for d in investigational_products if d not in classifications]\n",
    "    if missing:\n",
    "        print(\n",
    "            f\"⚠️ [{idx}/{total}] Coverage error for trial_hash={trial_hash}: \"\n",
    "            f\"missing classifications for {missing}\"\n",
    "        )\n",
    "        with counter_lock:\n",
    "            innov_counter[\"coverage_error\"] += 1\n",
    "        # DO NOT save this trial so it can be re-run next time\n",
    "        return\n",
    "\n",
    "    # Sanity check: each value has classification, explanation, tt_drug_id\n",
    "    for d in investigational_products:\n",
    "        meta = classifications.get(d, {})\n",
    "        if not isinstance(meta, dict):\n",
    "            print(f\"⚠️ [{idx}/{total}] Invalid meta for {d} in trial_hash={trial_hash}\")\n",
    "            with counter_lock:\n",
    "                innov_counter[\"parse_error\"] += 1\n",
    "            return\n",
    "        if (\"classification\" not in meta) or (\"explanation\" not in meta) or (\"tt_drug_id\" not in meta):\n",
    "            print(f\"⚠️ [{idx}/{total}] Missing fields for {d} in trial_hash={trial_hash}\")\n",
    "            with counter_lock:\n",
    "                innov_counter[\"parse_error\"] += 1\n",
    "            return\n",
    "\n",
    "    mapped = {\n",
    "        \"trial_hash\": trial_hash,\n",
    "        \"investigational_products\": investigational_products,\n",
    "        \"classifications\": classifications,\n",
    "        \"source\": \"llm\",\n",
    "    }\n",
    "\n",
    "    # Save per-trial JSON\n",
    "    out_fp.write_text(json.dumps(mapped, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    # Log entry\n",
    "    log_payload = {\n",
    "        \"token\": token,\n",
    "        \"hash_id\": hash_id,\n",
    "        \"model\": MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"structured_response\": json.dumps(mapped, ensure_ascii=False, indent=2),\n",
    "        \"raw_response\": repr(raw_response),\n",
    "        \"total_cost\": total_cost,\n",
    "        \"time_elapsed\": elapsed,\n",
    "    }\n",
    "    (INNOV_LOG_DIR / f\"{hash_id}.json\").write_text(\n",
    "        json.dumps(log_payload, ensure_ascii=False, indent=2),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "    # Update master\n",
    "    with master_lock:\n",
    "        master_innov[trial_hash] = mapped\n",
    "        MASTER_INNOV_PATH.write_text(\n",
    "            json.dumps(master_innov, ensure_ascii=False, indent=2),\n",
    "            encoding=\"utf-8\"\n",
    "        )\n",
    "\n",
    "    with counter_lock:\n",
    "        innov_counter[\"processed\"] += 1\n",
    "        if innov_counter[\"processed\"] % 50 == 0:\n",
    "            print(f\"Progress: processed {innov_counter['processed']} trials for innovation status...\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# LOAD & MERGE DATA\n",
    "# -------------------------------------------------\n",
    "# Load breakdown (investigational products + all drug-role cols)\n",
    "df_breakdown = pd.read_csv(PRODUCT_BREAKDOWN_CSV, dtype=str).fillna(\"\")\n",
    "\n",
    "df_breakdown[\"investigational_products_parsed\"] = df_breakdown[\"investigational_products\"].apply(parse_listish)\n",
    "mask_has_inv = df_breakdown[\"investigational_products_parsed\"].apply(lambda x: len(x) > 0)\n",
    "\n",
    "# Restrict to rows with investigational products\n",
    "df_breakdown_sub = df_breakdown.loc[mask_has_inv].copy()\n",
    "\n",
    "# All columns from trial_product_breakdown.csv except trial_hash (which is already separate)\n",
    "BREAKDOWN_COLS = [c for c in df_breakdown_sub.columns if c != \"trial_hash\"]\n",
    "\n",
    "# Load raw trials (for RELEVANT_COLS)\n",
    "df_trials = pd.read_csv(TRIALS_WITH_HASH_CSV, dtype=str).fillna(\"\")\n",
    "\n",
    "# Merge on trial_hash; keep all breakdown columns + investigational_products_parsed + RELEVANT_COLS\n",
    "df_merged = df_breakdown_sub.merge(\n",
    "    df_trials[[\"trial_hash\"] + RELEVANT_COLS],\n",
    "    on=\"trial_hash\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "innov_rows = df_merged.to_dict(orient=\"records\")\n",
    "total_innov = len(innov_rows)\n",
    "print(f\"Loaded {total_innov} trials with investigational products for innovation-status classification.\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# RUN CONCURRENTLY\n",
    "# -------------------------------------------------\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS_INNOV) as ex:\n",
    "    futures = {\n",
    "        ex.submit(process_innov_row, row, idx, total_innov, BREAKDOWN_COLS): row.get(\"trial_hash\")\n",
    "        for idx, row in enumerate(innov_rows, start=1)\n",
    "    }\n",
    "    for fut in as_completed(futures):\n",
    "        th = futures[fut]\n",
    "        try:\n",
    "            fut.result()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Worker error (innovation) trial_hash={th}: {e}\")\n",
    "\n",
    "print(\n",
    "    f\"Trial investigational-drug innovation classification complete. \"\n",
    "    f\"processed={innov_counter['processed']}, \"\n",
    "    f\"skipped={innov_counter['skipped_existing']}, \"\n",
    "    f\"llm_error={innov_counter['llm_error']}, \"\n",
    "    f\"parse_error={innov_counter['parse_error']}, \"\n",
    "    f\"coverage_error={innov_counter['coverage_error']}\"\n",
    ")\n",
    "print(f\"Classifications directory: {INNOV_DIR}\")\n",
    "print(f\"Log directory:             {INNOV_LOG_DIR}\")\n",
    "print(f\"Master classifications:    {MASTER_INNOV_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2c10a2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== LLM COST SUMMARY ==========\n",
      "Total LLM cost:             $1.9217\n",
      "Number of logged trials:     180\n",
      "Average cost per trial:      $0.0107\n",
      "\n",
      "Top 10 most expensive trials:\n",
      "  tid_9727cefa81bf0a9c341273bce42d3346.json: $0.0349\n",
      "  tid_261f0233308ca080d1c60e3fda61ca85.json: $0.0265\n",
      "  tid_8b4d60a5fddc078962af34399d7e342c.json: $0.0257\n",
      "  tid_eb1667b5d18009748ec8618dbdc9c665.json: $0.0256\n",
      "  tid_94883aa2d583afced004e22a7991ef3e.json: $0.0220\n",
      "  tid_feede52527d9398412e271be90f95486.json: $0.0213\n",
      "  tid_b7bfcfc03f35aef9374d0648fbd16da4.json: $0.0184\n",
      "  tid_9dc4ace9308864c9f8a619d6abe32011.json: $0.0180\n",
      "  tid_43635104c2d64be16c8882a500dd5181.json: $0.0174\n",
      "  tid_99fac3ebe48aad5ebc1077142f61d5eb.json: $0.0173\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "LOG_DIR = Path(\"cache/trial_investigational_drugs_classifications_log\")\n",
    "\n",
    "total_cost = 0.0\n",
    "num_entries = 0\n",
    "costs = []\n",
    "\n",
    "for fp in LOG_DIR.glob(\"*.json\"):\n",
    "    try:\n",
    "        log = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "        c = float(log.get(\"total_cost\") or 0.0)\n",
    "        total_cost += c\n",
    "        costs.append((fp.name, c))\n",
    "        num_entries += 1\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {fp.name}: {e}\")\n",
    "\n",
    "# Sort descending by cost\n",
    "costs_sorted = sorted(costs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"========== LLM COST SUMMARY ==========\")\n",
    "print(f\"Total LLM cost:             ${total_cost:,.4f}\")\n",
    "print(f\"Number of logged trials:     {num_entries}\")\n",
    "if num_entries > 0:\n",
    "    print(f\"Average cost per trial:      ${total_cost / num_entries:,.4f}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Top 10 most expensive trials:\")\n",
    "for name, c in costs_sorted[:10]:\n",
    "    print(f\"  {name}: ${c:,.4f}\")\n",
    "\n",
    "print(\"========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bebf824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved investigational drug classifications to cache/trial_investigational_drugs_classifications.csv\n",
      "| trial_hash                           | investigational_products                      | investigational_products_classifications   |\n",
      "|:-------------------------------------|:----------------------------------------------|:-------------------------------------------|\n",
      "| tid_0541995757b10e613a42173d6b8ddc09 | [\"cinacalcet hydrochloride (test)\"]           | [\"Generic\"]                                |\n",
      "| tid_0da20e863cfc5f3e369868462bff74e0 | [\"NuPIAO\"]                                    | [\"Innovative\"]                             |\n",
      "| tid_0e8fa21079f928135dfc6164a15285f8 | [\"SSS-17\"]                                    | [\"Innovative\"]                             |\n",
      "| tid_0f04ddb3d522d528d083d7d5c43d1e18 | [\"Metformin hydrochloride sustained-release\"] | [\"Generic\"]                                |\n",
      "| tid_10562c0430b8b9bae93c94cadfb0a129 | [\"RD-01\"]                                     | [\"Innovative\"]                             |\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "OUT_CSV = BASE_DIR / \"trial_investigational_drugs_classifications.csv\"\n",
    "\n",
    "rows = []\n",
    "\n",
    "for fp in INNOV_DIR.glob(\"*.json\"):\n",
    "    try:\n",
    "        obj = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {fp.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    trial_hash = obj.get(\"trial_hash\")\n",
    "    if not trial_hash:\n",
    "        print(f\"⚠️ Missing trial_hash in {fp.name}, skipping\")\n",
    "        continue\n",
    "\n",
    "    inv_products_raw = obj.get(\"investigational_products\") or []\n",
    "    classifications_map = obj.get(\"classifications\") or {}\n",
    "\n",
    "    flat_products = []\n",
    "    flat_classifications = []\n",
    "\n",
    "    for drug_raw in inv_products_raw:\n",
    "        # drug_raw might be \"['inetetamab', 'toripalimab']\" or just \"SSGJ-707\"\n",
    "        if isinstance(drug_raw, str):\n",
    "            parsed_names = parse_listish(drug_raw)  # from earlier cell (uses ast.literal_eval)\n",
    "        else:\n",
    "            parsed_names = [drug_raw]\n",
    "\n",
    "        # Prefer classification using the exact key that was sent to the model\n",
    "        meta = classifications_map.get(drug_raw, {})\n",
    "        cls = meta.get(\"classification\", \"\")\n",
    "\n",
    "        # If not found, try each parsed name as a key\n",
    "        if not cls:\n",
    "            for name in parsed_names:\n",
    "                meta_n = classifications_map.get(name, {})\n",
    "                if \"classification\" in meta_n:\n",
    "                    cls = meta_n.get(\"classification\", \"\")\n",
    "                    break\n",
    "\n",
    "        if not cls:\n",
    "            print(\n",
    "                f\"⚠️ Missing classification for raw drug {drug_raw!r} in \"\n",
    "                f\"trial_hash={trial_hash}, file={fp.name}\"\n",
    "            )\n",
    "\n",
    "        # Add one entry per parsed name so both lists are flat and aligned\n",
    "        for name in parsed_names:\n",
    "            flat_products.append(name)\n",
    "            flat_classifications.append(cls)\n",
    "\n",
    "    # Sanity check: lengths must match\n",
    "    if len(flat_products) != len(flat_classifications):\n",
    "        print(\n",
    "            f\"⚠️ Length mismatch for trial_hash={trial_hash}: \"\n",
    "            f\"{len(flat_products)} products vs {len(flat_classifications)} classifications\"\n",
    "        )\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"trial_hash\": trial_hash,\n",
    "            # store as JSON stringified flat lists\n",
    "            \"investigational_products\": json.dumps(flat_products, ensure_ascii=False),\n",
    "            \"investigational_products_classifications\": json.dumps(flat_classifications, ensure_ascii=False),\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_out = pd.DataFrame(rows).sort_values(\"trial_hash\")\n",
    "\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved investigational drug classifications to {OUT_CSV}\")\n",
    "print(df_out.head().to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a96291d",
   "metadata": {},
   "source": [
    "#### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "24ce1036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 drug entries (did_*) to process\n",
      "Calcimimetic; calcium-sensing receptor agonist || already processed for did_7062b42d2ed6ae1765a37cbc17d49ece\n",
      "Erythropoietin receptor agonist; Erythropoietin receptor ago || already processed for did_1e8e96e5a2857a7645534e99f20928b7\n",
      "HIF-prolyl hydroxylase inhibitor; Hypoxia-inducible factor a || already processed for did_3be5e5c89d552d2f9929a4feff6cd5d0\n",
      "Biguanide; gluconeogenesis inhibitor; insulin sensitizer || already processed for did_8325e44a148075cfd7a264d89c96b30b\n",
      "Biguanide; gluconeogenesis inhibitor; insulin sensitizer || already processed for did_6f2fed8e626e7d1238e8d15a3104a42b\n",
      "Erythropoiesis-stimulating agent (pegylated recombinant huma || already processed for did_863659a6cafeb92ebc045c196b94d238\n",
      "Thrombopoietin agonist; Thrombopoietin receptor agonist; Thr || already processed for did_5f62b80e297edbcbfb1bb211062834e9\n",
      "HER2/PD-1 bispecific antibody; PD-1/HER2 bispecific antibody || already processed for did_77f76adb85405f4c35c97b1fd7953e03\n",
      "PD-1 monoclonal antibody; PD-1 monoclonal antibody (immune c || already processed for did_1f4ce1ae9e17172cefaca6730349a3be\n",
      "Antimetabolite (prodrug of 5-FU); thymidylate synthase inhib || already processed for did_3b24156ad560a696116454056bc88ab4\n",
      "Platinum DNA crosslinking agent; Platinum-based DNA crosslin || already processed for did_088d6dc6ddb3113e9b902711ccdfafef\n",
      "Antifolate antimetabolite; Antimetabolite (inhibitor of DHFR || already processed for did_194309a52da9de185b531cfc697cfca8\n",
      "DNA crosslinking platinum agent; Platinum-based DNA crosslin || already processed for did_120ca817ebe8caa71e92ac53049b2c6a\n",
      "Microtubule stabilizer (taxane); Taxane (tubulin inhibitor); || already processed for did_ee364229b2791d1ef9355708eff0ba34\n",
      "PD-1/PD-L1 bispecific antibody (immune checkpoint inhibitor) || already processed for did_213aca6490a68c3e930220223f6d8028\n",
      "Anti-IL-5 humanized monoclonal antibody; Anti-IL-5 monoclona || already processed for did_1f14d108f7e5edaaa683c580c5298d1d\n",
      "BCL2/BCL-XL inhibitor || already processed for did_4ab52371762b735317125e6446a51e8f\n",
      "PD-1/VEGF bispecific antibody || already processed for did_8709147691d5e6cbe19cfb99dd19d33d\n",
      "Thrombopoietin receptor agonist; Thrombopoietin receptor ago || already processed for did_40b393d7b1a09e0eda62340f2baac8f2\n",
      "HER2-targeted humanized monoclonal antibody; HER2-targeted m || already processed for did_caa0fe665af380b663e4cd90f4e976c8\n",
      "TNF alpha antagonist (TNFR-Fc fusion protein); TNF receptor  || already processed for did_0cd40d0d78426ac13b20b036e0ab6f9d\n",
      "Humanized monoclonal antibody (TNF-alpha antagonist); Monocl || already processed for did_b68691259764267768d7aafbfb1b07fc\n",
      "mTOR kinase inhibitor || already processed for did_905887323bb1da663485a41adcca186a\n",
      "PD-1 antagonist monoclonal antibody; PD-1 antagonist monoclo || already processed for did_f337d88f0e353df021345848aebfa91d\n",
      "HER2-targeted monoclonal antibody || already processed for did_c1bf083e0d09941f097cbe30648a588d\n",
      "Taxane (tubulin inhibitor); Taxane tubulin inhibitor; taxane || already processed for did_077b83af57538aa183971a2fe0971ec1\n",
      "Humanized monoclonal antibody; angiogenesis inhibitor (anti- || already processed for did_db55b70c7f59ea9507f18c7110bce1ab\n",
      "Anti-IL-17A humanized monoclonal antibody; Anti-IL-17A human || already processed for did_667a0b7862bb9382e28a19b634fc7f3c\n",
      "TNF-alpha antagonist monoclonal antibody || already processed for did_996740de914ced0902e686373e319391\n",
      "Kappa-opioid receptor agonist || already processed for did_391d0b7b69bc5432cf86a0d473110ed8\n",
      "SIRPα-Fc fusion protein (CD47 antagonist; immune checkpoint  || already processed for did_02270665c74dfcd2765c037cf22771a4\n",
      "Anti-HER2 humanized monoclonal antibody; Humanized anti-HER2 || already processed for did_9868de7d15bae3816653aa9fad6cf106\n",
      "PEGylated recombinant uricase (urate oxidase) enzyme; Pegyla || already processed for did_9ef248df74556f4768271660f5ef5f7b\n",
      "PD-1/LAG-3 bispecific antibody; Unidentified pharmacological || already processed for did_1ea07f22fea050e733d105558b46fc19\n",
      "Erythropoietin receptor agonist || already processed for did_06a552b36816022643150a234e4eb23e\n",
      "Low molecular weight heparin; indirect Factor Xa and thrombi || already processed for did_fac661be5cc6c6ea00ff1758dff644b3\n",
      "Low molecular weight heparin; indirect Factor Xa and thrombi || already processed for did_c6d4eb15f1e84a36eff58eca3627c82e\n",
      "Anti-VEGF humanized monoclonal antibody; Humanized monoclona || already processed for did_917fb629a072adaa792fe3a16ac0bd08\n",
      "Anti-VEGF monoclonal antibody fragment (Fab); Monoclonal ant || already processed for did_1e963a1d2b57f85203e9fc58a78e7018\n",
      "Platinum-based DNA crosslinker; platinum-based DNA crosslink || already processed for did_ba9fab001f67381e56e410575874d967\n",
      "Antimetabolite (pyrimidine analog); thymidylate synthase inh || already processed for did_51b7f28943a5d99b071833e9886fd1fe\n",
      "Monoclonal antibody (PSGL-1 antagonist; immune checkpoint in || already processed for did_9aff2665c3ecf996ae91e7b69d0d3419\n",
      "Monoclonal antibody (PD-1 antagonist; immune checkpoint inhi || already processed for did_e214786a5ff033e8ad5d57501bf82a16\n",
      "Janus kinase (JAK) inhibitor || already processed for did_cd722944ff52dc7009e0ba0db865b7e8\n",
      "Janus kinase (JAK) inhibitor || already processed for did_3570b5f72981d5b8610852a8d33a6f27\n",
      "Erythropoietin receptor agonist || already processed for did_ce476323fc088abd55d5c54c34995350\n",
      "Monoclonal antibody (IL-33 antagonist) || already processed for did_312610104f7da24984fdfde55a3b9265\n",
      "Fixed-dose combination of nucleoside analog (trifluridine) a || already processed for did_c3a941a16fbfba31e93846fcf19489ee\n",
      "Fixed-dose combination of nucleoside analog (trifluridine) a || already processed for did_4fa87f4ab207dc8c3e6126a0b7734d3c\n",
      "Chimeric anti-CD20 monoclonal antibody; Chimeric anti-CD20 m || already processed for did_bd1bb6b87180689231804f4ceb383485\n",
      "Chimeric anti-CD20 monoclonal antibody || already processed for did_adf880d5c8986bd0deb6423c92c9d948\n",
      "Thrombopoietin receptor agonist; recombinant cytokine || already processed for did_e27a6e93cb00930fb0b5c1a533b0df88\n",
      "Anti-IL-4Rα humanized monoclonal antibody; Humanized IgG4 mo || already processed for did_90ce1e192a88f1ec48bae75c3a516fb5\n",
      "PD-1 monoclonal antibody || already processed for did_724c8bee82317a5635cb82949405cb4f\n",
      "Anti–IL-1β humanized monoclonal antibody; Humanized monoclon || already processed for did_260dfcb78fefa1c82a2c3fe6702ae645\n",
      "Cytotoxic chemotherapy; Cytotoxic chemotherapy (unspecified) || already processed for did_624e50d2bca9c6314160403c2f83bc0c\n",
      "Non-absorbed polymeric phosphate binder (anion-exchange resi || already processed for did_a5618be8a468853911fd4a8e162eb623\n",
      "Complement C3b inhibitor; Unidentified pharmacological activ || already processed for did_ca91588b3a6b9581e7efc7b8f49e3acf\n",
      "Disease-modifying antirheumatic drug (unspecified) || already processed for did_297de1592f2fb79bb2823e5c1a41771f\n",
      "Opioid kappa receptor agonist || already processed for did_9b0f4932ee013ec1b2afb5057c2d34e8\n",
      "DNA topoisomerase I inhibitor || already processed for did_bb724df6fba7591838d311c31c465dc5\n",
      "TL1A (TNFSF15) antagonist || already processed for did_52e2991b71ae379446e45783b6106ec1\n",
      "Erythropoietin receptor agonist || already processed for did_fc2e6a440b94f64831840137698021e1\n",
      "TNF receptor-Fc fusion protein; TNF-alpha antagonist; TNF re || already processed for did_2d36b5821f8affc6868b59dfc9af6c9f\n",
      "Chimeric anti-EGFR monoclonal antibody (cetuximab biosimilar || already processed for did_42d577941d42ba1de11e23427f6e5d4c\n",
      "Chimeric monoclonal antibody EGFR antagonist; EGFR antagonis || already processed for did_f670ef5d2d6bdf8f29450a970494dd64\n",
      "Calcineurin inhibitor || already processed for did_02e8ca2ad17d56e17e1fc2edcbee4d40\n",
      "H1 receptor antagonist (antihistamine); Histamine H1 recepto || already processed for did_4ff25c60792fa2f9cb596e4666530aec\n",
      "Corticosteroid (glucocorticoid) agonist; Corticosteroid agon || already processed for did_13d7bacaeffaa43f1d6e5fa886547670\n",
      "Taxane microtubule stabilizer || already processed for did_95d674a4eb85adf92a242f0b46a24d1a\n",
      "Microtubule (tubulin) inhibitor || already processed for did_7d62a09f598662ce52495a7b49467973\n",
      "Humanized monoclonal antibody; BDCA2/CLEC4C antagonist || already processed for did_6d29b2b831dd6e918ce93b1c46df71e6\n",
      "Anti-HER2 monoclonal antibody; HER2 antagonist / HER2 tyrosi || already processed for did_c00b67c82a117f175e54574b2723b3cd\n",
      "Phosphodiesterase 4 inhibitor || already processed for did_3ceacd513e9ece1ad8b4b42b4c55aa3e\n",
      "Phosphodiesterase 4 inhibitor || already processed for did_88c9c159e8ca183ba0188b2303662550\n",
      "Anti-VEGF humanized monoclonal antibody || already processed for did_e7f3cdf35a158388e5c0f96420e0216c\n",
      "Erythropoietin receptor agonist || already processed for did_76ed1349ede88e27cd5d9af851e594da\n",
      "Histamine H1 receptor antagonist || already processed for did_8346db44a721fa863ca38180638bad3d\n",
      "Trispecific T-cell engaging antibody || already processed for did_c9c4fc1ebfedfaaee8262319fa20bac0\n",
      "Antimetabolite (dihydrofolate reductase inhibitor); Dihydrof || already processed for did_211cbc6c7d410d6372ec40eda30e8baa\n",
      "Bispecific CAR-T cell therapy || already processed for did_05cf22dcb225cea0be727d494986f6f9\n",
      "Calcineurin inhibitor || already processed for did_b59daa00d1e1374bd65a69362493b380\n",
      "Inosine monophosphate dehydrogenase inhibitor || already processed for did_d9dbc51dc534921589adf460c85cd824\n",
      "Corticosteroid || already processed for did_15f4d7d8386e78fc5ed49a02dd6bef94\n",
      "Interleukin-2 agonist || already processed for did_7b76aabbcca9301ca0f8604376a1908b\n",
      "Taxane microtubule stabilizer || already processed for did_4f5f4c42bd8b84cb379ef405bc5cf90f\n",
      "Vinca alkaloid microtubule inhibitor || already processed for did_264095b9e936a7831228d84f429f58c8\n",
      "Chimeric monoclonal antibody (TNF-alpha inhibitor) || already processed for did_1457c0d6bfcb4967418bfb8ac142f64a\n",
      "Interleukin-1 receptor antagonist || already processed for did_3f00436e3415eabeafb77ba1fe5b6f87\n",
      "Alkylating agent (DNA crosslinker); Alkylating agent (DNA cr || already processed for did_797d4cb7bd126ec1aced5691af658a88\n",
      "Anthracycline; topoisomerase II inhibitor; DNA/RNA synthesis || already processed for did_30ac4c52bd5bf0762504d49ecb92077d\n",
      "Corticosteroid; immunosuppressant || already processed for did_5ee786031eccc21675bb1d322d8c024a\n",
      "Vinca alkaloid; microtubule inhibitor || already processed for did_275db609ebbdc7b03e227c97bbfa1fc5\n",
      "⚠️ Empty mechanism list for did=did_14f5219735c03c9b814c4b99a887d5f5, skipping\n",
      "Monoclonal antibody (BDCA2/CLEC4C antagonist); Monoclonal an || already processed for did_94ab773edc2a0a7be75541f8f3ff43fa\n",
      "Anti-NGF monoclonal antibody; Humanized monoclonal antibody; || already processed for did_3c3cc608d5b0f0372565a809c82fb193\n",
      "Corticosteroid (glucocorticoid receptor agonist) || already processed for did_601a960a247e8776ec2b0425761a94ef\n",
      "Immunosuppressant || already processed for did_d980ca60aa83275039bc9406d21a2726\n",
      "Antimalarial || already processed for did_c4a3e7f5a77ae5d7a72ad60e18467696\n",
      "Chimeric anti-EGFR monoclonal antibody; Chimeric monoclonal  || already processed for did_182d516d54f5547d6f562ff65f623f75\n",
      "Small-molecule thrombopoietin receptor agonist; Thrombopoiet || already processed for did_bc2a0cc8f8b4ac6f758b528c430d1d17\n",
      "Thrombopoietin receptor agonist; Thrombopoietin receptor ago || already processed for did_6bbf194c8de8177cb0942bf4620eac11\n",
      "Alkylating agent (DNA crosslinker) || already processed for did_2c2fb9efd4b8a1f837bf47004a49ce45\n",
      "Dual PD-1/TGF-beta antagonist immunotherapy || already processed for did_80a8d1abab46f48788f6fb90a898d229\n",
      "Erythropoietin receptor agonist || already processed for did_c7e768a43cec82484eb8574b5258d16c\n",
      "Thrombopoietin receptor agonist || already processed for did_a27e7a831553d5c182179b8154a20f60\n",
      "Monoclonal antibody || already processed for did_0c651b9889bb8badce3de429cf39f99f\n",
      "Anti-VEGF monoclonal antibody (angiogenesis inhibitor); Anti || already processed for did_66be31e4c40d676991f2405aaecc6934\n",
      "Folate analog (leucovorin); chemomodulator || already processed for did_3adcd252cbea832dd6e9443fc0789dd5\n",
      "Monoclonal antibody (PD-1 inhibitor) || already processed for did_22259ee6329364cebbe4c40bd951f307\n",
      "Taxane chemotherapy (microtubule stabilizer) || already processed for did_1b75a3a0dc0659ce560001fc65987bd1\n",
      "Erythropoietin receptor agonist || already processed for did_da3d1c04a0f5d78302f0db830fdcb4da\n",
      "Anti-CD25 humanized monoclonal antibody || already processed for did_e9c46fbd9f4b5dd58e5f5b297670dc19\n",
      "IL-15 immunocytokine (B7-H3-targeted antibody-cytokine fusio || already processed for did_0d92ee7b118cc89aab1fa1bcaf5e2505\n",
      "DNA topoisomerase I inhibitor || already processed for did_9375e58c8325b652f623d22b5e9fda3f\n",
      "Cyclooxygenase inhibitor (NSAID) || already processed for did_1c30c8722bc846ce1dec08974bbe5cbf\n",
      "Cancer vaccine || already processed for did_99cc8493c2392e2b0f5d61bb0220b474\n",
      "Interleukin-1 receptor antagonist || already processed for did_2b3bf3eee2475e03885a110e9acaab61\n",
      "Folinic acid chemosensitizer || already processed for did_26013ffde5413a2b062afa00935c8cca\n",
      "Completed 133 drug entries with at least one PubMed hit. Files written to cache/investigational_drug_moa_pubmed_search\n"
     ]
    }
   ],
   "source": [
    "# PubMed search for each drug's MOA (HASH-BASED OUTPUT FILENAMES)\n",
    "\n",
    "import os, json, time, html, unicodedata\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "from services.openai_wrapper import OpenAIWrapper\n",
    "\n",
    "# -----------------------------\n",
    "# Paths / Config\n",
    "# -----------------------------\n",
    "BASE_DIR = Path(\"cache\")\n",
    "\n",
    "PRODUCT_MASTER_PATH = BASE_DIR / \"product_id_master_by_did.json\"\n",
    "OUT_DIR             = BASE_DIR / \"investigational_drug_moa_pubmed_search\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MASTER_INDEX_PATH   = BASE_DIR / \"investigational_drug_moa_pubmed_index.json\"\n",
    "\n",
    "EUTILS     = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\"\n",
    "API_KEY    = os.getenv(\"NCBI_API_KEY\") or None\n",
    "EMAIL      = os.getenv(\"NCBI_EMAIL\") or None\n",
    "SLEEP      = 0.25\n",
    "RETRY_MAX  = 3\n",
    "RETRY_WAIT = 1.0\n",
    "\n",
    "# LLM config (for MOA refinement)\n",
    "MODEL  = \"gpt-5-mini\"   # adjust if needed\n",
    "client = OpenAIWrapper()\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "NAN_STRINGS = {\"nan\", \"none\", \"null\", \"\"}\n",
    "\n",
    "def _clean(s):\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s_str = str(s).strip()\n",
    "    return \"\" if s_str.lower() in NAN_STRINGS else s_str\n",
    "\n",
    "def norm_text(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    t = html.unescape(s)\n",
    "    t = unicodedata.normalize(\"NFKC\", t)\n",
    "    t = \" \".join(t.strip().lower().split())\n",
    "    return \"\" if t in NAN_STRINGS else t\n",
    "\n",
    "def _http_get_with_retry(url: str, params: dict, timeout: int) -> requests.Response:\n",
    "    last_err = None\n",
    "    for attempt in range(1, RETRY_MAX + 1):\n",
    "        try:\n",
    "            r = requests.get(url, params=params, timeout=timeout)\n",
    "            r.raise_for_status()\n",
    "            return r\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            if attempt < RETRY_MAX:\n",
    "                time.sleep(RETRY_WAIT)\n",
    "            else:\n",
    "                raise last_err\n",
    "\n",
    "def esearch_ids(term: str, n: int = 3) -> list[str]:\n",
    "    term = _clean(term)\n",
    "    if not term:\n",
    "        return []\n",
    "    params = {\n",
    "        \"db\": \"pubmed\",\n",
    "        \"term\": term,\n",
    "        \"retmode\": \"json\",\n",
    "        \"retmax\": n,\n",
    "        \"sort\": \"relevance\",\n",
    "    }\n",
    "    if API_KEY:\n",
    "        params[\"api_key\"] = API_KEY\n",
    "    if EMAIL:\n",
    "        params[\"email\"] = EMAIL\n",
    "    r = _http_get_with_retry(f\"{EUTILS}/esearch.fcgi\", params=params, timeout=30)\n",
    "    return r.json().get(\"esearchresult\", {}).get(\"idlist\", []) or []\n",
    "\n",
    "def _parse_xml_with_retry(text: str) -> ET.Element:\n",
    "    last_err = None\n",
    "    for attempt in range(1, RETRY_MAX + 1):\n",
    "        try:\n",
    "            return ET.fromstring(text)\n",
    "        except ET.ParseError as e:\n",
    "            last_err = e\n",
    "            if attempt < RETRY_MAX:\n",
    "                time.sleep(RETRY_WAIT)\n",
    "            else:\n",
    "                raise last_err\n",
    "\n",
    "def efetch_details(pmids: list[str]) -> dict:\n",
    "    if not pmids:\n",
    "        return {}\n",
    "    params = {\"db\": \"pubmed\", \"id\": \",\".join(pmids), \"retmode\": \"xml\"}\n",
    "    if API_KEY:\n",
    "        params[\"api_key\"] = API_KEY\n",
    "    if EMAIL:\n",
    "        params[\"email\"] = EMAIL\n",
    "    r = _http_get_with_retry(f\"{EUTILS}/efetch.fcgi\", params=params, timeout=60)\n",
    "    root = _parse_xml_with_retry(r.text)\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    def text_from_el(el):\n",
    "        return \"\".join(el.itertext()).strip() if el is not None else \"\"\n",
    "\n",
    "    def join_abstract(abs_parent):\n",
    "        parts = []\n",
    "        for t in abs_parent.findall(\"AbstractText\"):\n",
    "            label = t.attrib.get(\"Label\")\n",
    "            txt = text_from_el(t)\n",
    "            if txt:\n",
    "                parts.append(f\"{label}: {txt}\" if label else txt)\n",
    "        return \"\\n\".join(parts).strip()\n",
    "\n",
    "    for art in root.findall(\".//PubmedArticle\"):\n",
    "        pmid_el = art.find(\".//MedlineCitation/PMID\")\n",
    "        if pmid_el is None or not (pmid_el.text or \"\").strip():\n",
    "            continue\n",
    "        pmid = pmid_el.text.strip()\n",
    "\n",
    "        title = text_from_el(art.find(\".//Article/ArticleTitle\"))\n",
    "        abs_parent = art.find(\".//Article/Abstract\")\n",
    "        abstract = join_abstract(abs_parent) if abs_parent is not None else \"\"\n",
    "\n",
    "        mesh_terms = []\n",
    "        for mh in art.findall(\".//MedlineCitation/MeshHeadingList/MeshHeading\"):\n",
    "            desc = mh.find(\"DescriptorName\")\n",
    "            if desc is None or not (desc.text or \"\").strip():\n",
    "                continue\n",
    "            d_text = desc.text.strip()\n",
    "            d_major = desc.attrib.get(\"MajorTopicYN\") == \"Y\"\n",
    "            d_str = f\"{d_text}{'*' if d_major else ''}\"\n",
    "\n",
    "            quals = []\n",
    "            for q in mh.findall(\"QualifierName\"):\n",
    "                q_text = (q.text or \"\").strip()\n",
    "                if q_text:\n",
    "                    q_major = q.attrib.get(\"MajorTopicYN\") == \"Y\"\n",
    "                    quals.append(f\"{q_text}{'*' if q_major else ''}\")\n",
    "\n",
    "            mesh_terms.append(d_str if not quals else d_str + \" / \" + \"; \".join(quals))\n",
    "\n",
    "        substances = []\n",
    "        for chem in art.findall(\".//Chemical\"):\n",
    "            nm_el = chem.find(\"NameOfSubstance\")\n",
    "            rn_el = chem.find(\"RegistryNumber\")\n",
    "            nm = nm_el.text.strip() if nm_el is not None else \"\"\n",
    "            rn = rn_el.text.strip() if rn_el is not None else \"\"\n",
    "            if nm and rn and rn != \"0\":\n",
    "                substances.append(f\"{nm} [RN:{rn}]\")\n",
    "            elif nm:\n",
    "                substances.append(nm)\n",
    "            elif rn and rn != \"0\":\n",
    "                substances.append(f\"[RN:{rn}]\")\n",
    "\n",
    "        def uniq(xs):\n",
    "            seen, out_local = set(), []\n",
    "            for x in xs:\n",
    "                if x and x not in seen:\n",
    "                    seen.add(x)\n",
    "                    out_local.append(x)\n",
    "            return out_local\n",
    "\n",
    "        out[pmid] = {\n",
    "            \"title\": title,\n",
    "            \"abstract\": abstract,\n",
    "            \"mesh_terms\": uniq(mesh_terms),\n",
    "            \"substances\": uniq(substances),\n",
    "        }\n",
    "\n",
    "    return out\n",
    "\n",
    "def save_json(path: Path, obj: dict):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    path.write_text(json.dumps(obj, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "def load_json_or_empty(path: Path) -> dict:\n",
    "    if not path.exists():\n",
    "        return {}\n",
    "    try:\n",
    "        return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def split_terms(s: str):\n",
    "    \"\"\"\n",
    "    For MOA strings like:\n",
    "      'Thrombopoietin receptor agonist (recombinant growth factor); PEGylated recombinant human EPO'\n",
    "    we split on ';' and treat each piece as a candidate search term.\n",
    "    \"\"\"\n",
    "    if not s:\n",
    "        return []\n",
    "    raw = [t.strip() for t in str(s).split(\";\")]\n",
    "    return [t for t in raw if t and t.lower() not in NAN_STRINGS]\n",
    "\n",
    "# --------------- LLM refinement helpers ---------------\n",
    "\n",
    "def build_moa_refinement_prompt(mechanism: str) -> str:\n",
    "    \"\"\"\n",
    "    Prompt the chatbot to turn a free-text MOA into a concise, canonical\n",
    "    mechanism-of-action phrase suitable for PubMed search.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "You are an expert clinical pharmacologist and mechanisms-of-action classifier.\n",
    "\n",
    "Given the following mechanism-of-action (MOA) description from a drug development database:\n",
    "\n",
    "\\\"\\\"\\\"{mechanism}\\\"\\\"\\\"\n",
    "\n",
    "Rewrite or condense it into a SHORT, CANONICAL mechanism-of-action term that would work well as a PubMed search term.\n",
    "\n",
    "Rules:\n",
    "- Output a concise mechanism class or well-recognized pharmacologic concept, not a full sentence.\n",
    "- Prefer standard pharmacologic/mechanistic classes (e.g. \"Ion Exchange Resins\", \"Immunocytokines\",\n",
    "  \"Kinase Inhibitors\", \"Antibodies, Monoclonal\", \"Immune Checkpoint Inhibitors\").\n",
    "- Do NOT include long target listings or extra explanation.\n",
    "- If the original MOA is already an appropriate concise search term, you may return it unchanged.\n",
    "\n",
    "Return ONLY the refined mechanism phrase, with no additional explanation or formatting.\n",
    "\"\"\".strip()\n",
    "\n",
    "def refine_mechanism_with_llm(mechanism: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Use the OpenAIWrapper .query() interface to get a refined mechanism phrase.\n",
    "    Returns the refined phrase or None on failure.\n",
    "    \"\"\"\n",
    "    mech_clean = _clean(mechanism)\n",
    "    if not mech_clean:\n",
    "        return None\n",
    "\n",
    "    prompt = build_moa_refinement_prompt(mech_clean)\n",
    "\n",
    "    try:\n",
    "        res = client.query(prompt=prompt, model=MODEL)\n",
    "        text = (res.get(\"text_response\") or \"\").strip()\n",
    "        # Strip surrounding quotes if the model adds them\n",
    "        text = text.strip().strip('\"').strip(\"'\")\n",
    "        refined = _clean(text)\n",
    "        return refined or None\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ LLM refinement failed for mechanism='{mech_clean[:80]}': {e}\")\n",
    "        return None\n",
    "\n",
    "# -----------------------------\n",
    "# Load product master (by did)\n",
    "# -----------------------------\n",
    "product_master_by_did = load_json_or_empty(PRODUCT_MASTER_PATH)\n",
    "if not product_master_by_did:\n",
    "    raise RuntimeError(f\"No product entries found in {PRODUCT_MASTER_PATH}\")\n",
    "\n",
    "master_index = load_json_or_empty(MASTER_INDEX_PATH) or {}\n",
    "\n",
    "total = len(product_master_by_did)\n",
    "print(f\"{total} drug entries (did_*) to process\")\n",
    "processed = 0\n",
    "\n",
    "# -----------------------------\n",
    "# Main loop: one PubMed search per DRUG (by did)\n",
    "# -----------------------------\n",
    "for did, rec in product_master_by_did.items():\n",
    "    # Skip if already indexed\n",
    "    if did in master_index:\n",
    "        mech_list = rec.get(\"product_mechanisms\", []) or []\n",
    "        mech_preview = \"; \".join(mech_list)[:60]\n",
    "        print(f\"{mech_preview} || already processed for {did}\")\n",
    "        processed += 1\n",
    "        continue\n",
    "\n",
    "    # product_mechanisms is a list; join into a single string for a \"combo\" key,\n",
    "    # but we'll search EACH mechanism (and its ';'-split pieces) separately.\n",
    "    mech_list = rec.get(\"product_mechanisms\", []) or []\n",
    "    mechanism = _clean(\"; \".join(mech_list))\n",
    "    if not mechanism:\n",
    "        print(f\"⚠️ Empty mechanism list for did={did}, skipping\")\n",
    "        continue\n",
    "\n",
    "    mech_key = norm_text(mechanism)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Build candidate search terms\n",
    "    # -----------------------------\n",
    "    # For MOAs: search EACH mechanism string (and each ';'-split subterm).\n",
    "    mechanism_terms: list[str] = []\n",
    "    for mech in mech_list:\n",
    "        mech = _clean(mech)\n",
    "        if not mech:\n",
    "            continue\n",
    "        subterms = split_terms(mech)\n",
    "        if not subterms:\n",
    "            subterms = [mech]\n",
    "        for t in subterms:\n",
    "            t_clean = _clean(t)\n",
    "            if t_clean and t_clean not in mechanism_terms:\n",
    "                mechanism_terms.append(t_clean)\n",
    "\n",
    "    # For molecular targets: direct terms\n",
    "    target_terms: list[str] = []\n",
    "    for tgt in rec.get(\"molecular_targets\", []) or []:\n",
    "        t_clean = _clean(tgt)\n",
    "        if t_clean and t_clean not in target_terms:\n",
    "            target_terms.append(t_clean)\n",
    "\n",
    "    if not mechanism_terms and not target_terms:\n",
    "        print(f\"⚠️ No usable mechanism or target terms for did={did}, skipping\")\n",
    "        continue\n",
    "\n",
    "    tried_terms: list[str] = []\n",
    "    first_hit_term: str | None = None\n",
    "    llm_refined: str | None = None\n",
    "\n",
    "    # Detailed per-term results\n",
    "    mechanism_search: dict[str, dict] = {}\n",
    "    target_search: dict[str, dict] = {}\n",
    "\n",
    "    # Aggregate across all searches for summary\n",
    "    all_pmids: set[str] = set()\n",
    "    all_records: dict[str, dict] = {}\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) Mechanism term searches\n",
    "    # -----------------------------\n",
    "    for term in mechanism_terms:\n",
    "        tried_terms.append(term)\n",
    "        query = f\"\\\"{term}\\\"\"\n",
    "        try:\n",
    "            pmids = esearch_ids(query, n=5)\n",
    "        except Exception:\n",
    "            pmids = []\n",
    "\n",
    "        records = {}\n",
    "        if pmids:\n",
    "            try:\n",
    "                records = efetch_details(pmids)\n",
    "            except Exception as e:\n",
    "                records = {\"_error\": str(e)}\n",
    "\n",
    "            # Track first term that hits\n",
    "            if first_hit_term is None and pmids:\n",
    "                first_hit_term = term\n",
    "\n",
    "            for p in pmids:\n",
    "                all_pmids.add(p)\n",
    "                if p not in all_records and p in records:\n",
    "                    all_records[p] = records[p]\n",
    "\n",
    "        mechanism_search[term] = {\n",
    "            \"pmids\": pmids,\n",
    "            \"records\": records,\n",
    "        }\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2) LLM refinement if NO mechanism hits\n",
    "    # -----------------------------\n",
    "    if not all_pmids:\n",
    "        llm_refined = refine_mechanism_with_llm(mechanism)\n",
    "        if llm_refined:\n",
    "            llm_term_key = llm_refined  # store as-is\n",
    "            tried_terms.append(llm_refined + \" [LLM]\")\n",
    "            query = f\"\\\"{llm_refined}\\\"\"\n",
    "            try:\n",
    "                pmids = esearch_ids(query, n=5)\n",
    "            except Exception:\n",
    "                pmids = []\n",
    "\n",
    "            records = {}\n",
    "            if pmids:\n",
    "                try:\n",
    "                    records = efetch_details(pmids)\n",
    "                except Exception as e:\n",
    "                    records = {\"_error\": str(e)}\n",
    "\n",
    "                if first_hit_term is None and pmids:\n",
    "                    first_hit_term = llm_refined\n",
    "\n",
    "                for p in pmids:\n",
    "                    all_pmids.add(p)\n",
    "                    if p not in all_records and p in records:\n",
    "                        all_records[p] = records[p]\n",
    "\n",
    "            mechanism_search[llm_term_key] = {\n",
    "                \"pmids\": pmids,\n",
    "                \"records\": records,\n",
    "                \"llm_refined\": True,\n",
    "            }\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3) Molecular target term searches (10 PMIDs each)\n",
    "    # -----------------------------\n",
    "    for term in target_terms:\n",
    "        tried_terms.append(term)\n",
    "        query = f\"\\\"{term}\\\"\"\n",
    "        try:\n",
    "            pmids = esearch_ids(query, n=10)  # ← 10 studies per target term\n",
    "        except Exception:\n",
    "            pmids = []\n",
    "\n",
    "        records = {}\n",
    "        if pmids:\n",
    "            try:\n",
    "                records = efetch_details(pmids)\n",
    "            except Exception as e:\n",
    "                records = {\"_error\": str(e)}\n",
    "\n",
    "            if first_hit_term is None and pmids:\n",
    "                first_hit_term = term\n",
    "\n",
    "            for p in pmids:\n",
    "                all_pmids.add(p)\n",
    "                if p not in all_records and p in records:\n",
    "                    all_records[p] = records[p]\n",
    "\n",
    "        target_search[term] = {\n",
    "            \"pmids\": pmids,\n",
    "            \"records\": records,\n",
    "        }\n",
    "\n",
    "    # 4) If STILL no PMIDs at all, skip saving (so you can rerun later)\n",
    "    if not all_pmids:\n",
    "        print(f\"⚠️ No PubMed hits for did={did} after mechanisms + targets + LLM, skipping\")\n",
    "        continue\n",
    "\n",
    "    # -----------------------------\n",
    "    # HASH-BASED OUTPUT (BY did)\n",
    "    # -----------------------------\n",
    "    fname    = f\"{did}.json\"\n",
    "    out_path = OUT_DIR / fname\n",
    "\n",
    "    payload = {\n",
    "        \"type\": \"drug_moa_pubmed_search\",\n",
    "        \"did\": did,\n",
    "        \"tt_drug_id\": rec.get(\"tt_drug_id\"),\n",
    "        \"drug_names\": rec.get(\"drug_names\", []),\n",
    "        \"alternative_names\": rec.get(\"alternative_names\", []),\n",
    "        \"molecular_targets\": rec.get(\"molecular_targets\", []),\n",
    "        \"product_mechanisms\": mech_list,\n",
    "        \"mechanism_combined\": mechanism,\n",
    "        \"mechanism_key\": mech_key,\n",
    "        \"tried_terms\": tried_terms,\n",
    "        \"llm_refined_mechanism\": llm_refined,\n",
    "        # New detailed breakdowns:\n",
    "        \"mechanism_search\": mechanism_search,\n",
    "        \"target_search\": target_search,\n",
    "        # Backward-compatible summary:\n",
    "        \"match\": {\n",
    "            \"term\": first_hit_term,\n",
    "            \"pmids\": sorted(all_pmids),\n",
    "            \"records\": all_records,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    save_json(out_path, payload)\n",
    "\n",
    "    # Index entry keyed by did (summary only, as before)\n",
    "    master_index[did] = {\n",
    "        \"did\": did,\n",
    "        \"tt_drug_id\": rec.get(\"tt_drug_id\"),\n",
    "        \"drug_names\": rec.get(\"drug_names\", []),\n",
    "        \"product_mechanisms\": mech_list,\n",
    "        \"mechanism_combined\": mechanism,\n",
    "        \"mechanism_key\": mech_key,\n",
    "        \"json_path\": f\"{OUT_DIR.name}/{fname}\",\n",
    "        \"pmids\": sorted(all_pmids),\n",
    "        \"matched_term\": first_hit_term,\n",
    "        \"llm_refined_mechanism\": llm_refined,\n",
    "    }\n",
    "    save_json(MASTER_INDEX_PATH, master_index)\n",
    "\n",
    "    processed += 1\n",
    "    if processed % 50 == 0:\n",
    "        print(f\"Processed {processed}/{total}…\")\n",
    "\n",
    "    time.sleep(SLEEP)\n",
    "\n",
    "save_json(MASTER_INDEX_PATH, master_index)\n",
    "print(f\"Completed {processed} drug entries with at least one PubMed hit. Files written to {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "66fdab87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 133 MOA PubMed-search files for MeSH-term selection.\n",
      "MOA MeSH-term selection complete. processed=0, skipped=133, llm_error=0, parse_error=0, coverage_error=0, no_candidates=0\n",
      "Chosen MOA directory: cache/investigational_drug_moa_chosen\n",
      "Log directory:        cache/investigational_drug_moa_chosen_log\n",
      "Master choices:       cache/investigational_drug_moa_chosen_master.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "from services.openai_wrapper import OpenAIWrapper  # your wrapper\n",
    "\n",
    "# -------------------------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------------------------\n",
    "BASE_DIR = Path(\"cache\")\n",
    "\n",
    "MOA_PUBMED_DIR        = BASE_DIR / \"investigational_drug_moa_pubmed_search\"\n",
    "MOA_CHOICE_DIR        = BASE_DIR / \"investigational_drug_moa_chosen\"\n",
    "MOA_CHOICE_LOG_DIR    = BASE_DIR / \"investigational_drug_moa_chosen_log\"\n",
    "MASTER_MOA_CHOICES_PATH = BASE_DIR / \"investigational_drug_moa_chosen_master.json\"\n",
    "\n",
    "MOA_CHOICE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MOA_CHOICE_LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MAX_WORKERS_MOA = 8\n",
    "MODEL = \"gpt-5\"\n",
    "\n",
    "client = OpenAIWrapper()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Helpers\n",
    "# -------------------------------------------------\n",
    "def extract_json_object(text: str) -> dict:\n",
    "    \"\"\"Extract first valid JSON object from model output.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return {}\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return {}\n",
    "\n",
    "    # Direct parse first\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: first {...} region\n",
    "    m = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        return {}\n",
    "    try:\n",
    "        obj = json.loads(m.group(0))\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "    return {}\n",
    "\n",
    "def load_master_moa_choices() -> dict:\n",
    "    if not MASTER_MOA_CHOICES_PATH.exists():\n",
    "        return {}\n",
    "    try:\n",
    "        return json.loads(MASTER_MOA_CHOICES_PATH.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def build_moa_mesh_prompt(moa_payload: dict, candidate_mesh_terms: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Prompt the LLM to choose the best MeSH term that represents the mechanism of action.\n",
    "    If no suitable MeSH term exists, the model MUST return \"[none]\".\n",
    "    \"\"\"\n",
    "\n",
    "    payload_json = json.dumps(moa_payload, ensure_ascii=False, indent=2)\n",
    "    mesh_json    = json.dumps(candidate_mesh_terms, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return f\"\"\"\n",
    "You are an expert pharmacologist and MeSH annotation specialist.\n",
    "\n",
    "You are given:\n",
    "1) A mechanism-of-action (MOA) text string describing how a drug works.\n",
    "2) A set of PubMed-derived MeSH terms (candidate list).\n",
    "3) Condensed PubMed records used for MOA search.\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "------------------------------------------------------------\n",
    "TASK 1 — Select the Best MeSH Term\n",
    "------------------------------------------------------------\n",
    "Choose EXACTLY ONE MeSH term that best represents the mechanism of action.\n",
    "\n",
    "Rules:\n",
    "- You MUST select a term *only* from the candidate list.\n",
    "- Choose the most mechanistic/specific pharmacologic concept available\n",
    "  (e.g., \"Receptor Antagonists\", \"Antibodies, Monoclonal\", \"Kinase Inhibitors\").\n",
    "- Avoid generic terms (\"Humans\", \"Adult\", \"Neoplasms\") unless absolutely no mechanistic term exists.\n",
    "\n",
    "------------------------------------------------------------\n",
    "TASK 2 — Handle Cases with No Good Mechanistic Term\n",
    "------------------------------------------------------------\n",
    "If NONE of the candidate MeSH terms meaningfully represent the MOA:\n",
    "\n",
    "You MUST output:\n",
    "\n",
    "  \"chosen_mesh_term\": \"[none]\",\n",
    "  \"source_pmid\": null,\n",
    "  \"rationale\": \"Explain why no term fits.\"\n",
    "\n",
    "This is a VALID and EXPECTED outcome.\n",
    "\n",
    "------------------------------------------------------------\n",
    "OUTPUT FORMAT  (STRICT)\n",
    "------------------------------------------------------------\n",
    "\n",
    "Return ONLY a valid JSON object with EXACTLY these fields:\n",
    "\n",
    "{{\n",
    "  \"chosen_mesh_term\": \"<one exact candidate term OR '[none]'>\",\n",
    "  \"source_pmid\": \"<PMID you relied on OR null>\",\n",
    "  \"rationale\": \"One concise sentence explaining your decision.\"\n",
    "}}\n",
    "\n",
    "Constraints:\n",
    "- If you choose a MeSH term, it MUST MATCH EXACTLY one item from the candidate list.\n",
    "- If no suitable term exists, return \"[none]\".\n",
    "- JSON must be valid and parseable.\n",
    "\n",
    "------------------------------------------------------------\n",
    "MOA Payload (input data)\n",
    "------------------------------------------------------------\n",
    "{payload_json}\n",
    "\n",
    "------------------------------------------------------------\n",
    "Candidate MeSH Terms\n",
    "------------------------------------------------------------\n",
    "{mesh_json}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "master_moa_choices = load_master_moa_choices()\n",
    "master_moa_lock = threading.Lock()\n",
    "\n",
    "moa_counter = {\n",
    "    \"processed\": 0,\n",
    "    \"skipped_existing\": 0,\n",
    "    \"llm_error\": 0,\n",
    "    \"parse_error\": 0,\n",
    "    \"coverage_error\": 0,   # includes \"chosen term not in JSON-derived list\"\n",
    "    \"no_candidates\": 0,\n",
    "}\n",
    "moa_counter_lock = threading.Lock()\n",
    "\n",
    "\n",
    "def process_moa_file(fp: Path, idx: int, total: int) -> None:\n",
    "    \"\"\"Process a single MOA PubMed-search JSON file.\"\"\"\n",
    "    try:\n",
    "        payload = json.loads(fp.read_text(encoding=\"utf-8\"))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ [{idx}/{total}] Error reading {fp.name}: {e}\")\n",
    "        with moa_counter_lock:\n",
    "            moa_counter[\"parse_error\"] += 1\n",
    "        return\n",
    "\n",
    "    moa_id = (\n",
    "        payload.get(\"moa_id\")\n",
    "        or payload.get(\"did\")   \n",
    "        or fp.stem\n",
    "    )\n",
    "\n",
    "    mechanism = (\n",
    "        payload.get(\"mechanism\")        \n",
    "        or payload.get(\"mechanism_combined\")\n",
    "        or \"; \".join(payload.get(\"product_mechanisms\", []) or [])\n",
    "        or \"\"\n",
    "    )\n",
    "\n",
    "    if not moa_id:\n",
    "        print(f\"⚠️ [{idx}/{total}] Missing moa_id in {fp.name}, skipping\")\n",
    "        return\n",
    "\n",
    "    out_fp = MOA_CHOICE_DIR / f\"{moa_id}.json\"\n",
    "    if out_fp.exists():\n",
    "        with moa_counter_lock:\n",
    "            moa_counter[\"skipped_existing\"] += 1\n",
    "        return\n",
    "\n",
    "    match = payload.get(\"match\") or {}\n",
    "    records = match.get(\"records\") or {}\n",
    "    pmids = match.get(\"pmids\") or []\n",
    "\n",
    "    # Collect candidate MeSH terms (unique, in stable order) FROM THE JSON ONLY\n",
    "    candidate_terms = []\n",
    "    seen_terms = set()\n",
    "    for pmid, rec in records.items():\n",
    "        mesh_terms = rec.get(\"mesh_terms\") or []\n",
    "        for term in mesh_terms:\n",
    "            if term and term not in seen_terms:\n",
    "                seen_terms.add(term)\n",
    "                candidate_terms.append(term)\n",
    "\n",
    "    if not candidate_terms:\n",
    "        print(f\"⚠️ [{idx}/{total}] No candidate MeSH terms for moa_id={moa_id}, skipping\")\n",
    "        with moa_counter_lock:\n",
    "            moa_counter[\"no_candidates\"] += 1\n",
    "        return\n",
    "\n",
    "    # Condensed payload for the model (avoid full abstracts to save tokens)\n",
    "    condensed_records = {\n",
    "        pmid: {\n",
    "            \"title\": (rec.get(\"title\") or \"\"),\n",
    "            \"mesh_terms\": (rec.get(\"mesh_terms\") or []),\n",
    "        }\n",
    "        for pmid, rec in records.items()\n",
    "    }\n",
    "\n",
    "    moa_payload = {\n",
    "        \"moa_id\": moa_id,\n",
    "        \"mechanism\": mechanism,\n",
    "        \"tried_terms\": payload.get(\"tried_terms\") or [],\n",
    "        \"pmids\": pmids,\n",
    "        \"records\": condensed_records,\n",
    "    }\n",
    "\n",
    "    prompt = build_moa_mesh_prompt(moa_payload, candidate_terms)\n",
    "\n",
    "    token = moa_id\n",
    "    hash_id = moa_id\n",
    "\n",
    "    text_response = \"\"\n",
    "    raw_response = None\n",
    "    total_cost = 0.0\n",
    "    elapsed = 0.0\n",
    "\n",
    "    # Call LLM\n",
    "    try:\n",
    "        t0 = time.perf_counter()\n",
    "        res = client.query(prompt=prompt, model=MODEL)\n",
    "        elapsed = round(time.perf_counter() - t0, 2)\n",
    "\n",
    "        text_response = (res.get(\"text_response\") or \"\").strip()\n",
    "        raw_response = res.get(\"raw_response\")\n",
    "        total_cost = float(res.get(\"cost\") or 0.0)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ [{idx}/{total}] LLM error for moa_id={moa_id}: {e}\")\n",
    "        with moa_counter_lock:\n",
    "            moa_counter[\"llm_error\"] += 1\n",
    "        return\n",
    "\n",
    "    # Parse JSON\n",
    "    obj = extract_json_object(text_response)\n",
    "\n",
    "    if not isinstance(obj, dict) or not obj:\n",
    "        print(f\"⚠️ [{idx}/{total}] JSON parse error moa_id={moa_id}, raw={text_response!r}\")\n",
    "        with moa_counter_lock:\n",
    "            moa_counter[\"parse_error\"] += 1\n",
    "        return\n",
    "\n",
    "    chosen_term = obj.get(\"chosen_mesh_term\")\n",
    "    source_pmid = obj.get(\"source_pmid\")\n",
    "    rationale = obj.get(\"rationale\")\n",
    "\n",
    "    # HARD CHECK: chosen term\n",
    "    if not chosen_term or not isinstance(chosen_term, str):\n",
    "        print(f\"⚠️ [{idx}/{total}] Missing or invalid chosen_mesh_term for moa_id={moa_id}\")\n",
    "        with moa_counter_lock:\n",
    "            moa_counter[\"coverage_error\"] += 1\n",
    "        return\n",
    "\n",
    "    # Special allowed sentinel for \"no good term\"\n",
    "    if chosen_term == \"[none]\":\n",
    "        # Accept even though it's not in candidate_terms\n",
    "        mapped = {\n",
    "            \"moa_id\": moa_id,\n",
    "            \"mechanism\": mechanism,\n",
    "            \"candidate_mesh_terms\": candidate_terms,\n",
    "            \"chosen_mesh_term\": chosen_term,\n",
    "            \"source_pmid\": source_pmid,\n",
    "            \"rationale\": rationale,\n",
    "            \"source\": \"llm\",\n",
    "        }\n",
    "    else:\n",
    "        # For any real term, it MUST come from the JSON-derived candidate list\n",
    "        if chosen_term not in candidate_terms:\n",
    "            # DNE in JSON (hallucinated or modified term) → reject, do NOT save\n",
    "            print(\n",
    "                f\"⚠️ [{idx}/{total}] chosen_mesh_term not in JSON-derived candidate list \"\n",
    "                f\"for moa_id={moa_id}: {chosen_term!r}\"\n",
    "            )\n",
    "            with moa_counter_lock:\n",
    "                moa_counter[\"coverage_error\"] += 1\n",
    "            return\n",
    "\n",
    "        # Optional: source_pmid sanity check (must be one of pmids or None)\n",
    "        if source_pmid is not None and source_pmid not in pmids:\n",
    "            print(\n",
    "                f\"⚠️ [{idx}/{total}] source_pmid {source_pmid!r} not in pmids for moa_id={moa_id}; \"\n",
    "                f\"still accepting chosen_mesh_term\"\n",
    "            )\n",
    "\n",
    "        mapped = {\n",
    "            \"moa_id\": moa_id,\n",
    "            \"mechanism\": mechanism,\n",
    "            \"candidate_mesh_terms\": candidate_terms,\n",
    "            \"chosen_mesh_term\": chosen_term,\n",
    "            \"source_pmid\": source_pmid,\n",
    "            \"rationale\": rationale,\n",
    "            \"source\": \"llm\",\n",
    "        }\n",
    "\n",
    "    # Save per-MOA JSON\n",
    "    out_fp.write_text(json.dumps(mapped, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    # Log entry\n",
    "    log_payload = {\n",
    "        \"token\": token,\n",
    "        \"hash_id\": hash_id,\n",
    "        \"model\": MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"structured_response\": json.dumps(mapped, ensure_ascii=False, indent=2),\n",
    "        \"raw_response\": repr(raw_response),\n",
    "        \"total_cost\": total_cost,\n",
    "        \"time_elapsed\": elapsed,\n",
    "    }\n",
    "    (MOA_CHOICE_LOG_DIR / f\"{hash_id}.json\").write_text(\n",
    "        json.dumps(log_payload, ensure_ascii=False, indent=2),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "    # Update master\n",
    "    with master_moa_lock:\n",
    "        master_moa_choices[moa_id] = mapped\n",
    "        MASTER_MOA_CHOICES_PATH.write_text(\n",
    "            json.dumps(master_moa_choices, ensure_ascii=False, indent=2),\n",
    "            encoding=\"utf-8\",\n",
    "        )\n",
    "\n",
    "    with moa_counter_lock:\n",
    "        moa_counter[\"processed\"] += 1\n",
    "        if moa_counter[\"processed\"] % 50 == 0:\n",
    "            print(f\"Progress: processed {moa_counter['processed']} MOA entries...\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# RUN CONCURRENTLY OVER MOA PUBMED SEARCH FILES\n",
    "# -------------------------------------------------\n",
    "moa_files = sorted(MOA_PUBMED_DIR.glob(\"*.json\"))\n",
    "total_moa = len(moa_files)\n",
    "print(f\"Loaded {total_moa} MOA PubMed-search files for MeSH-term selection.\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS_MOA) as ex:\n",
    "    futures = {\n",
    "        ex.submit(process_moa_file, fp, idx, total_moa): fp.name\n",
    "        for idx, fp in enumerate(moa_files, start=1)\n",
    "    }\n",
    "    for fut in as_completed(futures):\n",
    "        name = futures[fut]\n",
    "        try:\n",
    "            fut.result()\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Worker error (MOA MeSH selection) file={name}: {e}\")\n",
    "\n",
    "print(\n",
    "    f\"MOA MeSH-term selection complete. \"\n",
    "    f\"processed={moa_counter['processed']}, \"\n",
    "    f\"skipped={moa_counter['skipped_existing']}, \"\n",
    "    f\"llm_error={moa_counter['llm_error']}, \"\n",
    "    f\"parse_error={moa_counter['parse_error']}, \"\n",
    "    f\"coverage_error={moa_counter['coverage_error']}, \"\n",
    "    f\"no_candidates={moa_counter['no_candidates']}\"\n",
    ")\n",
    "print(f\"Chosen MOA directory: {MOA_CHOICE_DIR}\")\n",
    "print(f\"Log directory:        {MOA_CHOICE_LOG_DIR}\")\n",
    "print(f\"Master choices:       {MASTER_MOA_CHOICES_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "25b762f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trial breakdown: cache/trial_product_breakdown.csv, shape=(184, 23)\n",
      "did_to_mesh (excluding [none]) entries: 132\n",
      "trial_to_dids entries: 183\n",
      "did_to_names_norm entries: 132\n",
      "✔️ Wrote trial breakdown with chosen MeSH mechanisms → cache/trial_product_breakdown_w_chosen_mechanisms.csv\n",
      "| trial_hash                           | investigational_products                      | investigational_products_mechanism_mesh_terms                      | investigational_products_alternative_names                                                                                                                                                 | investigational_products_molecular_target   | investigational_products_mechanism                                    | investigational_products_tt_drug_id   | investigational_products_bmt_drug_id   | active_comparators                       | active_comparators_mechanism_mesh_terms    | active_comparators_alternative_names                                                                                                                                                                                            | active_comparators_molecular_target   | active_comparators_mechanism                                 | active_comparators_tt_drug_id   | active_comparators_bmt_drug_id   | placebos   | placebos_alternative_names   | placebos_molecular_target   | placebos_mechanism   | standard_of_care   | standard_of_care_mechanism_mesh_terms   | standard_of_care_alternative_names   | standard_of_care_molecular_target   | standard_of_care_mechanism   | standard_of_care_tt_drug_id   | standard_of_care_bmt_drug_id   |\n",
      "|:-------------------------------------|:----------------------------------------------|:-------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------|:----------------------------------------------------------------------|:--------------------------------------|:---------------------------------------|:-----------------------------------------|:-------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------|:-------------------------------------------------------------|:--------------------------------|:---------------------------------|:-----------|:-----------------------------|:----------------------------|:---------------------|:-------------------|:----------------------------------------|:-------------------------------------|:------------------------------------|:-----------------------------|:------------------------------|:-------------------------------|\n",
      "| tid_0541995757b10e613a42173d6b8ddc09 | ['cinacalcet hydrochloride (test)']           | ['Receptors, Calcium-Sensing / agonists*']                         | [['cinacalcet HCl, Zhejiang Wansheng Pharmaceutical Co.', 'cinacalcet hydrochloride, Zhejiang Wansheng Pharmaceutical Co.', 'cinacalcet, Zhejiang Wansheng Pharmaceutical Co.']]           | ['Calcium-sensing receptor (CaSR)']         | ['Calcimimetic; calcium-sensing receptor agonist']                    | ['194454']                            | ['']                                   | ['cinacalcet hydrochloride (reference)'] | ['Receptors, Calcium-Sensing / agonists*'] | [['cinacalcet hydrochloride tablets produced by Kyowa Kirin Co., Ltd.', 'cinacalcet HCl (Kyowa Kirin)']]                                                                                                                        | ['Calcium-sensing receptor (CaSR)']   | ['Calcimimetic; calcium-sensing receptor agonist']           | ['']                            | ['']                             | []         | []                           | []                          | []                   | []                 | []                                      | []                                   | []                                  | []                           | []                            | []                             |\n",
      "| tid_0da20e863cfc5f3e369868462bff74e0 | ['NuPIAO']                                    | ['Receptors, Erythropoietin / agonists*']                          | [['nupiao', 'rESP', 'SSS-06', 'SSS 06', 'SSS06', 'NuPIAO (iv)', 'recombinant erythropoietin stimulating protein', 'recombinant erythropoiesis-stimulating protein injection (CHO cells)']] | ['Erythropoietin receptor']                 | ['Erythropoietin receptor agonist']                                   | ['40640']                             | ['19694']                              | []                                       | []                                         | []                                                                                                                                                                                                                              | []                                    | []                                                           | []                              | []                               | []         | []                           | []                          | []                   | []                 | []                                      | []                                   | []                                  | []                           | []                            | []                             |\n",
      "| tid_0e8fa21079f928135dfc6164a15285f8 | ['SSS-17']                                    | ['Prolyl-Hydroxylase Inhibitors* / pharmacology; therapeutic use'] | [['SSS17', 'SSS 17', '[14C]SSS17', '[14C] SSS17', '[14C]-SSS17', '[¹⁴C]SSS17', '[¹⁴C] SSS17', '[¹⁴C]-SSS17', 'HIF-117', 'HIF 117', 'HIF117', '[14C]HIF-117']]                              | ['Hypoxia-inducible factor (HIF)']          | ['Hypoxia-inducible factor antagonist']                               | ['130313']                            | ['']                                   | []                                       | []                                         | []                                                                                                                                                                                                                              | []                                    | []                                                           | []                              | []                               | []         | []                           | []                          | []                   | []                 | []                                      | []                                   | []                                  | []                           | []                            | []                             |\n",
      "| tid_0f04ddb3d522d528d083d7d5c43d1e18 | ['Metformin hydrochloride sustained-release'] | ['Gluconeogenesis / drug effects*']                                | [['Metformin Hydrochloride Sustained-release Tablets', 'metformin hydrochloride, Zhejiang Sunshine Mandi Pharmaceutical Co.', 'metformin hydrochloride extended-release', 'metformin XR']] | ['']                                        | ['Biguanide; gluconeogenesis inhibitor; insulin sensitizer']          | ['290388']                            | ['']                                   | ['Glucophage XR']                        | ['Gluconeogenesis / drug effects*']        | [['Glucophage', '格华止', 'metformin XR', 'metformin hydrochloride, once-daily, BMS', 'metformin HCl, once-daily, BMS', 'Diabex', 'Diabex XR', 'Dabex XR', 'Glifage XR', 'Metgluco', 'Stagid', 'SMP 862', 'SMP-862', 'SMP862']] | ['']                                  | ['Biguanide; gluconeogenesis inhibitor; insulin sensitizer'] | ['24060']                       | ['']                             | []         | []                           | []                          | []                   | []                 | []                                      | []                                   | []                                  | []                           | []                            | []                             |\n",
      "| tid_10562c0430b8b9bae93c94cadfb0a129 | ['RD-01']                                     | ['Receptors, Erythropoietin / agonists*']                          | [['RD001', 'RD-001', 'RD 001', 'RD01', 'RD-01 Long-acting rhEPO', 'Peg-EPO']]                                                                                                              | ['Erythropoietin receptor (EPOR)']          | ['PEGylated recombinant human erythropoietin (EPO) receptor agonist'] | ['144350']                            | ['']                                   | []                                       | []                                         | []                                                                                                                                                                                                                              | []                                    | []                                                           | []                              | []                               | []         | []                           | []                          | []                   | []                 | []                                      | []                                   | []                                  | []                           | []                            | []                             |\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------------------\n",
    "# CONFIG\n",
    "# ----------------------------------------\n",
    "BASE_DIR = Path(\"cache\")\n",
    "IN_BREAKDOWN_CSV = BASE_DIR / \"trial_product_breakdown.csv\"\n",
    "PRODUCT_MASTER_BY_DID = BASE_DIR / \"product_id_master_by_did.json\"\n",
    "MOA_MASTER_PATH = BASE_DIR / \"investigational_drug_moa_chosen_master.json\"\n",
    "OUT_BREAKDOWN_CSV = BASE_DIR / \"trial_product_breakdown_w_chosen_mechanisms.csv\"\n",
    "\n",
    "# ----------------------------------------\n",
    "# Helpers\n",
    "# ----------------------------------------\n",
    "def parse_listish(x):\n",
    "    \"\"\"Parse strings like \"['a','b']\" into Python lists.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if x is None:\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if not s or s in (\"[]\", \"[ ]\"):\n",
    "        return []\n",
    "    try:\n",
    "        v = ast.literal_eval(s)\n",
    "        if isinstance(v, list):\n",
    "            return v\n",
    "        return [v]\n",
    "    except Exception:\n",
    "        return [s]\n",
    "\n",
    "def insert_after(df, col, newcol, values):\n",
    "    cols = list(df.columns)\n",
    "    if col not in cols:\n",
    "        df[newcol] = values\n",
    "        return\n",
    "    idx = cols.index(col)\n",
    "    df.insert(idx + 1, newcol, values)\n",
    "\n",
    "def is_none_term(s: str) -> bool:\n",
    "    \"\"\"True if the term represents '[none]' or equivalent.\"\"\"\n",
    "    if not s:\n",
    "        return True\n",
    "    s2 = s.strip().lower()\n",
    "    return s2 in (\"[none]\", \"none\", \"\")\n",
    "\n",
    "def norm_name(s: str) -> str:\n",
    "    \"\"\"Simple normalization for name matching.\"\"\"\n",
    "    return str(s).strip().lower()\n",
    "\n",
    "# ----------------------------------------\n",
    "# Load inputs\n",
    "# ----------------------------------------\n",
    "df = pd.read_csv(IN_BREAKDOWN_CSV, dtype=str).fillna(\"\")\n",
    "print(f\"Loaded trial breakdown: {IN_BREAKDOWN_CSV}, shape={df.shape}\")\n",
    "\n",
    "if not PRODUCT_MASTER_BY_DID.exists():\n",
    "    raise FileNotFoundError(f\"No product master by did found at {PRODUCT_MASTER_BY_DID}\")\n",
    "if not MOA_MASTER_PATH.exists():\n",
    "    raise FileNotFoundError(f\"No MOA master file found at {MOA_MASTER_PATH}\")\n",
    "\n",
    "product_by_did = json.loads(PRODUCT_MASTER_BY_DID.read_text(encoding=\"utf-8\"))\n",
    "moa_master = json.loads(MOA_MASTER_PATH.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# ----------------------------------------\n",
    "# did -> chosen_mesh_term (exclude \"[none]\")\n",
    "# ----------------------------------------\n",
    "did_to_mesh = {}\n",
    "for did, rec in moa_master.items():\n",
    "    mesh = (rec.get(\"chosen_mesh_term\") or \"\").strip()\n",
    "    if mesh and not is_none_term(mesh):\n",
    "        did_to_mesh[did] = mesh\n",
    "\n",
    "print(f\"did_to_mesh (excluding [none]) entries: {len(did_to_mesh)}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Build trial_hash -> list of dids (only those with a chosen mesh term)\n",
    "# and did -> normalized name set for matching\n",
    "# ----------------------------------------\n",
    "trial_to_dids = {}\n",
    "did_to_names_norm = {}\n",
    "\n",
    "for did, rec in product_by_did.items():\n",
    "    if did not in did_to_mesh:\n",
    "        # If we don't have a chosen MeSH term, skip this did for mapping purposes\n",
    "        continue\n",
    "\n",
    "    # Collect all names / alt names\n",
    "    drug_names = rec.get(\"drug_names\", []) or []\n",
    "    alt_names = rec.get(\"alternative_names\", []) or []\n",
    "    all_names = set(drug_names) | set(alt_names)\n",
    "\n",
    "    names_norm = {norm_name(n) for n in all_names if str(n).strip()}\n",
    "    if not names_norm:\n",
    "        continue\n",
    "\n",
    "    did_to_names_norm[did] = names_norm\n",
    "\n",
    "    # Map each trial_hash to this did\n",
    "    trial_hashes = rec.get(\"trial_hashes\", []) or []\n",
    "    for th in trial_hashes:\n",
    "        th_str = str(th).strip()\n",
    "        if not th_str:\n",
    "            continue\n",
    "        trial_to_dids.setdefault(th_str, []).append(did)\n",
    "\n",
    "print(f\"trial_to_dids entries: {len(trial_to_dids)}\")\n",
    "print(f\"did_to_names_norm entries: {len(did_to_names_norm)}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# For each trial row, build chosen MeSH mechanism lists per role\n",
    "# based on matching product NAMES (not tt_drug_id) within that trial.\n",
    "# ----------------------------------------\n",
    "ROLE_NAME_SPECS = [\n",
    "    (\"investigational_products\", \"investigational_products_mechanism_mesh_terms\"),\n",
    "    (\"active_comparators\", \"active_comparators_mechanism_mesh_terms\"),\n",
    "    (\"standard_of_care\", \"standard_of_care_mechanism_mesh_terms\"),\n",
    "]\n",
    "\n",
    "# Prepare containers\n",
    "new_cols = {spec[1]: [] for spec in ROLE_NAME_SPECS}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    trial_hash = str(row.get(\"trial_hash\", \"\")).strip()\n",
    "    candidate_dids = trial_to_dids.get(trial_hash, [])\n",
    "\n",
    "    # Fast path: if no dids for this trial, all lists are empty\n",
    "    if not candidate_dids:\n",
    "        for _, new_col in ROLE_NAME_SPECS:\n",
    "            # But we still need correct length per role (one entry per product name)\n",
    "            base_col = [spec[0] for spec in ROLE_NAME_SPECS if spec[1] == new_col][0]\n",
    "            names_list = parse_listish(row.get(base_col, \"\"))\n",
    "            mesh_list = [\"\" for _ in names_list]\n",
    "            new_cols[new_col].append(str(mesh_list))\n",
    "        continue\n",
    "\n",
    "    # For each role, match by name\n",
    "    for base_col, new_col in ROLE_NAME_SPECS:\n",
    "        names_list = parse_listish(row.get(base_col, \"\"))\n",
    "        mesh_list = []\n",
    "\n",
    "        for prod_name in names_list:\n",
    "            name_norm = norm_name(prod_name)\n",
    "            if not name_norm:\n",
    "                mesh_list.append(\"\")\n",
    "                continue\n",
    "\n",
    "            meshes_for_this = set()\n",
    "\n",
    "            # Check each candidate did for this trial\n",
    "            for did in candidate_dids:\n",
    "                names_norm = did_to_names_norm.get(did, set())\n",
    "                if name_norm in names_norm:\n",
    "                    mesh = did_to_mesh.get(did, \"\")\n",
    "                    if mesh:\n",
    "                        meshes_for_this.add(mesh)\n",
    "\n",
    "            if not meshes_for_this:\n",
    "                mesh_list.append(\"\")\n",
    "            elif len(meshes_for_this) == 1:\n",
    "                mesh_list.append(next(iter(meshes_for_this)))\n",
    "            else:\n",
    "                mesh_list.append(\"; \".join(sorted(meshes_for_this)))\n",
    "\n",
    "        new_cols[new_col].append(str(mesh_list))\n",
    "\n",
    "# ----------------------------------------\n",
    "# Attach columns next to their name columns\n",
    "# ----------------------------------------\n",
    "for base_col, new_col in ROLE_NAME_SPECS:\n",
    "    insert_after(df, base_col, new_col, new_cols[new_col])\n",
    "\n",
    "# ----------------------------------------\n",
    "# Save output\n",
    "# ----------------------------------------\n",
    "OUT_BREAKDOWN_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(OUT_BREAKDOWN_CSV, index=False)\n",
    "\n",
    "print(f\"✔️ Wrote trial breakdown with chosen MeSH mechanisms → {OUT_BREAKDOWN_CSV}\")\n",
    "print(df.head(5).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c61cff9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping desc2025.xml, already exists.\n",
      "Skipping supp2025.xml, already exists.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "BASE_URL = \"https://nlmpubs.nlm.nih.gov/projects/mesh/MESH_FILES/xmlmesh\"\n",
    "OUT_DIR = Path(\"cache\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FILES = [\"desc2025.xml\", \"supp2025.xml\"]\n",
    "\n",
    "for fname in FILES:\n",
    "    url = f\"{BASE_URL}/{fname}\"\n",
    "    out_path = OUT_DIR / fname\n",
    "\n",
    "    # Skip if already downloaded\n",
    "    if out_path.exists() and out_path.stat().st_size > 0:\n",
    "        print(f\"Skipping {fname}, already exists.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"⬇Downloading {url} -> {out_path}\")\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    out_path.write_bytes(r.content)\n",
    "    print(f\"Downloaded {fname}\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8f42c84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MeSH index terms: 992,888 unique normalized terms\n",
      "sotatercept → {'mesh_id': 'C542017', 'tree_numbers': ['D12.776.828.300'], 'scope_note': 'Recombinant proteins produced by the GENETIC TRANSLATION of fused genes formed by the combination of NUCLEIC ACID REGULATORY SEQUENCES of one or more genes with the protein coding sequences of one or more genes.'}\n",
      "ACE-011 → {'mesh_id': 'C542017', 'tree_numbers': ['D12.776.828.300'], 'scope_note': 'Recombinant proteins produced by the GENETIC TRANSLATION of fused genes formed by the combination of NUCLEIC ACID REGULATORY SEQUENCES of one or more genes with the protein coding sequences of one or more genes.'}\n",
      "winrevair → {'mesh_id': 'C542017', 'tree_numbers': ['D12.776.828.300'], 'scope_note': 'Recombinant proteins produced by the GENETIC TRANSLATION of fused genes formed by the combination of NUCLEIC ACID REGULATORY SEQUENCES of one or more genes with the protein coding sequences of one or more genes.'}\n"
     ]
    }
   ],
   "source": [
    "import os, xml.etree.ElementTree as ET\n",
    "import html, unicodedata\n",
    "\n",
    "DESC_XML  = \"cache/desc2025.xml\"\n",
    "SUPP_XML  = \"cache/supp2025.xml\"\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    t = html.unescape(s)\n",
    "    t = unicodedata.normalize(\"NFKC\", t)\n",
    "    t = t.replace(\"\\u2019\", \"'\").replace(\"\\u2018\", \"'\").replace(\"\\u2032\", \"'\").replace(\"\\u2033\", '\"')\n",
    "    t = t.replace(\"\\u201C\", '\"').replace(\"\\u201D\", '\"')\n",
    "    t = t.replace(\"\\u2010\", \"-\").replace(\"\\u2011\", \"-\").replace(\"\\u2012\", \"-\").replace(\"\\u2013\", \"-\").replace(\"\\u2014\", \"-\")\n",
    "    return \" \".join(t.strip().lower().split())\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    \"\"\"Unicode-clean + collapse whitespace (preserve case).\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    t = html.unescape(s)\n",
    "    t = unicodedata.normalize(\"NFKC\", t)\n",
    "    t = t.replace(\"\\u2019\", \"'\").replace(\"\\u2018\", \"'\").replace(\"\\u2032\", \"'\").replace(\"\\u2033\", '\"')\n",
    "    t = t.replace(\"\\u201C\", '\"').replace(\"\\u201D\", '\"')\n",
    "    t = t.replace(\"\\u2010\", \"-\").replace(\"\\u2011\", \"-\").replace(\"\\u2012\", \"-\").replace(\"\\u2013\", \"-\").replace(\"\\u2014\", \"-\")\n",
    "    return \" \".join(t.strip().split())\n",
    "\n",
    "def _dedup(seq):\n",
    "    seen = set(); out = []\n",
    "    for x in seq:\n",
    "        if x and x not in seen:\n",
    "            seen.add(x); out.append(x)\n",
    "    return out\n",
    "\n",
    "def _extract_scope_note_from_descriptor(rec: ET.Element) -> str:\n",
    "    \"\"\"\n",
    "    Prefer the ScopeNote of the PreferredConcept (PreferredConceptYN='Y'),\n",
    "    else fall back to the first ScopeNote present under any Concept.\n",
    "    \"\"\"\n",
    "    # Preferred concept first\n",
    "    pref = rec.find(\".//ConceptList/Concept[@PreferredConceptYN='Y']/ScopeNote\")\n",
    "    if pref is not None and pref.text:\n",
    "        return clean_text(pref.text)\n",
    "\n",
    "    # Any concept scope note as fallback\n",
    "    any_sn = rec.find(\".//ConceptList/Concept/ScopeNote\")\n",
    "    if any_sn is not None and any_sn.text:\n",
    "        return clean_text(any_sn.text)\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def _extract_scope_note_from_supp(rec: ET.Element) -> str:\n",
    "    \"\"\"\n",
    "    For SCRs, ScopeNote can also live under Concept.\n",
    "    Prefer the PreferredConcept (if flagged), else the first available.\n",
    "    \"\"\"\n",
    "    pref = rec.find(\".//ConceptList/Concept[@PreferredConceptYN='Y']/ScopeNote\")\n",
    "    if pref is not None and pref.text:\n",
    "        return clean_text(pref.text)\n",
    "\n",
    "    any_sn = rec.find(\".//ConceptList/Concept/ScopeNote\")\n",
    "    if any_sn is not None and any_sn.text:\n",
    "        return clean_text(any_sn.text)\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def load_mesh_tree_and_id(desc_xml_fp: str, supp_xml_fp: str) -> dict[str, dict[str, list[str] | str]]:\n",
    "    # term_map[normalized_term] = {\"mesh_id\": <UI>, \"tree_numbers\": [..], \"scope_note\": <str>}\n",
    "    term_map: dict[str, dict[str, list[str] | str]] = {}\n",
    "\n",
    "    # Helper maps for fallbacks/joins\n",
    "    heading_to_tree: dict[str, list[str]] = {}\n",
    "    ui_to_tree: dict[str, list[str]] = {}\n",
    "    heading_to_scope: dict[str, str] = {}\n",
    "    ui_to_scope: dict[str, str] = {}\n",
    "\n",
    "    # --- Descriptors ---\n",
    "    if os.path.exists(desc_xml_fp):\n",
    "        root = ET.parse(desc_xml_fp).getroot()\n",
    "        for rec in root.findall(\".//DescriptorRecord\"):\n",
    "            desc_ui = (rec.findtext(\"DescriptorUI\") or \"\").strip()\n",
    "            tree_numbers = _dedup([tn.text.strip() for tn in rec.findall(\".//TreeNumberList/TreeNumber\") if tn.text])\n",
    "\n",
    "            heading_raw = rec.findtext(\"DescriptorName/String\")\n",
    "            heading_norm = norm(heading_raw) if heading_raw else \"\"\n",
    "            scope_note = _extract_scope_note_from_descriptor(rec)\n",
    "\n",
    "            if heading_norm:\n",
    "                heading_to_tree[heading_norm] = tree_numbers\n",
    "                heading_to_scope[heading_norm] = scope_note\n",
    "            if desc_ui:\n",
    "                ui_to_tree[desc_ui] = tree_numbers\n",
    "                ui_to_scope[desc_ui] = scope_note\n",
    "\n",
    "            # Collect all terms mapped to this descriptor\n",
    "            terms = set()\n",
    "            if heading_raw:\n",
    "                terms.add(heading_norm)\n",
    "            for concept in rec.findall(\".//Concept\"):\n",
    "                for term in concept.findall(\".//Term\"):\n",
    "                    s = term.findtext(\"String\")\n",
    "                    if s:\n",
    "                        terms.add(norm(s))\n",
    "\n",
    "            for term in terms:\n",
    "                term_map[term] = {\n",
    "                    \"mesh_id\": desc_ui,\n",
    "                    \"tree_numbers\": tree_numbers,\n",
    "                    \"scope_note\": scope_note\n",
    "                }\n",
    "\n",
    "    # --- Supplementary (SCRs) ---\n",
    "    if os.path.exists(supp_xml_fp):\n",
    "        root = ET.parse(supp_xml_fp).getroot()\n",
    "        for rec in root.findall(\".//SupplementalRecord\"):\n",
    "            supp_ui = (rec.findtext(\"SupplementalRecordUI\") or \"\").strip()\n",
    "\n",
    "            # Collect ALL names for this SCR\n",
    "            names = set()\n",
    "\n",
    "            for s in rec.findall(\".//SupplementalRecordName/String\"):\n",
    "                if s is not None and s.text:\n",
    "                    names.add(norm(s.text))\n",
    "\n",
    "            for s in rec.findall(\".//ConceptList/Concept/ConceptName/String\"):\n",
    "                if s is not None and s.text:\n",
    "                    names.add(norm(s.text))\n",
    "\n",
    "            for s in rec.findall(\".//ConceptList/Concept/TermList/Term/String\"):\n",
    "                if s is not None and s.text:\n",
    "                    names.add(norm(s.text))\n",
    "\n",
    "            # Direct trees (often none for SCRs)\n",
    "            tree_numbers = [tn.text.strip() for tn in rec.findall(\".//TreeNumberList/TreeNumber\") if tn.text]\n",
    "\n",
    "            # SCR scope note (preferred concept first)\n",
    "            scr_scope_note = _extract_scope_note_from_supp(rec)\n",
    "\n",
    "            # Fallback via HeadingMappedTo (names and UIs)\n",
    "            mapped_scope_note = \"\"\n",
    "            if not tree_numbers:\n",
    "                # Try mapped names\n",
    "                mapped_names = [n.text.strip() for n in rec.findall(\".//HeadingMappedTo/DescriptorReferredTo/DescriptorName/String\") if n is not None and n.text]\n",
    "                for m in mapped_names:\n",
    "                    m_norm = norm(m)\n",
    "                    tns = heading_to_tree.get(m_norm)\n",
    "                    if tns:\n",
    "                        tree_numbers.extend(tns)\n",
    "                    if not mapped_scope_note and m_norm in heading_to_scope and heading_to_scope[m_norm]:\n",
    "                        mapped_scope_note = heading_to_scope[m_norm]\n",
    "\n",
    "                # Try mapped UIs\n",
    "                mapped_uis = [u.text.strip().lstrip(\"*\") for u in rec.findall(\".//HeadingMappedTo/DescriptorReferredTo/DescriptorUI\") if u is not None and u.text]\n",
    "                for mui in mapped_uis:\n",
    "                    tns = ui_to_tree.get(mui)\n",
    "                    if tns:\n",
    "                        tree_numbers.extend(tns)\n",
    "                    if not mapped_scope_note and mui in ui_to_scope and ui_to_scope[mui]:\n",
    "                        mapped_scope_note = ui_to_scope[mui]\n",
    "\n",
    "                tree_numbers = _dedup(tree_numbers)\n",
    "\n",
    "            final_scope_note = scr_scope_note or mapped_scope_note or \"\"\n",
    "\n",
    "            for name in names:\n",
    "                # Keep Descriptor mapping if already present for same term\n",
    "                if name in term_map and str(term_map[name].get(\"mesh_id\", \"\")).startswith(\"D\"):\n",
    "                    continue\n",
    "                term_map[name] = {\n",
    "                    \"mesh_id\": supp_ui,\n",
    "                    \"tree_numbers\": tree_numbers,\n",
    "                    \"scope_note\": final_scope_note\n",
    "                }\n",
    "\n",
    "    return term_map\n",
    "\n",
    "# -------- Run --------\n",
    "TREE_INDEX = load_mesh_tree_and_id(DESC_XML, SUPP_XML)\n",
    "print(f\"Loaded MeSH index terms: {len(TREE_INDEX):,} unique normalized terms\")\n",
    "\n",
    "# Quick checks\n",
    "for q in [\"sotatercept\", \"ACE-011\", \"winrevair\"]:\n",
    "    k = norm(q)\n",
    "    print(q, \"→\", TREE_INDEX.get(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "58fa5631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trials: cache/trial_product_breakdown_w_chosen_mechanisms.csv, shape=(184, 26)\n",
      "✅ Wrote: cache/trial_mechanism_mesh_mapping.csv\n",
      "| trial_hash                           | investigational_products                      | investigational_products_mechanism_mesh_terms                      | investigational_products_mechanism_tree_numbers                          | investigational_products_mechanism_primary_tree_numbers   | investigational_products_alternative_names                                                                                                                                                 | investigational_products_molecular_target   | investigational_products_mechanism                                    | investigational_products_tt_drug_id   | investigational_products_bmt_drug_id   | active_comparators                       | active_comparators_mechanism_mesh_terms    | active_comparators_mechanism_tree_numbers   | active_comparators_mechanism_primary_tree_numbers   | active_comparators_alternative_names                                                                                                                                                                                            | active_comparators_molecular_target   | active_comparators_mechanism                                 | active_comparators_tt_drug_id   | active_comparators_bmt_drug_id   | placebos   | placebos_alternative_names   | placebos_molecular_target   | placebos_mechanism   | standard_of_care   | standard_of_care_mechanism_mesh_terms   | standard_of_care_mechanism_tree_numbers   | standard_of_care_mechanism_primary_tree_numbers   | standard_of_care_alternative_names   | standard_of_care_molecular_target   | standard_of_care_mechanism   | standard_of_care_tt_drug_id   | standard_of_care_bmt_drug_id   |\n",
      "|:-------------------------------------|:----------------------------------------------|:-------------------------------------------------------------------|:-------------------------------------------------------------------------|:----------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------|:----------------------------------------------------------------------|:--------------------------------------|:---------------------------------------|:-----------------------------------------|:-------------------------------------------|:--------------------------------------------|:----------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------|:-------------------------------------------------------------|:--------------------------------|:---------------------------------|:-----------|:-----------------------------|:----------------------------|:---------------------|:-------------------|:----------------------------------------|:------------------------------------------|:--------------------------------------------------|:-------------------------------------|:------------------------------------|:-----------------------------|:------------------------------|:-------------------------------|\n",
      "| tid_0541995757b10e613a42173d6b8ddc09 | ['cinacalcet hydrochloride (test)']           | ['Receptors, Calcium-Sensing / agonists*']                         | [['D12.776.543.750.695.115']]                                            | ['D12.776.543.750.695.115']                               | [['cinacalcet HCl, Zhejiang Wansheng Pharmaceutical Co.', 'cinacalcet hydrochloride, Zhejiang Wansheng Pharmaceutical Co.', 'cinacalcet, Zhejiang Wansheng Pharmaceutical Co.']]           | ['Calcium-sensing receptor (CaSR)']         | ['Calcimimetic; calcium-sensing receptor agonist']                    | ['194454']                            | ['']                                   | ['cinacalcet hydrochloride (reference)'] | ['Receptors, Calcium-Sensing / agonists*'] | [['D12.776.543.750.695.115']]               | ['D12.776.543.750.695.115']                         | [['cinacalcet hydrochloride tablets produced by Kyowa Kirin Co., Ltd.', 'cinacalcet HCl (Kyowa Kirin)']]                                                                                                                        | ['Calcium-sensing receptor (CaSR)']   | ['Calcimimetic; calcium-sensing receptor agonist']           | ['']                            | ['']                             | []         | []                           | []                          | []                   | []                 | []                                      | []                                        | []                                                | []                                   | []                                  | []                           | []                            | []                             |\n",
      "| tid_0da20e863cfc5f3e369868462bff74e0 | ['NuPIAO']                                    | ['Receptors, Erythropoietin / agonists*']                          | [['D12.776.543.750.705.852.150.200', 'D12.776.543.750.750.400.200.340']] | ['D12.776.543.750.705.852.150.200']                       | [['nupiao', 'rESP', 'SSS-06', 'SSS 06', 'SSS06', 'NuPIAO (iv)', 'recombinant erythropoietin stimulating protein', 'recombinant erythropoiesis-stimulating protein injection (CHO cells)']] | ['Erythropoietin receptor']                 | ['Erythropoietin receptor agonist']                                   | ['40640']                             | ['19694']                              | []                                       | []                                         | []                                          | []                                                  | []                                                                                                                                                                                                                              | []                                    | []                                                           | []                              | []                               | []         | []                           | []                          | []                   | []                 | []                                      | []                                        | []                                                | []                                   | []                                  | []                           | []                            | []                             |\n",
      "| tid_0e8fa21079f928135dfc6164a15285f8 | ['SSS-17']                                    | ['Prolyl-Hydroxylase Inhibitors* / pharmacology; therapeutic use'] | [['D27.505.519.389.740']]                                                | ['D27.505.519.389.740']                                   | [['SSS17', 'SSS 17', '[14C]SSS17', '[14C] SSS17', '[14C]-SSS17', '[¹⁴C]SSS17', '[¹⁴C] SSS17', '[¹⁴C]-SSS17', 'HIF-117', 'HIF 117', 'HIF117', '[14C]HIF-117']]                              | ['Hypoxia-inducible factor (HIF)']          | ['Hypoxia-inducible factor antagonist']                               | ['130313']                            | ['']                                   | []                                       | []                                         | []                                          | []                                                  | []                                                                                                                                                                                                                              | []                                    | []                                                           | []                              | []                               | []         | []                           | []                          | []                   | []                 | []                                      | []                                        | []                                                | []                                   | []                                  | []                           | []                            | []                             |\n",
      "| tid_0f04ddb3d522d528d083d7d5c43d1e18 | ['Metformin hydrochloride sustained-release'] | ['Gluconeogenesis / drug effects*']                                | [['G02.111.158.500', 'G03.191.500']]                                     | ['G02.111.158.500']                                       | [['Metformin Hydrochloride Sustained-release Tablets', 'metformin hydrochloride, Zhejiang Sunshine Mandi Pharmaceutical Co.', 'metformin hydrochloride extended-release', 'metformin XR']] | ['']                                        | ['Biguanide; gluconeogenesis inhibitor; insulin sensitizer']          | ['290388']                            | ['']                                   | ['Glucophage XR']                        | ['Gluconeogenesis / drug effects*']        | [['G02.111.158.500', 'G03.191.500']]        | ['G02.111.158.500']                                 | [['Glucophage', '格华止', 'metformin XR', 'metformin hydrochloride, once-daily, BMS', 'metformin HCl, once-daily, BMS', 'Diabex', 'Diabex XR', 'Dabex XR', 'Glifage XR', 'Metgluco', 'Stagid', 'SMP 862', 'SMP-862', 'SMP862']] | ['']                                  | ['Biguanide; gluconeogenesis inhibitor; insulin sensitizer'] | ['24060']                       | ['']                             | []         | []                           | []                          | []                   | []                 | []                                      | []                                        | []                                                | []                                   | []                                  | []                           | []                            | []                             |\n",
      "| tid_10562c0430b8b9bae93c94cadfb0a129 | ['RD-01']                                     | ['Receptors, Erythropoietin / agonists*']                          | [['D12.776.543.750.705.852.150.200', 'D12.776.543.750.750.400.200.340']] | ['D12.776.543.750.705.852.150.200']                       | [['RD001', 'RD-001', 'RD 001', 'RD01', 'RD-01 Long-acting rhEPO', 'Peg-EPO']]                                                                                                              | ['Erythropoietin receptor (EPOR)']          | ['PEGylated recombinant human erythropoietin (EPO) receptor agonist'] | ['144350']                            | ['']                                   | []                                       | []                                         | []                                          | []                                                  | []                                                                                                                                                                                                                              | []                                    | []                                                           | []                              | []                               | []         | []                           | []                          | []                   | []                 | []                                      | []                                        | []                                                | []                                   | []                                  | []                           | []                            | []                             |\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = Path(\"cache\")\n",
    "TRIALS_IN_PATH  = BASE_DIR / \"trial_product_breakdown_w_chosen_mechanisms.csv\"\n",
    "TRIALS_OUT_PATH = BASE_DIR / \"trial_mechanism_mesh_mapping.csv\"\n",
    "\n",
    "# -----------------------------------------\n",
    "# Sanity: TREE_INDEX and norm must already be loaded\n",
    "# -----------------------------------------\n",
    "try:\n",
    "    TREE_INDEX\n",
    "except NameError:\n",
    "    raise RuntimeError(\"TREE_INDEX is not defined — run the MeSH loader cell first.\")\n",
    "\n",
    "try:\n",
    "    norm\n",
    "except NameError:\n",
    "    raise RuntimeError(\"norm() is not defined — ensure it is defined in the MeSH loader cell.\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# Helpers\n",
    "# -----------------------------------------\n",
    "def parse_listish(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    try:\n",
    "        v = ast.literal_eval(s)\n",
    "        if isinstance(v, list):\n",
    "            return v\n",
    "    except Exception:\n",
    "        pass\n",
    "    return [s]\n",
    "\n",
    "\n",
    "def mesh_heading_to_tree_numbers(chosen_mesh_term: str):\n",
    "    \"\"\"\n",
    "    Return *all* tree numbers for the chosen MeSH heading.\n",
    "    \"\"\"\n",
    "    if not chosen_mesh_term or chosen_mesh_term == \"[none]\":\n",
    "        return []\n",
    "    base = chosen_mesh_term.split(\" / \")[0].replace(\"*\", \"\").strip()\n",
    "    key = norm(base)\n",
    "    info = TREE_INDEX.get(key)\n",
    "    if not info:\n",
    "        return []\n",
    "    return info.get(\"tree_numbers\", []) or []\n",
    "\n",
    "\n",
    "# Clinical-pharmacology-ish heuristic for ONE primary tree number\n",
    "PRIORITY_PREFIXES = [\n",
    "    \"D12.\",  # Proteins: receptors, enzymes, cytokines, antibodies (biologics / targets)\n",
    "    \"D27.\",  # Chemical Actions and Uses: classic pharmacologic classes\n",
    "    \"D02.\",  # Organic Chemicals: small-molecule drugs\n",
    "    \"D09.\",  # Carbohydrates\n",
    "    \"D23.\",  # Immunologic Factors\n",
    "    \"D26.\",  # Biological Factors\n",
    "]\n",
    "\n",
    "def _depth(tn: str) -> int:\n",
    "    # fewer segments = higher-level class\n",
    "    return len(tn.split(\".\"))\n",
    "\n",
    "def choose_primary_tree(tree_numbers):\n",
    "    \"\"\"\n",
    "    Given a list of tree numbers for ONE MeSH term,\n",
    "    choose a single 'primary' tree that best reflects the\n",
    "    pharmacologic / target-level concept.\n",
    "    \"\"\"\n",
    "    if not tree_numbers:\n",
    "        return \"\"\n",
    "\n",
    "    tns = [t.strip() for t in tree_numbers if isinstance(t, str) and t.strip()]\n",
    "    if not tns:\n",
    "        return \"\"\n",
    "\n",
    "    # 1) Prefer specific high-value branches (by prefix)\n",
    "    for prefix in PRIORITY_PREFIXES:\n",
    "        candidates = [t for t in tns if t.startswith(prefix)]\n",
    "        if candidates:\n",
    "            # choose the highest-level (shortest depth) node in that branch\n",
    "            return max(candidates, key=_depth)\n",
    "\n",
    "    # 2) Else prefer any Chemicals & Drugs branch (D*)\n",
    "    d_candidates = [t for t in tns if t.startswith(\"D\")]\n",
    "    if d_candidates:\n",
    "        return max(d_candidates, key=_depth)\n",
    "\n",
    "    # 3) Fallback: shortest overall\n",
    "    return max(tns, key=_depth)\n",
    "\n",
    "\n",
    "def trees_for_mesh_term_list(mesh_term_list):\n",
    "    \"\"\"\n",
    "    Given a list of MeSH headings (already mapped mechanism terms),\n",
    "    return:\n",
    "      all_tree_lists : list of [list-of-tree-numbers] per term\n",
    "      primary_trees  : list of ONE chosen tree number per term (\"\" if none)\n",
    "    \"\"\"\n",
    "    all_tree_lists = []\n",
    "    primary_trees = []\n",
    "\n",
    "    for term in mesh_term_list:\n",
    "        term_str = (term or \"\").strip()\n",
    "        if not term_str:\n",
    "            all_tree_lists.append([])\n",
    "            primary_trees.append(\"\")\n",
    "            continue\n",
    "\n",
    "        all_trees = mesh_heading_to_tree_numbers(term_str)\n",
    "        all_tree_lists.append(all_trees)\n",
    "\n",
    "        primary = choose_primary_tree(all_trees)\n",
    "        primary_trees.append(primary)\n",
    "\n",
    "    return all_tree_lists, primary_trees\n",
    "\n",
    "\n",
    "def insert_after(df, col, newcol, values):\n",
    "    cols = list(df.columns)\n",
    "    if col not in cols:\n",
    "        # fallback: append\n",
    "        df[newcol] = values\n",
    "        return\n",
    "    idx = cols.index(col)\n",
    "    df.insert(idx + 1, newcol, values)\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Load trial dataset\n",
    "# -----------------------------------------\n",
    "df = pd.read_csv(TRIALS_IN_PATH, dtype=str).fillna(\"\")\n",
    "print(f\"Loaded trials: {TRIALS_IN_PATH}, shape={df.shape}\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# Compute tree-number columns row-wise\n",
    "# -----------------------------------------\n",
    "inv_trees_all  = []\n",
    "inv_trees_primary = []\n",
    "\n",
    "ac_trees_all   = []\n",
    "ac_trees_primary = []\n",
    "\n",
    "soc_trees_all  = []\n",
    "soc_trees_primary = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    inv_mesh_terms = parse_listish(row.get(\"investigational_products_mechanism_mesh_terms\"))\n",
    "    ac_mesh_terms  = parse_listish(row.get(\"active_comparators_mechanism_mesh_terms\"))\n",
    "    soc_mesh_terms = parse_listish(row.get(\"standard_of_care_mechanism_mesh_terms\"))\n",
    "\n",
    "    inv_all_t, inv_primary_t = trees_for_mesh_term_list(inv_mesh_terms)\n",
    "    ac_all_t,  ac_primary_t  = trees_for_mesh_term_list(ac_mesh_terms)\n",
    "    soc_all_t, soc_primary_t = trees_for_mesh_term_list(soc_mesh_terms)\n",
    "\n",
    "    inv_trees_all.append(inv_all_t)\n",
    "    inv_trees_primary.append(inv_primary_t)\n",
    "\n",
    "    ac_trees_all.append(ac_all_t)\n",
    "    ac_trees_primary.append(ac_primary_t)\n",
    "\n",
    "    soc_trees_all.append(soc_all_t)\n",
    "    soc_trees_primary.append(soc_primary_t)\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Insert columns next to the mechanism_mesh_terms columns\n",
    "# -----------------------------------------\n",
    "insert_after(\n",
    "    df,\n",
    "    \"investigational_products_mechanism_mesh_terms\",\n",
    "    \"investigational_products_mechanism_tree_numbers\",\n",
    "    inv_trees_all,\n",
    ")\n",
    "insert_after(\n",
    "    df,\n",
    "    \"investigational_products_mechanism_tree_numbers\",\n",
    "    \"investigational_products_mechanism_primary_tree_numbers\",\n",
    "    inv_trees_primary,\n",
    ")\n",
    "\n",
    "insert_after(\n",
    "    df,\n",
    "    \"active_comparators_mechanism_mesh_terms\",\n",
    "    \"active_comparators_mechanism_tree_numbers\",\n",
    "    ac_trees_all,\n",
    ")\n",
    "insert_after(\n",
    "    df,\n",
    "    \"active_comparators_mechanism_tree_numbers\",\n",
    "    \"active_comparators_mechanism_primary_tree_numbers\",\n",
    "    ac_trees_primary,\n",
    ")\n",
    "\n",
    "insert_after(\n",
    "    df,\n",
    "    \"standard_of_care_mechanism_mesh_terms\",\n",
    "    \"standard_of_care_mechanism_tree_numbers\",\n",
    "    soc_trees_all,\n",
    ")\n",
    "insert_after(\n",
    "    df,\n",
    "    \"standard_of_care_mechanism_tree_numbers\",\n",
    "    \"standard_of_care_mechanism_primary_tree_numbers\",\n",
    "    soc_trees_primary,\n",
    ")\n",
    "\n",
    "# -----------------------------------------\n",
    "# Save output\n",
    "# -----------------------------------------\n",
    "TRIALS_OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(TRIALS_OUT_PATH, index=False)\n",
    "print(f\"✅ Wrote: {TRIALS_OUT_PATH}\")\n",
    "print(df.head(5).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e3e09af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tree number + term breakdown → cache/trial_mechanism_mesh_tree_number_counts.csv\n",
      "Top 20 combinations:\n",
      "| mesh_term                                                              | tree_number                             |   count |\n",
      "|:-----------------------------------------------------------------------|:----------------------------------------|--------:|\n",
      "| Receptors, Erythropoietin / agonists*                                  | D12.776.543.750.705.852.150.200         |      28 |\n",
      "| Vascular Endothelial Growth Factor A / antagonists & inhibitors*       | D12.644.276.100.800.200                 |      15 |\n",
      "| Interleukin-4 Receptor alpha Subunit / antagonists & inhibitors*       | D12.776.543.750.705.852.420.360.300.200 |      13 |\n",
      "| Cross-Linking Reagents                                                 | D27.720.470.410.210                     |      13 |\n",
      "| Programmed Cell Death 1 Receptor / antagonists & inhibitors*           | D12.776.543.750.705.222.875             |      12 |\n",
      "| Receptor, ErbB-2 / antagonists & inhibitors*                           | D12.776.543.750.750.400.074.400         |      11 |\n",
      "| Receptors, Thrombopoietin / agonists*                                  | D12.776.543.750.705.852.610             |       9 |\n",
      "| Tumor Necrosis Factor-alpha / antagonists & inhibitors*                | D12.644.276.374.500.800                 |       8 |\n",
      "| Tumor Necrosis Factor Inhibitors* / therapeutic use                    | D27.505.954.158.757                     |       8 |\n",
      "| ErbB Receptors / antagonists & inhibitors*; metabolism                 | D12.776.543.750.750.400.074             |       7 |\n",
      "| Antibodies, Bispecific* / therapeutic use; pharmacology                | D12.776.124.486.485.114.125             |       7 |\n",
      "| Receptors, Thrombopoietin / agonists                                   | D12.776.543.750.705.852.610             |       7 |\n",
      "| Tubulin Modulators / pharmacology*                                     | D27.505.519.593.249.500                 |       7 |\n",
      "| Tubulin Modulators* / pharmacology; chemistry                          | D27.505.519.593.249.500                 |       6 |\n",
      "| Interleukin-1beta / antagonists & inhibitors*                          | D12.644.276.374.465.010.600             |       6 |\n",
      "| Prolyl-Hydroxylase Inhibitors* / pharmacology; therapeutic use         | D27.505.519.389.740                     |       6 |\n",
      "| Urate Oxidase / pharmacology; therapeutic use*                         | D08.811.682.943                         |       6 |\n",
      "| Interleukin-17 / antagonists & inhibitors*                             | D12.644.276.374.465.517                 |       6 |\n",
      "| Interleukin-5* / antagonists & inhibitors; metabolism; therapeutic use | D12.644.276.374.465.202                 |       5 |\n",
      "| Antibodies, Bispecific* / therapeutic use                              | D12.776.124.486.485.114.125             |       4 |\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "BASE_DIR = Path(\"cache\")\n",
    "INPUT_PATH  = BASE_DIR / \"trial_mechanism_mesh_mapping.csv\"\n",
    "OUTPUT_PATH = BASE_DIR / \"trial_mechanism_mesh_tree_number_counts.csv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_PATH)\n",
    "\n",
    "# Columns with MeSH mechanism terms (already mapped)\n",
    "MESH_TERM_COLS = [\n",
    "    \"investigational_products_mechanism_mesh_terms\",\n",
    "    \"active_comparators_mechanism_mesh_terms\",\n",
    "    \"standard_of_care_mechanism_mesh_terms\",\n",
    "]\n",
    "\n",
    "# Columns with *primary* tree numbers (one tree per mechanism)\n",
    "TREE_COLS = [\n",
    "    \"investigational_products_mechanism_primary_tree_numbers\",\n",
    "    \"active_comparators_mechanism_primary_tree_numbers\",\n",
    "    \"standard_of_care_mechanism_primary_tree_numbers\",\n",
    "]\n",
    "\n",
    "def parse_list(x):\n",
    "    \"\"\"Parse list-like strings safely into Python lists.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    try:\n",
    "        val = ast.literal_eval(s)\n",
    "        return val if isinstance(val, list) else []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def is_none_term(s: str) -> bool:\n",
    "    \"\"\"Treat '[none]' / 'none' / empty as unusable.\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return True\n",
    "    t = s.strip().lower()\n",
    "    return t in (\"\", \"[none]\", \"none\")\n",
    "\n",
    "tree_to_mesh_terms = defaultdict(list)\n",
    "pair_counter = Counter()   # (mesh_term, primary_tree_number) → count\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # Parse lists for each mechanism category\n",
    "    mesh_term_lists   = [parse_list(row.get(c, \"[]\")) for c in MESH_TERM_COLS]\n",
    "    tree_number_lists = [parse_list(row.get(c, \"[]\")) for c in TREE_COLS]\n",
    "\n",
    "    # Iterate over the three mechanism categories in parallel\n",
    "    for mesh_terms, tree_nums in zip(mesh_term_lists, tree_number_lists):\n",
    "        for mesh_term, primary_tn in zip(mesh_terms, tree_nums):\n",
    "            if is_none_term(mesh_term):\n",
    "                continue\n",
    "            if not isinstance(primary_tn, str) or not primary_tn.strip():\n",
    "                continue\n",
    "\n",
    "            tn = primary_tn.strip()\n",
    "            mt = mesh_term.strip()\n",
    "\n",
    "            pair_counter[(mt, tn)] += 1\n",
    "            tree_to_mesh_terms[tn].append(mt)\n",
    "\n",
    "# Convert to DataFrame\n",
    "out_rows = [\n",
    "    {\n",
    "        \"mesh_term\": mesh_term,\n",
    "        \"tree_number\": tree_num,\n",
    "        \"count\": count,\n",
    "    }\n",
    "    for (mesh_term, tree_num), count in pair_counter.items()\n",
    "]\n",
    "\n",
    "out_df = pd.DataFrame(out_rows).sort_values(\"count\", ascending=False)\n",
    "\n",
    "# Save\n",
    "out_df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"Saved tree number + term breakdown → {OUTPUT_PATH}\")\n",
    "print(\"Top 20 combinations:\")\n",
    "print(out_df.head(20).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cd96708b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mechanism super-group mapping → cache/trial_mechanism_super_group_mapping.csv\n",
      "|    | mesh_term                                                                                                       | tree_number                             | mechanism_super_group                     |\n",
      "|---:|:----------------------------------------------------------------------------------------------------------------|:----------------------------------------|:------------------------------------------|\n",
      "|  0 | Receptors, Erythropoietin / agonists*                                                                           | D12.776.543.750.705.852.150.200         | cytokine_hormone_receptor_modulators      |\n",
      "|  1 | Vascular Endothelial Growth Factor A / antagonists & inhibitors*                                                | D12.644.276.100.800.200                 | targeted_pathway_inhibitors               |\n",
      "|  2 | Interleukin-4 Receptor alpha Subunit / antagonists & inhibitors*                                                | D12.776.543.750.705.852.420.360.300.200 | supportive_adjunctive_agents              |\n",
      "|  3 | Cross-Linking Reagents                                                                                          | D27.720.470.410.210                     | supportive_adjunctive_agents              |\n",
      "|  4 | Programmed Cell Death 1 Receptor / antagonists & inhibitors*                                                    | D12.776.543.750.705.222.875             | immune_checkpoint_immune_modulation       |\n",
      "|  5 | Receptor, ErbB-2 / antagonists & inhibitors*                                                                    | D12.776.543.750.750.400.074.400         | targeted_pathway_inhibitors               |\n",
      "|  6 | Receptors, Thrombopoietin / agonists*                                                                           | D12.776.543.750.705.852.610             | cytokine_hormone_receptor_modulators      |\n",
      "|  7 | Tumor Necrosis Factor-alpha / antagonists & inhibitors*                                                         | D12.644.276.374.500.800                 | immune_checkpoint_immune_modulation       |\n",
      "|  8 | Tumor Necrosis Factor Inhibitors* / therapeutic use                                                             | D27.505.954.158.757                     | metabolic_pathway_modulators              |\n",
      "|  9 | ErbB Receptors / antagonists & inhibitors*; metabolism                                                          | D12.776.543.750.750.400.074             | supportive_adjunctive_agents              |\n",
      "| 10 | Antibodies, Bispecific* / therapeutic use; pharmacology                                                         | D12.776.124.486.485.114.125             | biologic_antibodies_biologics             |\n",
      "| 11 | Receptors, Thrombopoietin / agonists                                                                            | D12.776.543.750.705.852.610             | cytokine_hormone_receptor_modulators      |\n",
      "| 12 | Tubulin Modulators / pharmacology*                                                                              | D27.505.519.593.249.500                 | classical_cytotoxic_chemotherapy          |\n",
      "| 13 | Tubulin Modulators* / pharmacology; chemistry                                                                   | D27.505.519.593.249.500                 | classical_cytotoxic_chemotherapy          |\n",
      "| 14 | Interleukin-1beta / antagonists & inhibitors*                                                                   | D12.644.276.374.465.010.600             | supportive_adjunctive_agents              |\n",
      "| 15 | Prolyl-Hydroxylase Inhibitors* / pharmacology; therapeutic use                                                  | D27.505.519.389.740                     | metabolic_pathway_modulators              |\n",
      "| 16 | Urate Oxidase / pharmacology; therapeutic use*                                                                  | D08.811.682.943                         | supportive_adjunctive_agents              |\n",
      "| 17 | Interleukin-17 / antagonists & inhibitors*                                                                      | D12.644.276.374.465.517                 | supportive_adjunctive_agents              |\n",
      "| 18 | Interleukin-5* / antagonists & inhibitors; metabolism; therapeutic use                                          | D12.644.276.374.465.202                 | supportive_adjunctive_agents              |\n",
      "| 19 | Antibodies, Bispecific* / therapeutic use                                                                       | D12.776.124.486.485.114.125             | biologic_antibodies_biologics             |\n",
      "| 20 | Antibodies, Bispecific*                                                                                         | D12.776.124.486.485.114.125             | biologic_antibodies_biologics             |\n",
      "| 21 | Calcineurin Inhibitors                                                                                          | D27.505.519.389.174                     | small_molecule_immunomod_antiinflammatory |\n",
      "| 22 | Folic Acid Antagonists                                                                                          | D27.505.519.389.350                     | metabolic_pathway_modulators              |\n",
      "| 23 | Thymidylate Synthase / antagonists & inhibitors*                                                                | D08.811.913.555.500.862                 | metabolic_pathway_modulators              |\n",
      "| 24 | Antineoplastic Agents, Alkylating* / pharmacology                                                               | D27.505.519.124.035                     | classical_cytotoxic_chemotherapy          |\n",
      "| 25 | Receptor, ErbB-2 / antagonists & inhibitors*; metabolism                                                        | D12.776.543.750.750.400.074.400         | targeted_pathway_inhibitors               |\n",
      "| 26 | ErbB Receptors / antagonists & inhibitors*                                                                      | D12.776.543.750.750.400.074             | supportive_adjunctive_agents              |\n",
      "| 27 | Rituximab                                                                                                       | D12.776.124.486.485.114.224.075.785     | biologic_antibodies_biologics             |\n",
      "| 28 | Folic Acid Antagonists / pharmacology*                                                                          | D27.505.519.389.350                     | metabolic_pathway_modulators              |\n",
      "| 29 | Thymidylate Synthase* / antagonists & inhibitors; metabolism                                                    | D08.811.913.555.500.862                 | metabolic_pathway_modulators              |\n",
      "| 30 | Receptors, Glucocorticoid / agonists; metabolism                                                                | D12.776.826.750.430                     | cytokine_hormone_receptor_modulators      |\n",
      "| 31 | Histamine H1 Antagonists / pharmacology*                                                                        | D27.505.519.625.375.425.400             | small_molecule_immunomod_antiinflammatory |\n",
      "| 32 | Receptors, Thrombopoietin / agonists; Receptors, Thrombopoietin / agonists*                                     | D12.776.543.750.705.852.610             | cytokine_hormone_receptor_modulators      |\n",
      "| 33 | Topoisomerase I Inhibitors*                                                                                     | D27.505.519.389.892.500                 | classical_cytotoxic_chemotherapy          |\n",
      "| 34 | Receptors, Interleukin-2* / agonists                                                                            | D12.776.543.750.705.852.420.320         | cytokine_hormone_receptor_modulators      |\n",
      "| 35 | Topoisomerase II Inhibitors*                                                                                    | D27.505.519.389.892.750                 | classical_cytotoxic_chemotherapy          |\n",
      "| 36 | Lectins, C-Type / antagonists & inhibitors*                                                                     | D12.776.503.280                         | immune_checkpoint_immune_modulation       |\n",
      "| 37 | Nerve Growth Factor* / antagonists & inhibitors; immunology                                                     | D12.644.276.860.437                     | supportive_adjunctive_agents              |\n",
      "| 38 | Receptors, Glucocorticoid / agonists; antagonists & inhibitors*; metabolism*                                    | D12.776.826.750.430                     | cytokine_hormone_receptor_modulators      |\n",
      "| 39 | Receptors, Calcium-Sensing / agonists*                                                                          | D12.776.543.750.695.115                 | cytokine_hormone_receptor_modulators      |\n",
      "| 40 | Complement C3b / antagonists & inhibitors                                                                       | D12.776.124.486.274.250.260             | supportive_adjunctive_agents              |\n",
      "| 41 | Antimetabolites, Antineoplastic / pharmacology*                                                                 | D27.505.519.186.144                     | classical_cytotoxic_chemotherapy          |\n",
      "| 42 | Gluconeogenesis / drug effects*                                                                                 | G02.111.158.500                         | metabolic_pathway_modulators              |\n",
      "| 43 | Janus Kinase Inhibitors / pharmacology*                                                                         | D27.505.519.389.755.500                 | targeted_pathway_inhibitors               |\n",
      "| 44 | Immune Checkpoint Inhibitors*                                                                                   | D27.505.954.248.384.500                 | metabolic_pathway_modulators              |\n",
      "| 45 | Antithrombins / agonists                                                                                        | D27.505.519.389.745.800.449             | supportive_adjunctive_agents              |\n",
      "| 46 | Immune Checkpoint Inhibitors* / pharmacology; pharmacokinetics                                                  | D27.505.954.248.384.500                 | metabolic_pathway_modulators              |\n",
      "| 47 | Proto-Oncogene Proteins c-bcl-2* / antagonists & inhibitors; metabolism; genetics                               | D12.776.624.664.700.169                 | supportive_adjunctive_agents              |\n",
      "| 48 | Glucocorticoids* / metabolism; pharmacology                                                                     | D27.505.696.399.472.488                 | small_molecule_immunomod_antiinflammatory |\n",
      "| 49 | Tubulin Modulators / therapeutic use                                                                            | D27.505.519.593.249.500                 | classical_cytotoxic_chemotherapy          |\n",
      "| 50 | Antimetabolites, Antineoplastic / chemical synthesis; metabolism; pharmacology*                                 | D27.505.519.186.144                     | classical_cytotoxic_chemotherapy          |\n",
      "| 51 | Tubulin Modulators / chemistry; pharmacology*                                                                   | D27.505.519.593.249.500                 | classical_cytotoxic_chemotherapy          |\n",
      "| 52 | Tubulin Modulators / therapeutic use*                                                                           | D27.505.519.593.249.500                 | classical_cytotoxic_chemotherapy          |\n",
      "| 53 | Immunosuppressive Agents*                                                                                       | D27.505.696.477.656                     | small_molecule_immunomod_antiinflammatory |\n",
      "| 54 | Antimalarials* / pharmacology                                                                                   | D27.505.954.122.250.100.085             | small_molecule_immunomod_antiinflammatory |\n",
      "| 55 | Antimetabolites, Antineoplastic* / adverse effects; pharmacology; therapeutic use                               | D27.505.519.186.144                     | classical_cytotoxic_chemotherapy          |\n",
      "| 56 | Antibodies, Monoclonal / economics*; therapeutic use*                                                           | D12.776.124.486.485.114.224             | biologic_antibodies_biologics             |\n",
      "| 57 | Programmed Cell Death 1 Receptor* / antagonists & inhibitors; immunology                                        | D12.776.543.750.705.222.875             | immune_checkpoint_immune_modulation       |\n",
      "| 58 | Interleukin 1 Receptor Antagonist Protein*                                                                      | D12.644.276.374.460                     | immune_checkpoint_immune_modulation       |\n",
      "| 59 | Leucovorin / therapeutic use                                                                                    | D03.633.100.733.631.400.800.350.450     | supportive_adjunctive_agents              |\n",
      "| 60 | Interleukin-2 Receptor alpha Subunit* / antagonists & inhibitors; immunology                                    | D12.776.543.750.705.852.420.320.500     | cytokine_hormone_receptor_modulators      |\n",
      "| 61 | Recombinant Fusion Proteins* / pharmacology; therapeutic use                                                    | D12.776.828.300                         | vaccines_immune_biologics                 |\n",
      "| 62 | Cyclooxygenase Inhibitors / pharmacology                                                                        | D27.505.696.663.850.014.040.500.500     | small_molecule_immunomod_antiinflammatory |\n",
      "| 63 | Cancer Vaccines* / immunology; therapeutic use                                                                  | D20.215.894.200                         | vaccines_immune_biologics                 |\n",
      "| 64 | Vascular Endothelial Growth Factor A* / antagonists & inhibitors; genetics; physiology                          | D12.644.276.100.800.200                 | targeted_pathway_inhibitors               |\n",
      "| 65 | Interleukin 1 Receptor Antagonist Protein                                                                       | D12.644.276.374.460                     | immune_checkpoint_immune_modulation       |\n",
      "| 66 | MTOR Inhibitors*                                                                                                | D27.505.519.389.755.750                 | targeted_pathway_inhibitors               |\n",
      "| 67 | Glucocorticoids                                                                                                 | D27.505.696.399.472.488                 | small_molecule_immunomod_antiinflammatory |\n",
      "| 68 | Receptor, ErbB-2 / antagonists & inhibitors                                                                     | D12.776.543.750.750.400.074.400         | targeted_pathway_inhibitors               |\n",
      "| 69 | Receptor, ErbB-2 / antagonists & inhibitors*; immunology                                                        | D12.776.543.750.750.400.074.400         | targeted_pathway_inhibitors               |\n",
      "| 70 | Anion Exchange Resins*                                                                                          | D27.720.470.420.050                     | supportive_adjunctive_agents              |\n",
      "| 71 | Programmed Cell Death 1 Receptor* / antagonists & inhibitors                                                    | D12.776.543.750.705.222.875             | immune_checkpoint_immune_modulation       |\n",
      "| 72 | Immunosuppressive Agents / therapeutic use*                                                                     | D27.505.696.477.656                     | small_molecule_immunomod_antiinflammatory |\n",
      "| 73 | Receptors, Opioid, kappa / agonists*                                                                            | D12.776.543.750.720.600.610.400         | supportive_adjunctive_agents              |\n",
      "| 74 | Tumor Necrosis Factor Ligand Superfamily Member 15* / antagonists & inhibitors                                  | D12.644.276.374.750.720                 | immune_checkpoint_immune_modulation       |\n",
      "| 75 | CD47 Antigen / antagonists & inhibitors*                                                                        | D12.776.395.550.014                     | immune_checkpoint_immune_modulation       |\n",
      "| 76 | Receptors, Opioid, kappa / agonists                                                                             | D12.776.543.750.720.600.610.400         | supportive_adjunctive_agents              |\n",
      "| 77 | Lectins, C-Type / antagonists & inhibitors*; immunology                                                         | D12.776.503.280                         | immune_checkpoint_immune_modulation       |\n",
      "| 78 | Folic Acid Antagonists / pharmacology*; therapeutic use                                                         | D27.505.519.389.350                     | metabolic_pathway_modulators              |\n",
      "| 79 | Phosphodiesterase 4 Inhibitors* / pharmacology; therapeutic use                                                 | D27.505.519.389.735.374                 | small_molecule_immunomod_antiinflammatory |\n",
      "| 80 | Phosphodiesterase 4 Inhibitors* / pharmacology; Phosphodiesterase 4 Inhibitors* / pharmacology; therapeutic use | D27.505.519.389.735.374                 | small_molecule_immunomod_antiinflammatory |\n",
      "| 81 | Phosphodiesterase 4 Inhibitors* / pharmacology                                                                  | D27.505.519.389.735.374                 | small_molecule_immunomod_antiinflammatory |\n",
      "| 82 | Vascular Endothelial Growth Factor A / antagonists & inhibitors; immunology*                                    | D12.644.276.100.800.200                 | targeted_pathway_inhibitors               |\n",
      "| 83 | Histamine H1 Antagonists* / pharmacology                                                                        | D27.505.519.625.375.425.400             | small_molecule_immunomod_antiinflammatory |\n",
      "| 84 | Antibodies, Bispecific* / therapeutic use; immunology; pharmacology                                             | D12.776.124.486.485.114.125             | biologic_antibodies_biologics             |\n",
      "| 85 | Tubulin Modulators / pharmacology                                                                               | D27.505.519.593.249.500                 | classical_cytotoxic_chemotherapy          |\n",
      "| 86 | Receptors, Chimeric Antigen*                                                                                    | D12.776.543.750.705.816.824.150         | biologic_antibodies_biologics             |\n",
      "| 87 | IMP Dehydrogenase / antagonists & inhibitors*                                                                   | D08.811.682.047.820.450                 | metabolic_pathway_modulators              |\n",
      "| 88 | Interleukin-33* / antagonists & inhibitors; immunology                                                          | D12.644.276.374.465.850                 | immune_checkpoint_immune_modulation       |\n",
      "| 89 | Leucovorin / pharmacology; therapeutic use                                                                      | D03.633.100.733.631.400.800.350.450     | supportive_adjunctive_agents              |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"cache\")\n",
    "INPUT_PATH  = BASE_DIR / \"trial_mechanism_mesh_tree_number_counts.csv\"\n",
    "OUTPUT_PATH = BASE_DIR / \"trial_mechanism_super_group_mapping.csv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_PATH)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Define super-group labels (9 buckets)\n",
    "# -------------------------------------------------------------------\n",
    "G1 = \"cytokine_hormone_receptor_modulators\"\n",
    "G2 = \"immune_checkpoint_immune_modulation\"\n",
    "G3 = \"targeted_pathway_inhibitors\"\n",
    "G4 = \"classical_cytotoxic_chemotherapy\"\n",
    "G5 = \"biologic_antibodies_biologics\"\n",
    "G6 = \"small_molecule_immunomod_antiinflammatory\"\n",
    "G7 = \"metabolic_pathway_modulators\"\n",
    "G8 = \"vaccines_immune_biologics\"\n",
    "G9 = \"supportive_adjunctive_agents\"\n",
    "\n",
    "\n",
    "def classify_super_group(mesh_term: str, tree_number: str) -> str:\n",
    "    \"\"\"\n",
    "    Heuristic mapping of mesh_term + tree_number to one of 9 MOA super-groups.\n",
    "    Think like a clinical pharmacologist, but keep it deterministic and simple.\n",
    "    \"\"\"\n",
    "    t = (mesh_term or \"\").lower()\n",
    "    tn = (tree_number or \"\").strip()\n",
    "\n",
    "    # -----------------------\n",
    "    # GROUP 8: Vaccines & immune biologics (non-mAb)\n",
    "    # -----------------------\n",
    "    if \"vaccine\" in t:\n",
    "        return G8\n",
    "    if \"recombinant fusion proteins\" in t:\n",
    "        return G8\n",
    "\n",
    "    # -----------------------\n",
    "    # GROUP 5: Biologic antibodies (mono / bispecific / CAR / fusion)\n",
    "    # -----------------------\n",
    "    if (\n",
    "        \"antibod\" in t\n",
    "        or \"immunoconjugate\" in t\n",
    "        or \"chimeric antigen\" in t\n",
    "    ):\n",
    "        return G5\n",
    "    # Core monoclonal antibody/fusion protein MeSH branches\n",
    "    if tn.startswith(\"D12.776.124.486.485.114\"):  # Antibodies, Monoclonal*\n",
    "        return G5\n",
    "    if tn.startswith(\"D12.776.124.790.651.114\"):  # Therapeutic mAbs under Immunologic Factors\n",
    "        return G5\n",
    "    if tn.startswith(\"D12.776.828.300\"):  # Recombinant Fusion Proteins\n",
    "        return G5\n",
    "\n",
    "    # -----------------------\n",
    "    # GROUP 1: Cytokine & hormone receptor modulators\n",
    "    # (EPO-R, TPO-R, IL-2R, glucocorticoid receptor, Ca-sensing receptor, etc.)\n",
    "    # -----------------------\n",
    "    if any(kw in t for kw in [\n",
    "        \"receptors, erythropoietin\",\n",
    "        \"erythropoietin\",\n",
    "        \"receptors, thrombopoietin\",\n",
    "        \"thrombopoietin\",\n",
    "        \"receptors, interleukin-2\",\n",
    "        \"interleukin-2 receptor alpha subunit\",\n",
    "        \"receptors, glucocorticoid\",\n",
    "        \"receptors, calcium-sensing\",\n",
    "    ]):\n",
    "        return G1\n",
    "    # Hematopoietic / cytokine receptor MeSH branches seen in your table\n",
    "    if tn.startswith(\"D12.776.543.750.705.852.150\"):  # EPO-R agonists\n",
    "        return G1\n",
    "    if tn.startswith(\"D12.776.543.750.705.852.610\"):  # TPO-R agonists\n",
    "        return G1\n",
    "    if tn.startswith(\"D12.776.543.750.705.852.420.320\"):  # IL-2R\n",
    "        return G1\n",
    "    if tn.startswith(\"D12.776.826.750.430\"):  # Glucocorticoid receptor\n",
    "        return G1\n",
    "    if tn.startswith(\"D12.776.543.750.695.115\"):  # Ca-sensing receptor\n",
    "        return G1\n",
    "\n",
    "    # -----------------------\n",
    "    # GROUP 2: Immune checkpoint & immune modulation\n",
    "    # (PD-1, TNF, CD47, IL-33, IL-1RA, lectins, etc.)\n",
    "    # -----------------------\n",
    "    if any(kw in t for kw in [\n",
    "        \"programmed cell death 1 receptor\", \"pd-1\", \"pd1\",\n",
    "        \"pd-l1\", \"pdl1\",\n",
    "        \"tumor necrosis factor-alpha\",\n",
    "        \"tnf\",\n",
    "        \"tumor necrosis factor ligand superfamily member\",\n",
    "        \"cd47 antigen\",\n",
    "        \"lectins, c-type\",\n",
    "        \"interleukin-33\",\n",
    "        \"interleukin 1 receptor antagonist protein\",\n",
    "    ]):\n",
    "        return G2\n",
    "    if tn.startswith(\"D12.776.543.750.705.222.875\"):  # PD-1 receptor\n",
    "        return G2\n",
    "    if tn.startswith(\"D12.644.276.374.500.800\"):  # TNF-alpha\n",
    "        return G2\n",
    "    if tn.startswith(\"D12.776.395.550.014\"):  # CD47 antigen\n",
    "        return G2\n",
    "    if tn.startswith(\"D12.776.503.280\"):  # C-type lectins\n",
    "        return G2\n",
    "    if tn.startswith(\"D12.644.276.374.750.720\"):  # TNF ligand superfamily member 15\n",
    "        return G2\n",
    "    if tn.startswith(\"D12.644.276.374.465.850\"):  # IL-33\n",
    "        return G2\n",
    "\n",
    "    # -----------------------\n",
    "    # GROUP 3: Targeted pathway inhibitors (RTK / JAK-STAT / mTOR, VEGF, HER2)\n",
    "    # -----------------------\n",
    "    if any(kw in t for kw in [\n",
    "        \"vascular endothelial growth factor a\",\n",
    "        \"receptor, erbb-2\",\n",
    "        \"erbb2\",\n",
    "        \"vegf\",\n",
    "        \"janus kinase inhibitors\",\n",
    "        \"jak inhibitor\",\n",
    "        \"mtor inhibitors\",\n",
    "        \"tor serine-threonine kinases\",\n",
    "    ]):\n",
    "        return G3\n",
    "    # VEGF-A branch\n",
    "    if tn.startswith(\"D12.644.276.100.800.200\"):\n",
    "        return G3\n",
    "    # HER2 / ErbB-2 receptor branch\n",
    "    if tn.startswith(\"D12.776.543.750.750.400.074.400\"):\n",
    "        return G3\n",
    "    # JAK / mTOR live under D27.505.519.* but we key by text above.\n",
    "\n",
    "    # -----------------------\n",
    "    # GROUP 4: Classical cytotoxic chemotherapy (antimetabolite / alkylator / tubulin / topo)\n",
    "    # -----------------------\n",
    "    if any(kw in t for kw in [\n",
    "        \"antimetabolites, antineoplastic\",\n",
    "        \"antineoplastic agents, alkylating\",\n",
    "        \"topoisomerase i inhibitors\",\n",
    "        \"topoisomerase ii inhibitors\",\n",
    "        \"vinca alkaloids\",\n",
    "        \"vinblastine\",\n",
    "        \"taxoids\",\n",
    "        \"paclitaxel\",\n",
    "        \"tubulin modulators\",\n",
    "    ]):\n",
    "        return G4\n",
    "    # Classical chemo branches\n",
    "    if tn.startswith(\"D27.505.519.186\"):  # antimetabolites, antineoplastic\n",
    "        return G4\n",
    "    if tn.startswith(\"D27.505.519.124\"):  # alkylating agents\n",
    "        return G4\n",
    "    if tn.startswith(\"D27.505.519.593.249.500\"):  # tubulin modulators\n",
    "        return G4\n",
    "    # You can add explicit topo/anthracycline branches here if you see them later.\n",
    "\n",
    "    # -----------------------\n",
    "    # GROUP 6: Small-molecule immunomodulators & anti-inflammatories\n",
    "    # (PDE4 inhibitors, COX inhibitors, glucocorticoids as drugs, antimalarials)\n",
    "    # -----------------------\n",
    "    if any(kw in t for kw in [\n",
    "        \"phosphodiesterase 4 inhibitors\",\n",
    "        \"cyclooxygenase inhibitors\",\n",
    "        \"histamine h1 antagonists\",\n",
    "        \"glucocorticoids* / metabolism; pharmacology\",\n",
    "        \"glucocorticoids\",  # as a drug class\n",
    "        \"antimalarials\",\n",
    "        \"immunosuppressive agents\",\n",
    "        \"calcineurin inhibitors\",\n",
    "    ]):\n",
    "        return G6\n",
    "    if tn.startswith(\"D27.505.519.625.375.425.400\"):  # H1 antagonists\n",
    "        return G6\n",
    "    if tn.startswith(\"D27.505.696.663.850.014.040.500.500\"):  # COX inhibitors\n",
    "        return G6\n",
    "    if tn.startswith(\"D27.505.519.389.735.374\"):  # PDE4 inhibitors\n",
    "        return G6\n",
    "    if tn.startswith(\"D27.505.696.477.656\"):  # Immunosuppressive Agents*\n",
    "        return G6\n",
    "    if tn.startswith(\"D27.505.954.122.250.100.085\"):  # Antimalarials\n",
    "        return G6\n",
    "\n",
    "    # -----------------------\n",
    "    # GROUP 7: Metabolic pathway modulators\n",
    "    # (gluconeogenesis, metabolic enzymes, etc.)\n",
    "    # -----------------------\n",
    "    if any(kw in t for kw in [\n",
    "        \"gluconeogenesis / drug effects\",\n",
    "        \"gluconeogenesis\",\n",
    "        \"biguanides\",\n",
    "        \"imp dehydrogenase\",\n",
    "        \"thymidylate synthase\",\n",
    "        \"thymidine phosphorylase\",\n",
    "    ]):\n",
    "        return G7\n",
    "    if tn.startswith(\"G02.111.158.500\"):  # Gluconeogenesis / drug effects*\n",
    "        return G7\n",
    "    if tn.startswith(\"D08.811.682.047.820.450\"):  # IMP dehydrogenase\n",
    "        return G7\n",
    "\n",
    "    # -----------------------\n",
    "    # GROUP 9: Supportive / adjunctive agents\n",
    "    # (anion exchange resins, leucovorin, antithrombins, etc.)\n",
    "    # -----------------------\n",
    "    if any(kw in t for kw in [\n",
    "        \"anion exchange resins\",\n",
    "        \"antithrombins\",\n",
    "        \"leucovorin\",\n",
    "    ]):\n",
    "        return G9\n",
    "    if tn.startswith(\"D27.720.470.420.050\"):  # Anion exchange resins\n",
    "        return G9\n",
    "    if tn.startswith(\"D27.505.519.389.745.800.449\"):  # Antithrombins / agonists\n",
    "        return G9\n",
    "    if \"leucovorin\" in t:\n",
    "        return G9\n",
    "\n",
    "    # -----------------------\n",
    "    # Fallbacks:\n",
    "    # - If D27.505.* and not otherwise classified → treat as metabolic/chemical other\n",
    "    # -----------------------\n",
    "    if tn.startswith(\"D27.505.\"):\n",
    "        return G7  # generic chemical/metabolic \"other\" rather than immuno\n",
    "\n",
    "    # Absolute default: call it supportive/other\n",
    "    return G9\n",
    "\n",
    "\n",
    "# Apply classifier\n",
    "out_df = df[[\"mesh_term\", \"tree_number\"]].copy()\n",
    "out_df[\"mechanism_super_group\"] = [\n",
    "    classify_super_group(m, tn) for m, tn in zip(out_df[\"mesh_term\"], out_df[\"tree_number\"])\n",
    "]\n",
    "\n",
    "# Save\n",
    "out_df.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"Saved mechanism super-group mapping → {OUTPUT_PATH}\")\n",
    "print(out_df.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1b4f3847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 56 tree_number → super_group mappings\n",
      "Wrote final trial-level file with super-groups → cache/trial_mechanism_with_super_groups.csv\n",
      "| trial_hash                           | investigational_products                      | investigational_products_mechanism_mesh_terms                      | investigational_products_mechanism_tree_numbers                          | investigational_products_mechanism_primary_tree_numbers   | investigational_products_mechanism_super_group   | investigational_products_alternative_names                                                                                                                                                 | investigational_products_molecular_target   | investigational_products_mechanism                                    | investigational_products_tt_drug_id   | investigational_products_bmt_drug_id   | active_comparators                       | active_comparators_mechanism_mesh_terms    | active_comparators_mechanism_tree_numbers   | active_comparators_mechanism_primary_tree_numbers   | active_comparators_mechanism_super_group   | active_comparators_alternative_names                                                                                                                                                                                            | active_comparators_molecular_target   | active_comparators_mechanism                                 | active_comparators_tt_drug_id   | active_comparators_bmt_drug_id   | placebos   | placebos_alternative_names   | placebos_molecular_target   | placebos_mechanism   | standard_of_care   | standard_of_care_mechanism_mesh_terms   | standard_of_care_mechanism_tree_numbers   | standard_of_care_mechanism_primary_tree_numbers   | standard_of_care_mechanism_super_group   | standard_of_care_alternative_names   | standard_of_care_molecular_target   | standard_of_care_mechanism   | standard_of_care_tt_drug_id   | standard_of_care_bmt_drug_id   |\n",
      "|:-------------------------------------|:----------------------------------------------|:-------------------------------------------------------------------|:-------------------------------------------------------------------------|:----------------------------------------------------------|:-------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------|:----------------------------------------------------------------------|:--------------------------------------|:---------------------------------------|:-----------------------------------------|:-------------------------------------------|:--------------------------------------------|:----------------------------------------------------|:-------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------|:-------------------------------------------------------------|:--------------------------------|:---------------------------------|:-----------|:-----------------------------|:----------------------------|:---------------------|:-------------------|:----------------------------------------|:------------------------------------------|:--------------------------------------------------|:-----------------------------------------|:-------------------------------------|:------------------------------------|:-----------------------------|:------------------------------|:-------------------------------|\n",
      "| tid_0541995757b10e613a42173d6b8ddc09 | ['cinacalcet hydrochloride (test)']           | ['Receptors, Calcium-Sensing / agonists*']                         | [['D12.776.543.750.695.115']]                                            | ['D12.776.543.750.695.115']                               | ['cytokine_hormone_receptor_modulators']         | [['cinacalcet HCl, Zhejiang Wansheng Pharmaceutical Co.', 'cinacalcet hydrochloride, Zhejiang Wansheng Pharmaceutical Co.', 'cinacalcet, Zhejiang Wansheng Pharmaceutical Co.']]           | ['Calcium-sensing receptor (CaSR)']         | ['Calcimimetic; calcium-sensing receptor agonist']                    | ['194454']                            | ['']                                   | ['cinacalcet hydrochloride (reference)'] | ['Receptors, Calcium-Sensing / agonists*'] | [['D12.776.543.750.695.115']]               | ['D12.776.543.750.695.115']                         | ['cytokine_hormone_receptor_modulators']   | [['cinacalcet hydrochloride tablets produced by Kyowa Kirin Co., Ltd.', 'cinacalcet HCl (Kyowa Kirin)']]                                                                                                                        | ['Calcium-sensing receptor (CaSR)']   | ['Calcimimetic; calcium-sensing receptor agonist']           | ['']                            | ['']                             | []         | []                           | []                          | []                   | []                 | []                                      | []                                        | []                                                | []                                       | []                                   | []                                  | []                           | []                            | []                             |\n",
      "| tid_0da20e863cfc5f3e369868462bff74e0 | ['NuPIAO']                                    | ['Receptors, Erythropoietin / agonists*']                          | [['D12.776.543.750.705.852.150.200', 'D12.776.543.750.750.400.200.340']] | ['D12.776.543.750.705.852.150.200']                       | ['cytokine_hormone_receptor_modulators']         | [['nupiao', 'rESP', 'SSS-06', 'SSS 06', 'SSS06', 'NuPIAO (iv)', 'recombinant erythropoietin stimulating protein', 'recombinant erythropoiesis-stimulating protein injection (CHO cells)']] | ['Erythropoietin receptor']                 | ['Erythropoietin receptor agonist']                                   | ['40640']                             | ['19694']                              | []                                       | []                                         | []                                          | []                                                  | []                                         | []                                                                                                                                                                                                                              | []                                    | []                                                           | []                              | []                               | []         | []                           | []                          | []                   | []                 | []                                      | []                                        | []                                                | []                                       | []                                   | []                                  | []                           | []                            | []                             |\n",
      "| tid_0e8fa21079f928135dfc6164a15285f8 | ['SSS-17']                                    | ['Prolyl-Hydroxylase Inhibitors* / pharmacology; therapeutic use'] | [['D27.505.519.389.740']]                                                | ['D27.505.519.389.740']                                   | ['metabolic_pathway_modulators']                 | [['SSS17', 'SSS 17', '[14C]SSS17', '[14C] SSS17', '[14C]-SSS17', '[¹⁴C]SSS17', '[¹⁴C] SSS17', '[¹⁴C]-SSS17', 'HIF-117', 'HIF 117', 'HIF117', '[14C]HIF-117']]                              | ['Hypoxia-inducible factor (HIF)']          | ['Hypoxia-inducible factor antagonist']                               | ['130313']                            | ['']                                   | []                                       | []                                         | []                                          | []                                                  | []                                         | []                                                                                                                                                                                                                              | []                                    | []                                                           | []                              | []                               | []         | []                           | []                          | []                   | []                 | []                                      | []                                        | []                                                | []                                       | []                                   | []                                  | []                           | []                            | []                             |\n",
      "| tid_0f04ddb3d522d528d083d7d5c43d1e18 | ['Metformin hydrochloride sustained-release'] | ['Gluconeogenesis / drug effects*']                                | [['G02.111.158.500', 'G03.191.500']]                                     | ['G02.111.158.500']                                       | ['metabolic_pathway_modulators']                 | [['Metformin Hydrochloride Sustained-release Tablets', 'metformin hydrochloride, Zhejiang Sunshine Mandi Pharmaceutical Co.', 'metformin hydrochloride extended-release', 'metformin XR']] | ['']                                        | ['Biguanide; gluconeogenesis inhibitor; insulin sensitizer']          | ['290388']                            | ['']                                   | ['Glucophage XR']                        | ['Gluconeogenesis / drug effects*']        | [['G02.111.158.500', 'G03.191.500']]        | ['G02.111.158.500']                                 | ['metabolic_pathway_modulators']           | [['Glucophage', '格华止', 'metformin XR', 'metformin hydrochloride, once-daily, BMS', 'metformin HCl, once-daily, BMS', 'Diabex', 'Diabex XR', 'Dabex XR', 'Glifage XR', 'Metgluco', 'Stagid', 'SMP 862', 'SMP-862', 'SMP862']] | ['']                                  | ['Biguanide; gluconeogenesis inhibitor; insulin sensitizer'] | ['24060']                       | ['']                             | []         | []                           | []                          | []                   | []                 | []                                      | []                                        | []                                                | []                                       | []                                   | []                                  | []                           | []                            | []                             |\n",
      "| tid_10562c0430b8b9bae93c94cadfb0a129 | ['RD-01']                                     | ['Receptors, Erythropoietin / agonists*']                          | [['D12.776.543.750.705.852.150.200', 'D12.776.543.750.750.400.200.340']] | ['D12.776.543.750.705.852.150.200']                       | ['cytokine_hormone_receptor_modulators']         | [['RD001', 'RD-001', 'RD 001', 'RD01', 'RD-01 Long-acting rhEPO', 'Peg-EPO']]                                                                                                              | ['Erythropoietin receptor (EPOR)']          | ['PEGylated recombinant human erythropoietin (EPO) receptor agonist'] | ['144350']                            | ['']                                   | []                                       | []                                         | []                                          | []                                                  | []                                         | []                                                                                                                                                                                                                              | []                                    | []                                                           | []                              | []                               | []         | []                           | []                          | []                   | []                 | []                                      | []                                        | []                                                | []                                       | []                                   | []                                  | []                           | []                            | []                             |\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"cache\")\n",
    "\n",
    "MAP_PATH      = BASE_DIR / \"trial_mechanism_super_group_mapping.csv\"\n",
    "TRIALS_IN     = BASE_DIR / \"trial_mechanism_mesh_mapping.csv\"\n",
    "TRIALS_OUT    = BASE_DIR / \"trial_mechanism_with_super_groups.csv\"\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Load mapping: tree_number → super_group\n",
    "# ---------------------------------------------------\n",
    "map_df = pd.read_csv(MAP_PATH)\n",
    "\n",
    "# Normalize tree_number a bit (strip whitespace)\n",
    "map_df[\"tree_number\"] = map_df[\"tree_number\"].astype(str).str.strip()\n",
    "\n",
    "# If there are duplicates, we just keep the first (should all agree anyway)\n",
    "mapping = {}\n",
    "for _, row in map_df.iterrows():\n",
    "    tn = str(row[\"tree_number\"]).strip()\n",
    "    sg = row[\"mechanism_super_group\"]\n",
    "    if tn and tn not in mapping:\n",
    "        mapping[tn] = sg\n",
    "\n",
    "print(f\"Loaded {len(mapping):,} tree_number → super_group mappings\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Helpers\n",
    "# ---------------------------------------------------\n",
    "def parse_list(x):\n",
    "    \"\"\"Parse list-like strings (e.g. \"['a','b']\") into Python lists.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    try:\n",
    "        v = ast.literal_eval(s)\n",
    "        if isinstance(v, list):\n",
    "            return v\n",
    "    except Exception:\n",
    "        return []\n",
    "    # If it's a single scalar, wrap in list\n",
    "    return [s]\n",
    "\n",
    "\n",
    "def build_super_group_list(mech_terms, mech_trees):\n",
    "    \"\"\"\n",
    "    Given:\n",
    "      mech_terms : list of MeSH headings (unused except for length)\n",
    "      mech_trees : list of primary tree numbers (strings)\n",
    "    Return:\n",
    "      list of mechanism_super_group strings (same length).\n",
    "    \"\"\"\n",
    "    # Ensure lists\n",
    "    mech_trees = mech_trees or []\n",
    "    mech_terms = mech_terms or []\n",
    "\n",
    "    n = max(len(mech_terms), len(mech_trees))\n",
    "    out = []\n",
    "\n",
    "    for i in range(n):\n",
    "        tn = (mech_trees[i] if i < len(mech_trees) else \"\") or \"\"\n",
    "        tn = tn.strip()\n",
    "        if not tn:\n",
    "            out.append(\"\")\n",
    "            continue\n",
    "        out.append(mapping.get(tn, \"\"))  # \"\" if not found\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_super_group_list_with_fallback(\n",
    "    mech_terms,\n",
    "    mech_trees,\n",
    "    fallback_terms,\n",
    "    fallback_trees,\n",
    "):\n",
    "    \"\"\"\n",
    "    For investigational products:\n",
    "    - First try mechanism-based MeSH mapping (mech_terms/mech_trees).\n",
    "    - If the mechanism term is missing / '[none]' / empty, fall back to\n",
    "      the investigational product MeSH mapping (fallback_terms/fallback_trees).\n",
    "\n",
    "    Mapping itself is done ONLY on tree_number.\n",
    "    \"\"\"\n",
    "    # Ensure all are lists\n",
    "    mech_terms     = mech_terms or []\n",
    "    mech_trees     = mech_trees or []\n",
    "    fallback_terms = fallback_terms or []\n",
    "    fallback_trees = fallback_trees or []\n",
    "\n",
    "    n = max(len(mech_terms), len(mech_trees), len(fallback_terms), len(fallback_trees))\n",
    "    out = []\n",
    "\n",
    "    for i in range(n):\n",
    "        # Primary (mechanism-based)\n",
    "        term_mech = (mech_terms[i] if i < len(mech_terms) else \"\") or \"\"\n",
    "        tn_mech   = (mech_trees[i] if i < len(mech_trees) else \"\") or \"\"\n",
    "\n",
    "        term_mech = term_mech.strip()\n",
    "        tn_mech   = tn_mech.strip()\n",
    "\n",
    "        # Fallback (drug-based)\n",
    "        term_fb = (fallback_terms[i] if i < len(fallback_terms) else \"\") or \"\"\n",
    "        tn_fb   = (fallback_trees[i] if i < len(fallback_trees) else \"\") or \"\"\n",
    "\n",
    "        term_fb = term_fb.strip()\n",
    "        tn_fb   = tn_fb.strip()\n",
    "\n",
    "        # Decide which tree number to use\n",
    "        chosen_tn = \"\"\n",
    "        # 1) Use mechanism term if present and not [none]\n",
    "        if term_mech and term_mech != \"[none]\" and tn_mech:\n",
    "            chosen_tn = tn_mech\n",
    "        # 2) Else fall back to investigational product MeSH term\n",
    "        elif term_fb and term_fb != \"[none]\" and tn_fb:\n",
    "            chosen_tn = tn_fb\n",
    "\n",
    "        chosen_tn = chosen_tn.strip()\n",
    "        if not chosen_tn:\n",
    "            out.append(\"\")\n",
    "            continue\n",
    "\n",
    "        out.append(mapping.get(chosen_tn, \"\"))  # \"\" if no mapping\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Load trials and build super-group columns\n",
    "# ---------------------------------------------------\n",
    "df = pd.read_csv(TRIALS_IN)\n",
    "\n",
    "inv_sg_list = []\n",
    "ac_sg_list  = []\n",
    "soc_sg_list = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    # -----------------------------\n",
    "    # INVESTIGATIONAL PRODUCTS\n",
    "    # -----------------------------\n",
    "    # Mechanism-based mapping\n",
    "    inv_mech_terms = parse_list(row.get(\"investigational_products_mechanism_mesh_terms\"))\n",
    "    inv_mech_tn    = parse_list(row.get(\"investigational_products_mechanism_primary_tree_numbers\"))\n",
    "\n",
    "    # Fallback: investigational product MeSH mapping\n",
    "    inv_prod_terms = parse_list(row.get(\"investigational_products_mapped\"))\n",
    "    inv_prod_tn    = parse_list(row.get(\"investigational_products_primary_tree_numbers\"))\n",
    "\n",
    "    inv_sg_list.append(\n",
    "        build_super_group_list_with_fallback(\n",
    "            inv_mech_terms,\n",
    "            inv_mech_tn,\n",
    "            inv_prod_terms,\n",
    "            inv_prod_tn,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # ACTIVE COMPARATORS\n",
    "    # (no fallback requested)\n",
    "    # -----------------------------\n",
    "    ac_terms = parse_list(row.get(\"active_comparators_mechanism_mesh_terms\"))\n",
    "    ac_tn    = parse_list(row.get(\"active_comparators_mechanism_primary_tree_numbers\"))\n",
    "    ac_sg_list.append(build_super_group_list(ac_terms, ac_tn))\n",
    "\n",
    "    # -----------------------------\n",
    "    # STANDARD OF CARE\n",
    "    # (no fallback requested)\n",
    "    # -----------------------------\n",
    "    soc_terms = parse_list(row.get(\"standard_of_care_mechanism_mesh_terms\"))\n",
    "    soc_tn    = parse_list(row.get(\"standard_of_care_mechanism_primary_tree_numbers\"))\n",
    "    soc_sg_list.append(build_super_group_list(soc_terms, soc_tn))\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Insert new columns next to the primary_tree_numbers\n",
    "# ---------------------------------------------------\n",
    "def insert_after(df, col, newcol, values):\n",
    "    cols = list(df.columns)\n",
    "    idx = cols.index(col)\n",
    "    df.insert(idx + 1, newcol, values)\n",
    "\n",
    "insert_after(\n",
    "    df,\n",
    "    \"investigational_products_mechanism_primary_tree_numbers\",\n",
    "    \"investigational_products_mechanism_super_group\",\n",
    "    inv_sg_list,\n",
    ")\n",
    "\n",
    "insert_after(\n",
    "    df,\n",
    "    \"active_comparators_mechanism_primary_tree_numbers\",\n",
    "    \"active_comparators_mechanism_super_group\",\n",
    "    ac_sg_list,\n",
    ")\n",
    "\n",
    "insert_after(\n",
    "    df,\n",
    "    \"standard_of_care_mechanism_primary_tree_numbers\",\n",
    "    \"standard_of_care_mechanism_super_group\",\n",
    "    soc_sg_list,\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Save final CSV\n",
    "# ---------------------------------------------------\n",
    "df.to_csv(TRIALS_OUT, index=False)\n",
    "print(f\"Wrote final trial-level file with super-groups → {TRIALS_OUT}\")\n",
    "print(df.head(5).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b71d17c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distribution → cache/trial_super_group_distribution.csv\n",
      "Top categories:\n",
      "\n",
      "| mechanism_super_group                     |   count |\n",
      "|:------------------------------------------|--------:|\n",
      "| supportive_adjunctive_agents              |      51 |\n",
      "| cytokine_hormone_receptor_modulators      |      39 |\n",
      "| immune_checkpoint_immune_modulation       |      21 |\n",
      "| biologic_antibodies_biologics             |      20 |\n",
      "| metabolic_pathway_modulators              |      19 |\n",
      "| targeted_pathway_inhibitors               |      19 |\n",
      "| small_molecule_immunomod_antiinflammatory |       7 |\n",
      "| classical_cytotoxic_chemotherapy          |       5 |\n",
      "| vaccines_immune_biologics                 |       2 |\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "BASE_DIR = Path(\"cache\")\n",
    "INPUT_PATH  = BASE_DIR / \"trial_mechanism_with_super_groups.csv\"\n",
    "OUTPUT_PATH = BASE_DIR / \"trial_super_group_distribution.csv\"\n",
    "\n",
    "df = pd.read_csv(INPUT_PATH)\n",
    "\n",
    "def parse_list(x):\n",
    "    \"\"\"Parse list-like strings safely into Python lists.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    try:\n",
    "        v = ast.literal_eval(s)\n",
    "        return v if isinstance(v, list) else []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def first_non_empty_str(lst):\n",
    "    \"\"\"Return the first non-empty string from a list, or '' if none.\"\"\"\n",
    "    if not isinstance(lst, list):\n",
    "        return \"\"\n",
    "    for v in lst:\n",
    "        if isinstance(v, str) and v.strip():\n",
    "            return v.strip()\n",
    "    return \"\"\n",
    "\n",
    "chosen_super_groups = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    inv_sg_list = parse_list(row.get(\"investigational_products_mechanism_super_group\", \"[]\"))\n",
    "    ac_sg_list  = parse_list(row.get(\"active_comparators_mechanism_super_group\", \"[]\"))\n",
    "    soc_sg_list = parse_list(row.get(\"standard_of_care_mechanism_super_group\", \"[]\"))\n",
    "\n",
    "    # Priority 1 — investigational product supergroup\n",
    "    chosen = first_non_empty_str(inv_sg_list)\n",
    "\n",
    "    # Priority 2 — active comparator supergroup\n",
    "    if not chosen:\n",
    "        chosen = first_non_empty_str(ac_sg_list)\n",
    "\n",
    "    # Priority 3 — fallback to SOC\n",
    "    if not chosen:\n",
    "        chosen = first_non_empty_str(soc_sg_list)\n",
    "\n",
    "    chosen_super_groups.append(chosen)\n",
    "\n",
    "# Add per-trial chosen super-group (optional but useful)\n",
    "df[\"trial_mechanism_super_group\"] = chosen_super_groups\n",
    "\n",
    "# Count distribution (exclude empty)\n",
    "dist = Counter(sg for sg in chosen_super_groups if sg)\n",
    "\n",
    "dist_df = (\n",
    "    pd.DataFrame(\n",
    "        [{\"mechanism_super_group\": sg, \"count\": count}\n",
    "         for sg, count in dist.items()]\n",
    "    )\n",
    "    .sort_values(\"count\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Save distribution\n",
    "dist_df.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"Saved distribution → {OUTPUT_PATH}\")\n",
    "print(\"Top categories:\\n\")\n",
    "print(dist_df.head(20).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deae989",
   "metadata": {},
   "source": [
    "#### Output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2e05ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results table → output/trial_results_table.csv\n",
      "| trial_title                                                                                                                                                                                                                                 | drug_name                                 | moa                                                                               | innovation_generic_biosimilar   | category                             |\n",
      "|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------|:----------------------------------------------------------------------------------|:--------------------------------|:-------------------------------------|\n",
      "| Random, single oral administration, double cycle, double cross, bioequivalence test of Cinacalcet Hydrochloride Tablets in healthy subjects under fasting and postprandial state                                                            | cinacalcet hydrochloride                  | Receptors, Calcium-Sensing / agonists*                                            | Generic                         | cytokine_hormone_receptor_modulators |\n",
      "| A single intravenous administration of recombinant erythropoiesis-stimulating protein injection (CHO cells) to explore the tolerability, safety and pharmacokinetic characteristics of healthy subjects                                     | NuPIAO                                    | Receptors, Erythropoietin / agonists*                                             | Innovative                      | cytokine_hormone_receptor_modulators |\n",
      "| A Mass Balance Study of [14C]SSS17 in Healthy Chinese Male Subjects                                                                                                                                                                         | SSS-17                                    | Prolyl-Hydroxylase Inhibitors* / pharmacology; therapeutic use                    | Innovative                      | metabolic_pathway_modulators         |\n",
      "| A randomized, open label, crossover, bioequivalence, bioavailability, safety study of metformin hydrochloride sustained-release tablets in healthy volunteers under fasting and postprandial administration                                 | Metformin hydrochloride sustained-release | Gluconeogenesis / drug effects*                                                   | Generic                         | metabolic_pathway_modulators         |\n",
      "| A Phase III study of RD001 for the treatment of Anemia                                                                                                                                                                                      | RD-01                                     | Receptors, Erythropoietin / agonists*                                             | Innovative                      | cytokine_hormone_receptor_modulators |\n",
      "| A Single-center, Single-arm, Open-label, Single-dose Phase I Clinical Study to Evaluate Pharmacokinetics, Pharmacodynamics, Safety and Tolerability of rhTPO in Healthy Caucasian Participants. Approximately 22 Subjects Will be Enrolled. | Recombinant human thrombopoietin          | Receptors, Thrombopoietin / agonists*                                             | Innovative                      | cytokine_hormone_receptor_modulators |\n",
      "| A Phase II Study to Evaluate the Safety and Efficacy of SSGJ-705 Monotherapy and Combination Therapy in Patients With Advanced HER2-Expressing Solid Tumors                                                                                 | SSGJ-705                                  | Antibodies, Bispecific*                                                           | Innovative                      | biologic_antibodies_biologics        |\n",
      "| A Phase II clinical trial to evaluate SSGJ-706 injection as a monotherapy or in Combination for the treatment of Advanced digestive system cancers                                                                                          | SSGJ-706                                  | Antibodies, Bispecific* / therapeutic use                                         | Innovative                      | biologic_antibodies_biologics        |\n",
      "| A Phase I, Multicenter, Open-Label, First-in-Human Clinical Trial to Evaluate the Safety, Tolerability, Pharmacokinetics and Potential Anti-tumor Effects of SSGJ-705 in Patients With Advanced or Metastatic HER2-expressing Solid Tumors  | SSGJ-705                                  | Antibodies, Bispecific*                                                           | Innovative                      | biologic_antibodies_biologics        |\n",
      "| A Multicenter, Randomized, Double-blind, Placebo-controlled Phase II, Efficacy and Safety Study of Recombinant Anti-IL-5 Humanized Monoclonal Antibody Therapy in Adult Subjects With Severe Eosinophilic Asthma                            | SSGJ-610                                  | Interleukin-5* / antagonists & inhibitors; metabolism; therapeutic use            | Innovative                      | supportive_adjunctive_agents         |\n",
      "| A Phase II Clinical Trial of Bcl-2/xL Inhibitor In Patients With Non-Small Cell Lung Cancer                                                                                                                                                 | TM-1251                                   | Proto-Oncogene Proteins c-bcl-2* / antagonists & inhibitors; metabolism; genetics | Innovative                      | supportive_adjunctive_agents         |\n",
      "| A Multicenter, Randomized, Double-blind, Placebo-controlled Phase IIb, Effcacy and Safety Study of Recombinant Anti-IL-5 Humanized Monoclonal Antibody Therapy in Adult Subjects With Severe Asthma                                         | 610                                       | Interleukin-5* / antagonists & inhibitors; metabolism; therapeutic use            | Innovative                      | supportive_adjunctive_agents         |\n",
      "| A Phase II Study of SSGJ-707 Monotherapy in First-line PD-L1 Positive Advanced NSCLC Patients                                                                                                                                               | SSGJ-707                                  | Antibodies, Bispecific* / therapeutic use; pharmacology                           | Innovative                      | biologic_antibodies_biologics        |\n",
      "| Study on the tolerability, pharmacokinetics and pharmacodynamics of a single subcutaneous injection of recombinant human thrombopoietic factor injection (rh-TPO) in healthy adults                                                         | recombinant human thrombopoietin          | Receptors, Thrombopoietin / agonists                                              | Biosimilar                      | cytokine_hormone_receptor_modulators |\n",
      "| rESP Medication With a  to Explore the Tolerability ,Safety and Pharmacokinetic Characteristics for Healthy Subjects in the Phase I Clinical Study                                                                                          | NuPIAO                                    | Receptors, Erythropoietin / agonists*                                             | Innovative                      | cytokine_hormone_receptor_modulators |\n",
      "| A Phase II Clinical trial to Evaluate SSGJ-705 in combination with or without Pertuzumab/Chemotherapy in Patients with HER2-expressing Advanced Malignant Solid Tumors.                                                                     | SSGJ-705                                  | Antibodies, Bispecific*                                                           | Innovative                      | biologic_antibodies_biologics        |\n",
      "| A Phase IV study of Yisaipu for rheumatoid arthritis                                                                                                                                                                                        | Yisaipu                                   | Tumor Necrosis Factor Inhibitors* / therapeutic use                               | Biosimilar                      | metabolic_pathway_modulators         |\n",
      "| Effect of Food on the Pharmacokinetics of SSS17 Capsules: A Study in Chinese Healthy Subjects                                                                                                                                               | SSS-17                                    | Prolyl-Hydroxylase Inhibitors* / pharmacology; therapeutic use                    | Innovative                      | metabolic_pathway_modulators         |\n",
      "| A Randomized, Double Blind, Placebo Controlled Trial with Humanized TNFalpha Monoclonal Antibody Injection by Single Dose and Dose Escalation to Explore the Tolerance, Safety and Pharmacokinetic Characteristics in Healthy Subjects      | SSS-07                                    | Tumor Necrosis Factor-alpha / antagonists & inhibitors*                           | Innovative                      | immune_checkpoint_immune_modulation  |\n",
      "| A Randomized, Double-blind, Placebo-controlled Phase I Clinical Trial Evaluating the Safety, Tolerability, and Pharmacokinetics of SSS39 Injection by Single Intravenous Infusion in Healthy Chinese Subjects                               | SSS39                                     | MTOR Inhibitors*                                                                  | Innovative                      | targeted_pathway_inhibitors          |\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"cache\")\n",
    "OUT_DIR = Path(\"output\")\n",
    "\n",
    "CLASS_PATH   = BASE_DIR / \"trial_investigational_drugs_classifications.csv\"\n",
    "MECH_PATH    = BASE_DIR / \"trial_mechanism_with_super_groups.csv\"\n",
    "TRIALS_PATH  = BASE_DIR / \"raw_trials_with_hash.csv\"\n",
    "OUTPUT_PATH  = OUT_DIR / \"trial_results_table.csv\"\n",
    "\n",
    "# ---------------------------------\n",
    "# Helpers\n",
    "# ---------------------------------\n",
    "def parse_listish(x):\n",
    "    \"\"\"Parse a list-like string into a Python list.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return []\n",
    "    try:\n",
    "        v = ast.literal_eval(s)\n",
    "        return v if isinstance(v, list) else []\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def join_plus(lst):\n",
    "    \"\"\"Join non-empty strings with '+'.\"\"\"\n",
    "    cleaned = [str(x).strip() for x in lst if str(x).strip()]\n",
    "    return \"+\".join(cleaned)\n",
    "\n",
    "def join_unique_plus(lst):\n",
    "    \"\"\"Join unique, non-empty strings with '+' (order-preserving).\"\"\"\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for x in lst:\n",
    "        s = str(x).strip()\n",
    "        if s and s not in seen:\n",
    "            seen.add(s)\n",
    "            out.append(s)\n",
    "    return \"+\".join(out)\n",
    "\n",
    "def normalize_innovation(val: str) -> str:\n",
    "    v = (val or \"\").strip()\n",
    "    return v\n",
    "\n",
    "# NEW — remove all parenthetical segments\n",
    "def strip_parentheses(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    return re.sub(r\"\\s*\\([^)]*\\)\", \"\", s).strip()\n",
    "\n",
    "# ---------------------------------\n",
    "# Load inputs\n",
    "# ---------------------------------\n",
    "df_class  = pd.read_csv(CLASS_PATH)\n",
    "df_mech   = pd.read_csv(MECH_PATH)\n",
    "df_titles = pd.read_csv(TRIALS_PATH, dtype=str)[[\"trial_hash\", \"title\"]]\n",
    "\n",
    "# ---------------------------------\n",
    "# Prepare classification info\n",
    "# ---------------------------------\n",
    "df_class[\"drug_name_list\"] = df_class[\"investigational_products\"].apply(parse_listish)\n",
    "df_class[\"innovation_list\"] = df_class[\"investigational_products_classifications\"].apply(parse_listish)\n",
    "\n",
    "df_class[\"drug_name_joined\"] = df_class[\"drug_name_list\"].apply(join_plus)\n",
    "df_class[\"innovation_joined\"] = df_class[\"innovation_list\"].apply(\n",
    "    lambda lst: join_plus([normalize_innovation(v) for v in lst])\n",
    ")\n",
    "\n",
    "df_class_slim = df_class[[\"trial_hash\", \"drug_name_joined\", \"innovation_joined\"]].copy()\n",
    "\n",
    "# ---------------------------------\n",
    "# Prepare mechanism / category info\n",
    "# ---------------------------------\n",
    "df_mech[\"inv_drug_name_joined\"] = df_mech[\"investigational_products\"].apply(\n",
    "    lambda x: join_plus(parse_listish(x))\n",
    ")\n",
    "df_mech[\"inv_moa_joined\"] = df_mech[\"investigational_products_mechanism_mesh_terms\"].apply(\n",
    "    lambda x: join_plus(parse_listish(x))\n",
    ")\n",
    "df_mech[\"inv_category_joined\"] = df_mech[\"investigational_products_mechanism_super_group\"].apply(\n",
    "    lambda x: join_unique_plus(parse_listish(x))\n",
    ")\n",
    "\n",
    "df_mech[\"soc_drug_name_joined\"] = df_mech[\"standard_of_care\"].apply(\n",
    "    lambda x: join_plus(parse_listish(x))\n",
    ")\n",
    "df_mech[\"soc_moa_joined\"] = df_mech[\"standard_of_care_mechanism_mesh_terms\"].apply(\n",
    "    lambda x: join_plus(parse_listish(x))\n",
    ")\n",
    "df_mech[\"soc_category_joined\"] = df_mech[\"standard_of_care_mechanism_super_group\"].apply(\n",
    "    lambda x: join_unique_plus(parse_listish(x))\n",
    ")\n",
    "\n",
    "df_mech_slim = df_mech[\n",
    "    [\n",
    "        \"trial_hash\",\n",
    "        \"inv_drug_name_joined\",\n",
    "        \"inv_moa_joined\",\n",
    "        \"inv_category_joined\",\n",
    "        \"soc_drug_name_joined\",\n",
    "        \"soc_moa_joined\",\n",
    "        \"soc_category_joined\",\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# ---------------------------------\n",
    "# Merge on trial_hash\n",
    "# ---------------------------------\n",
    "merged = pd.merge(\n",
    "    df_mech_slim,\n",
    "    df_class_slim,\n",
    "    on=\"trial_hash\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# ---------------------------------\n",
    "# Build final table\n",
    "# ---------------------------------\n",
    "def build_final_row(row):\n",
    "    inv_drug = (row.get(\"inv_drug_name_joined\") or \"\").strip()\n",
    "    soc_drug = (row.get(\"soc_drug_name_joined\") or \"\").strip()\n",
    "\n",
    "    if inv_drug:\n",
    "        drug_name  = inv_drug\n",
    "        moa        = (row.get(\"inv_moa_joined\") or \"\").strip()\n",
    "        innovation = (row.get(\"innovation_joined\") or \"\").strip()\n",
    "        category   = (row.get(\"inv_category_joined\") or \"\").strip()\n",
    "        if not category:\n",
    "            category = (row.get(\"soc_category_joined\") or \"\").strip()\n",
    "\n",
    "    elif soc_drug:\n",
    "        drug_name  = soc_drug\n",
    "        moa        = (row.get(\"soc_moa_joined\") or \"\").strip()\n",
    "        category   = (row.get(\"soc_category_joined\") or \"\").strip()\n",
    "        innovation = \"generic\"\n",
    "\n",
    "    else:\n",
    "        drug_name = \"\"\n",
    "        moa = \"\"\n",
    "        innovation = \"\"\n",
    "        category = \"\"\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"drug_name\": drug_name,\n",
    "            \"moa\": moa,\n",
    "            \"innovation_generic_biosimilar\": innovation,\n",
    "            \"category\": category,\n",
    "        }\n",
    "    )\n",
    "\n",
    "final_cols = merged.apply(build_final_row, axis=1)\n",
    "final = pd.concat([merged[[\"trial_hash\"]], final_cols], axis=1)\n",
    "\n",
    "# ---------------------------------\n",
    "# Attach titles\n",
    "# ---------------------------------\n",
    "final = final.merge(df_titles, on=\"trial_hash\", how=\"left\")\n",
    "final[\"trial_title\"] = final[\"title\"].fillna(final[\"trial_hash\"])\n",
    "final.drop(columns=[\"title\"], inplace=True)\n",
    "\n",
    "# ---------------------------------\n",
    "# REMOVE PARENTHETICAL TEXT FROM drug_name\n",
    "# ---------------------------------\n",
    "final[\"drug_name\"] = final[\"drug_name\"].apply(strip_parentheses)\n",
    "\n",
    "results = final[[\"trial_title\", \"drug_name\", \"moa\", \"innovation_generic_biosimilar\", \"category\"]].copy()\n",
    "\n",
    "# Save\n",
    "results.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"Saved results table → {OUTPUT_PATH}\")\n",
    "print(results.head(20).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7db1a3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 rows with at least one missing value.\n",
      "❗ Missing rows saved to → cache/trial_results_table_missing_rows.csv\n",
      "| trial_title                                                 | drug_name   | moa   | innovation_generic_biosimilar   | category   |\n",
      "|:------------------------------------------------------------|:------------|:------|:--------------------------------|:-----------|\n",
      "| A Phase I Study of SSS24 in Patients With Colorectal Cancer | SSS24       |       | Innovative                      |            |\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------\n",
    "# Find rows with missing values\n",
    "# ---------------------------------\n",
    "\n",
    "# Treat \"\" as missing for easier filtering\n",
    "cols_to_check = [\"trial_title\", \"drug_name\", \"moa\", \"innovation_generic_biosimilar\", \"category\"]\n",
    "\n",
    "def is_missing(x):\n",
    "    return (pd.isna(x)) or (str(x).strip() == \"\")\n",
    "\n",
    "# Modern replacement for applymap\n",
    "mask_missing = results[cols_to_check].map(is_missing).any(axis=1)\n",
    "\n",
    "missing_rows = results[mask_missing].copy()\n",
    "\n",
    "print(f\"Found {len(missing_rows)} rows with at least one missing value.\")\n",
    "\n",
    "# Save for debugging\n",
    "MISSING_OUTPUT_PATH = BASE_DIR / \"trial_results_table_missing_rows.csv\"\n",
    "missing_rows.to_csv(MISSING_OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"❗ Missing rows saved to → {MISSING_OUTPUT_PATH}\")\n",
    "print(missing_rows.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5036c24e",
   "metadata": {},
   "source": [
    "discovered for two drugs \"601\" and \"Inetetamab\" citline mapped them to the wrong drug / drug_id\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "\n",
    "That is inotuzumab ozogamicin (Besponsa):\n",
    "- Target: CD22\n",
    "- Indication: B-cell ALL, etc.\n",
    "- Mechanism: antibody–drug conjugate / DNA damaging.\n",
    "\n",
    "This has nothing to do with:\n",
    "- HER2\n",
    "- breast cancer neoadjuvant\n",
    "- Inetetamab / Inituzumab / Ceputin\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "\n",
    "AER-601 (Aerami / Dance Biopharm GLP-1 analogue)\n",
    "- Target: GLP-1 receptor\n",
    "- Indications: Type 2 diabetes, obesity, appetite/weight control\n",
    "- Mechanism: GLP-1 receptor agonist, incretin mimetic, insulin secretagogue\n",
    "\n",
    "This has nothing to do with:\n",
    "- VEGF-A or VEGF receptors\n",
    "- Intravitreal ophthalmic anti-VEGF biologics\n",
    "- Pathological myopic choroidal neovascularization (pmCNV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
